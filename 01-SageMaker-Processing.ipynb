{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Probabilistic Forecasting - Electricity\n",
    "\n",
    "This notebook demonstrates how to perform Data Analysis and Preparation Engineering with Amazon SageMaker Studio using AWS Glue Interactive Session.\n",
    "\n",
    "Using this notebook, we can execute cells in order to read data, visualize, and perform transformations using PySpark with AWS Glue Interactice Session.\n",
    "\n",
    "Let's start preparing our dataset.\n",
    "\n",
    "**SageMaker Studio Kernel**: DataScience 3.0 - Python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset\n",
    "\n",
    "The data set (Electricity Price Forecasting) was downloaded from [Kaggle](https://www.kaggle.com/code/dimitriosroussis/electricity-price-forecasting-with-dnns-eda/data).\n",
    "This dataset is using the past values of the electricity price as well as those of another features related to energy generation and weather conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 1 - Import Modules\n",
    "\n",
    "Here weâ€™ll import some libraries and define some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.spark.processing import PySparkProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a SageMaker Session and save the default region and the execution role in some Python variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "region = boto3.session.Session().region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bucket_name = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Step 2 - Run the processing job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By using [PySparkProcessor](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_processing/spark_distributed_data_processing/sagemaker-spark-processing.html), we can provide to the Amazon SageMaker Job the execution PySpark scripts in distributed data processing mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SparkSession\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctions\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m pandas_udf\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtypes\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DoubleType, TimestampType\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m PIPE, Popen\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtraceback\u001b[39;49;00m\n",
      "\n",
      "BASE_PATH = os.path.join(\u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mopt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "PROCESSING_PATH = os.path.join(BASE_PATH, \u001b[33m\"\u001b[39;49;00m\u001b[33mprocessing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "PROCESSING_PATH_INPUT = os.path.join(PROCESSING_PATH, \u001b[33m\"\u001b[39;49;00m\u001b[33minput\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "PROCESSING_PATH_OUTPUT = os.path.join(PROCESSING_PATH, \u001b[33m\"\u001b[39;49;00m\u001b[33moutput\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "logging.basicConfig(level=logging.INFO)\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "\n",
      "\u001b[37m## HDFS Manager\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mHDFSManager\u001b[39;49;00m:\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, spark):\n",
      "        sc = spark.sparkContext\n",
      "        \u001b[36mself\u001b[39;49;00m.files = []\n",
      "        \u001b[36mself\u001b[39;49;00m.URI = sc._gateway.jvm.java.net.URI\n",
      "        \u001b[36mself\u001b[39;49;00m.Path = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
      "        \u001b[36mself\u001b[39;49;00m.FileSystem = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
      "        \u001b[36mself\u001b[39;49;00m.Configuration = sc._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.fs = sc._jvm.org \\\n",
      "            .apache.hadoop \\\n",
      "            .fs.FileSystem \\\n",
      "            .get(sc._jsc.hadoopConfiguration())\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.hdfs_path = spark.sparkContext._jsc.hadoopConfiguration().get(\u001b[33m\"\u001b[39;49;00m\u001b[33mfs.defaultFS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "        logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mCreating /tmp folder in HDFS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "        put = Popen([\u001b[33m\"\u001b[39;49;00m\u001b[33mhadoop\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m-mkdir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m-p\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, os.path.join(\u001b[36mself\u001b[39;49;00m.hdfs_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mtmp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)], stdin=PIPE, bufsize=-\u001b[34m1\u001b[39;49;00m)\n",
      "        put.communicate()\n",
      "        \n",
      "        \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msave_df\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, df, file, separator=\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[34mtry\u001b[39;49;00m:\n",
      "            logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m in path \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(file, os.path.join(\u001b[36mself\u001b[39;49;00m.hdfs_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mtmp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, file)))\n",
      "            df.write \\\n",
      "                .format(\u001b[33m\"\u001b[39;49;00m\u001b[33mcom.databricks.spark.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \\\n",
      "                .mode(\u001b[33m'\u001b[39;49;00m\u001b[33moverwrite\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \\\n",
      "                .option(\u001b[33m\"\u001b[39;49;00m\u001b[33mquote\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \\\n",
      "                .option(\u001b[33m\"\u001b[39;49;00m\u001b[33mheader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mTrue\u001b[39;49;00m) \\\n",
      "                .option(\u001b[33m\"\u001b[39;49;00m\u001b[33msep\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, separator) \\\n",
      "                .csv(\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(os.path.join(\u001b[36mself\u001b[39;49;00m.hdfs_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mtmp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, file)))\n",
      "\n",
      "        \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "            stacktrace = traceback.format_exc()\n",
      "\n",
      "            logger.error(stacktrace)\n",
      "\n",
      "            \u001b[34mraise\u001b[39;49;00m e\n",
      "            \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mload_df\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, spark_session, file, separator=\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\n",
      "        \u001b[34mtry\u001b[39;49;00m:\n",
      "            logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m from path \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(file, os.path.join(\u001b[36mself\u001b[39;49;00m.hdfs_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mtmp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, file)))\n",
      "            \n",
      "            df = spark_session.read \\\n",
      "                .option(\u001b[33m\"\u001b[39;49;00m\u001b[33mheader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mTrue\u001b[39;49;00m) \\\n",
      "                .option(\u001b[33m\"\u001b[39;49;00m\u001b[33msep\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, separator) \\\n",
      "                .csv(\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(os.path.join(\u001b[36mself\u001b[39;49;00m.hdfs_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mtmp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, file)))\n",
      "\n",
      "            \u001b[34mreturn\u001b[39;49;00m df\n",
      "        \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "            stacktrace = traceback.format_exc()\n",
      "\n",
      "            logger.error(stacktrace)\n",
      "\n",
      "            \u001b[34mraise\u001b[39;49;00m e\n",
      "    \n",
      "    \u001b[37m## This method allows you to copy files from local file system to HDFS\u001b[39;49;00m\n",
      "    \u001b[37m#\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mfull_copy\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, path):\n",
      "        \u001b[34mtry\u001b[39;49;00m:\n",
      "            logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mEBS files: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(os.listdir(path)))\n",
      "            \n",
      "            \u001b[34mif\u001b[39;49;00m os.path.isdir(path):\n",
      "                \u001b[36mself\u001b[39;49;00m.files = [f \u001b[34mfor\u001b[39;49;00m f \u001b[35min\u001b[39;49;00m os.listdir(path)]\n",
      "\n",
      "                \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.files:\n",
      "                    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mCopy \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m in HDFS \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(os.path.join(path, file), os.path.join(\u001b[36mself\u001b[39;49;00m.hdfs_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mtmp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, file)))\n",
      "\n",
      "                    put = Popen([\u001b[33m\"\u001b[39;49;00m\u001b[33mhadoop\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m-put\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, os.path.join(path, file), os.path.join(\u001b[36mself\u001b[39;49;00m.hdfs_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mtmp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, file)], stdin=PIPE, bufsize=-\u001b[34m1\u001b[39;49;00m)\n",
      "                    put.communicate()                       \n",
      "        \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "            stacktrace = traceback.format_exc()\n",
      "\n",
      "            logger.error(stacktrace)\n",
      "\n",
      "            \u001b[34mraise\u001b[39;49;00m e\n",
      "\n",
      "\u001b[37m## Spark Initializer\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "spark = SparkSession.builder \\\n",
      "    .config(\u001b[33m\"\u001b[39;49;00m\u001b[33mspark.sql.legacy.timeParserPolicy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mCORRECTED\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \\\n",
      "    .getOrCreate()\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minterpolate\u001b[39;49;00m(pdf):\n",
      "    pdf = pdf.set_index(\u001b[33m'\u001b[39;49;00m\u001b[33mtime\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    pdf.interpolate(method=\u001b[33m'\u001b[39;49;00m\u001b[33mlinear\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, limit_direction=\u001b[33m'\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, inplace=\u001b[34mTrue\u001b[39;49;00m, axis=\u001b[34m0\u001b[39;49;00m)\n",
      "    pdf.reset_index(inplace=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m pdf\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--copy_hdfs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--bucket_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33ms3 input bucket\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--processing_input_files_path\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33ms3 input key prefix\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--processing_output_files_path\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33ms3 output bucket\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mArguments: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args))\n",
      "    \n",
      "    hdfs_manager = HDFSManager(spark)\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m args.copy_hdfs == \u001b[33m\"\u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "        hdfs_manager.full_copy(PROCESSING_PATH_INPUT)\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m args.copy_hdfs == \u001b[33m\"\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "        df_e = spark.read.csv(\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.bucket_name\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.processing_input_files_path\u001b[33m}\u001b[39;49;00m\u001b[33m/energy_dataset.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "            header=\u001b[34mTrue\u001b[39;49;00m\n",
      "        )\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        df_e = hdfs_manager.load_df(spark, \u001b[33m\"\u001b[39;49;00m\u001b[33menergy_dataset.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    columns_to_drop = [\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mgeneration fossil coal-derived gas\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mgeneration fossil oil shale\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mgeneration fossil peat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mgeneration geothermal\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mgeneration hydro pumped storage aggregated\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mgeneration marine\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mgeneration wind offshore\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mforecast wind offshore eday ahead\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mtotal load forecast\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mforecast solar day ahead\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mforecast wind onshore day ahead\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    ]\n",
      "\n",
      "    df_e = df_e.drop(*columns_to_drop)\n",
      "    \n",
      "    \u001b[34mfor\u001b[39;49;00m column \u001b[35min\u001b[39;49;00m df_e.schema.names:\n",
      "        \u001b[34mif\u001b[39;49;00m column != \u001b[33m\"\u001b[39;49;00m\u001b[33mtime\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "            df_e = df_e.withColumn(column, df_e[column].cast(DoubleType()))\n",
      "            df_e = df_e.withColumn(column, F.round(F.col(column), \u001b[34m2\u001b[39;49;00m))\n",
      "                \n",
      "    df_e \\\n",
      "        .select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m df_e.schema.names \u001b[34mif\u001b[39;49;00m c != \u001b[33m\"\u001b[39;49;00m\u001b[33mtime\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]) \\\n",
      "        .toPandas()\n",
      "    \n",
      "    df_e_p = df_e.toPandas()\n",
      "    df_e_p = interpolate(df_e_p)\n",
      "    df_e = spark.createDataFrame(df_e_p)\n",
      "    \n",
      "    df_e.show(\u001b[34m1\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m## Save DataFrame in HDFS\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m args.copy_hdfs == \u001b[33m\"\u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "        hdfs_manager.save_df(df_e, \u001b[33m\"\u001b[39;49;00m\u001b[33menergy_dataset_df\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \n",
      "    \u001b[34mif\u001b[39;49;00m args.copy_hdfs == \u001b[33m\"\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "        df_w = spark.read.csv(\n",
      "            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.bucket_name\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.processing_input_files_path\u001b[33m}\u001b[39;49;00m\u001b[33m/weather_features.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "            header=\u001b[34mTrue\u001b[39;49;00m\n",
      "        )\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        df_w = hdfs_manager.load_df(spark, \u001b[33m\"\u001b[39;49;00m\u001b[33mweather_features.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m df_w.columns:\n",
      "        \u001b[34mif\u001b[39;49;00m c != \u001b[33m\"\u001b[39;49;00m\u001b[33mdt_iso\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "            df_w = df_w.withColumn(c, df_w[c].cast(DoubleType()))\n",
      "            \n",
      "    df_w = df_w.withColumn(\u001b[33m\"\u001b[39;49;00m\u001b[33mtime\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, F.to_timestamp(\u001b[33m\"\u001b[39;49;00m\u001b[33mdt_iso\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33myyyy-MM-dd HH:mm:ssVV\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    \n",
      "    df_w = df_w.drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mdt_iso\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    df_w = df_w.orderBy(\u001b[33m\"\u001b[39;49;00m\u001b[33mtime\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).coalesce(\u001b[34m1\u001b[39;49;00m).dropDuplicates(subset = [\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtime\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \n",
      "    df_w.show(\u001b[34m1\u001b[39;49;00m)\n",
      "    \n",
      "    df_w_barcelona = df_w.filter(F.col(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) == \u001b[33m\"\u001b[39;49;00m\u001b[33m Barcelona\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_w_bilbao = df_w.filter(F.col(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) == \u001b[33m\"\u001b[39;49;00m\u001b[33mBilbao\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_w_madrid = df_w.filter(F.col(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) == \u001b[33m\"\u001b[39;49;00m\u001b[33mMadrid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_w_seville = df_w.filter(F.col(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) == \u001b[33m\"\u001b[39;49;00m\u001b[33mSeville\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_w_valencia = df_w.filter(F.col(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) == \u001b[33m\"\u001b[39;49;00m\u001b[33mValencia\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    df_w_barcelona = df_w_barcelona.select([F.col(c).alias(c + \u001b[33m\"\u001b[39;49;00m\u001b[33m_barcelona\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m df_w_barcelona.columns]).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name_barcelona\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_w_bilbao = df_w_bilbao.select([F.col(c).alias(c + \u001b[33m\"\u001b[39;49;00m\u001b[33m_bilbao\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m df_w_bilbao.columns]).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name_bilbao\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_w_madrid = df_w_madrid.select([F.col(c).alias(c + \u001b[33m\"\u001b[39;49;00m\u001b[33m_madrid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m df_w_madrid.columns]).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name_madrid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_w_seville = df_w_seville.select([F.col(c).alias(c + \u001b[33m\"\u001b[39;49;00m\u001b[33m_seville\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m df_w_seville.columns]).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name_seville\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_w_valencia = df_w_valencia.select([F.col(c).alias(c + \u001b[33m\"\u001b[39;49;00m\u001b[33m_valencia\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m df_w_valencia.columns]).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mcity_name_valencia\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m## Load DataFrame from HDFS\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m args.copy_hdfs == \u001b[33m\"\u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "        df_e = hdfs_manager.load_df(spark, \u001b[33m\"\u001b[39;49;00m\u001b[33menergy_dataset_df\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    df_e = df_e.join(df_w_barcelona, df_e.time == df_w_barcelona.time_barcelona, how=\u001b[33m'\u001b[39;49;00m\u001b[33mfull\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mtime_barcelona\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_e = df_e.join(df_w_bilbao, df_e.time == df_w_bilbao.time_bilbao, how=\u001b[33m'\u001b[39;49;00m\u001b[33mfull\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mtime_bilbao\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_e = df_e.join(df_w_madrid, df_e.time == df_w_madrid.time_madrid, how=\u001b[33m'\u001b[39;49;00m\u001b[33mfull\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mtime_madrid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_e = df_e.join(df_w_seville, df_e.time == df_w_seville.time_seville, how=\u001b[33m'\u001b[39;49;00m\u001b[33mfull\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mtime_seville\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    df_e = df_e.join(df_w_valencia, df_e.time == df_w_valencia.time_valencia, how=\u001b[33m'\u001b[39;49;00m\u001b[33mfull\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).drop(\u001b[33m\"\u001b[39;49;00m\u001b[33mtime_valencia\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mWriting output file \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m to \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[33m\"\u001b[39;49;00m\u001b[33menergy_full.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.bucket_name\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.processing_output_files_path\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    \n",
      "    df_e.repartition(\u001b[34m1\u001b[39;49;00m).write \\\n",
      "        .format(\u001b[33m\"\u001b[39;49;00m\u001b[33mcom.databricks.spark.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \\\n",
      "        .mode(\u001b[33m'\u001b[39;49;00m\u001b[33moverwrite\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \\\n",
      "        .option(\u001b[33m\"\u001b[39;49;00m\u001b[33mquote\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \\\n",
      "        .option(\u001b[33m\"\u001b[39;49;00m\u001b[33mheader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mTrue\u001b[39;49;00m) \\\n",
      "        .option(\u001b[33m\"\u001b[39;49;00m\u001b[33msep\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \\\n",
      "        .option(\u001b[33m'\u001b[39;49;00m\u001b[33mencoding\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mUTF-8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \\\n",
      "        .save(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.bucket_name\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.processing_output_files_path\u001b[33m}\u001b[39;49;00m\u001b[33m/energy_full.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,)\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ./code/processing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Global Parameters\n",
    "\n",
    "In order to allow users to execute the SageMaker Processing Job locally, we are defining the variable `local_mode`. If you want to test the local mode capability, please put the variable to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "local_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processing_framework_version = \"3.1\"\n",
    "processing_input_files_path = \"electricity-forecasting/data/input\"\n",
    "processing_instance_count = 2\n",
    "processing_output_files_path = \"electricity-forecasting/data/output\"\n",
    "\n",
    "if local_mode:\n",
    "    processing_instance_type = \"local\"\n",
    "else:\n",
    "    processing_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the `FrameworkProcessor` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processor = PySparkProcessor(\n",
    "    framework_version=processing_framework_version,\n",
    "    role=role,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function has been deprecated and could break pipeline step caching. We recommend using the run() function directly with pipeline sessionsto access step arguments.\n"
     ]
    }
   ],
   "source": [
    "run_args = processor.get_run_args(\n",
    "        \"./code/processing.py\",\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                input_name=\"input\",\n",
    "                source=\"s3://{}/{}\".format(bucket_name, processing_input_files_path),\n",
    "                destination=\"/opt/ml/processing/input\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"output\",\n",
    "                source=\"/opt/ml/processing/output\",\n",
    "                destination=\"s3://{}/{}\".format(bucket_name, processing_output_files_path))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name sagemaker-spark-processing-2023-02-02-13-06-02-090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-spark-processing-2023-02-02-13-06-02-090\n",
      "Inputs:  [{'InputName': 'input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/data/input', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-691148928602/sagemaker-spark-processing-2023-02-02-13-06-02-090/input/code/processing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/data/output', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'output-2', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/logs', 'LocalPath': '/opt/ml/processing/spark-events/', 'S3UploadMode': 'Continuous'}}]\n",
      ".........................\u001b[35m02-02 13:10 smspark.cli  INFO     Parsing arguments. argv: ['/usr/local/bin/smspark-submit', '--local-spark-event-logs-dir', '/opt/ml/processing/spark-events/', '/opt/ml/processing/input/code/processing.py', '--copy_hdfs', '1', '--bucket_name', 'sagemaker-eu-west-1-691148928602', '--processing_input_files_path', 'electricity-forecasting/data/input', '--processing_output_files_path', 'electricity-forecasting/data/output']\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark.cli  INFO     Raw spark options before processing: {'class_': None, 'jars': None, 'py_files': None, 'files': None, 'verbose': False}\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark.cli  INFO     App and app arguments: ['/opt/ml/processing/input/code/processing.py', '--copy_hdfs', '1', '--bucket_name', 'sagemaker-eu-west-1-691148928602', '--processing_input_files_path', 'electricity-forecasting/data/input', '--processing_output_files_path', 'electricity-forecasting/data/output']\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark.cli  INFO     Rendered spark options: {'class_': None, 'jars': None, 'py_files': None, 'files': None, 'verbose': False}\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark.cli  INFO     Initializing processing job.\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     {'current_host': 'algo-2', 'hosts': ['algo-1', 'algo-2']}\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     {'ProcessingJobArn': 'arn:aws:sagemaker:eu-west-1:691148928602:processing-job/sagemaker-spark-processing-2023-02-02-13-06-02-090', 'ProcessingJobName': 'sagemaker-spark-processing-2023-02-02-13-06-02-090', 'AppSpecification': {'ImageUri': '571004829621.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-spark-processing:3.1-cpu', 'ContainerEntrypoint': ['smspark-submit', '--local-spark-event-logs-dir', '/opt/ml/processing/spark-events/', '/opt/ml/processing/input/code/processing.py'], 'ContainerArguments': ['--copy_hdfs', '1', '--bucket_name', 'sagemaker-eu-west-1-691148928602', '--processing_input_files_path', 'electricity-forecasting/data/input', '--processing_output_files_path', 'electricity-forecasting/data/output']}, 'ProcessingInputs': [{'InputName': 'input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input', 'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/data/input', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/code', 'S3Uri': 's3://sagemaker-eu-west-1-691148928602/sagemaker-spark-processing-2023-02-02-13-06-02-090/input/code/processing.py', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/data/output', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}, {'OutputName': 'output-2', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/spark-events/', 'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/logs', 'S3UploadMode': 'Continuous'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 2, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::691148928602:role/mlops-sagemaker-execution-role', 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}}\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark.cli  INFO     running spark submit command: spark-submit --master yarn --deploy-mode client /opt/ml/processing/input/code/processing.py --copy_hdfs 1 --bucket_name sagemaker-eu-west-1-691148928602 --processing_input_files_path electricity-forecasting/data/input --processing_output_files_path electricity-forecasting/data/output\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     waiting for hosts\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     starting status server\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     Status server listening on algo-2:5555\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     bootstrapping cluster\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     transitioning from status INITIALIZING to BOOTSTRAPPING\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     copying aws jars\u001b[0m\n",
      "\u001b[35m02-02 13:10 waitress     INFO     Serving on http://10.0.73.224:5555\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     Found hadoop jar hadoop-aws-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     Optional jar jets3t-0.9.0.jar in /usr/lib/hadoop/lib does not exist\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     copying cluster config\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/hdfs-site.xml to /usr/lib/hadoop/etc/hadoop/hdfs-site.xml\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/core-site.xml to /usr/lib/hadoop/etc/hadoop/core-site.xml\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/yarn-site.xml to /usr/lib/hadoop/etc/hadoop/yarn-site.xml\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/spark-defaults.conf to /usr/lib/spark/conf/spark-defaults.conf\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/spark-env.sh to /usr/lib/spark/conf/spark-env.sh\u001b[0m\n",
      "\u001b[35m02-02 13:10 root         INFO     Detected instance type: m5.xlarge with total memory: 16384M and total cores: 4\u001b[0m\n",
      "\u001b[35m02-02 13:10 root         INFO     Writing default config to /usr/lib/hadoop/etc/hadoop/yarn-site.xml\u001b[0m\n",
      "\u001b[35m02-02 13:10 root         INFO     Configuration at /usr/lib/hadoop/etc/hadoop/yarn-site.xml is: \u001b[0m\n",
      "\u001b[35m<?xml version=\"1.0\"?>\u001b[0m\n",
      "\u001b[35m<!-- Site specific YARN configuration properties -->\n",
      " <configuration>\n",
      "     <property>\n",
      "         <name>yarn.resourcemanager.hostname</name>\n",
      "         <value>10.0.127.243</value>\n",
      "         <description>The hostname of the RM.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.hostname</name>\n",
      "         <value>algo-2</value>\n",
      "         <description>The hostname of the NM.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.webapp.address</name>\n",
      "         <value>algo-2:8042</value>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.vmem-pmem-ratio</name>\n",
      "         <value>5</value>\n",
      "         <description>Ratio between virtual memory to physical memory.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.resourcemanager.am.max-attempts</name>\n",
      "         <value>1</value>\n",
      "         <description>The maximum number of application attempts.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.env-whitelist</name>\n",
      "         <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,YARN_HOME,AWS_CONTAINER_CREDENTIALS_RELATIVE_URI,AWS_REGION</value>\n",
      "         <description>Environment variable whitelist</description>\n",
      "     </property>\n",
      " \n",
      "  <property>\n",
      "    <name>yarn.scheduler.minimum-allocation-mb</name>\n",
      "    <value>1</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.maximum-allocation-mb</name>\n",
      "    <value>15892</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.minimum-allocation-vcores</name>\n",
      "    <value>1</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.maximum-allocation-vcores</name>\n",
      "    <value>4</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.nodemanager.resource.memory-mb</name>\n",
      "    <value>15892</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.nodemanager.resource.cpu-vcores</name>\n",
      "    <value>4</value>\n",
      "  </property>\u001b[0m\n",
      "\u001b[35m</configuration>\u001b[0m\n",
      "\u001b[35m02-02 13:10 root         INFO     Writing default config to /usr/lib/spark/conf/spark-defaults.conf\u001b[0m\n",
      "\u001b[35m02-02 13:10 root         INFO     Configuration at /usr/lib/spark/conf/spark-defaults.conf is: \u001b[0m\n",
      "\u001b[35mspark.driver.extraClassPath      /usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar\u001b[0m\n",
      "\u001b[35mspark.driver.extraLibraryPath    /usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native\u001b[0m\n",
      "\u001b[35mspark.executor.extraClassPath    /usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar\u001b[0m\n",
      "\u001b[35mspark.executor.extraLibraryPath  /usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native\u001b[0m\n",
      "\u001b[35mspark.driver.host=10.0.127.243\u001b[0m\n",
      "\u001b[35mspark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2\u001b[0m\n",
      "\u001b[35m# Fix for \"Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot\u001b[0m\n",
      "\u001b[35m# receive any reply from 10.0.109.30:35219 in 120 seconds.\"\"\u001b[0m\n",
      "\u001b[35mspark.rpc.askTimeout=300s\u001b[0m\n",
      "\u001b[35mspark.driver.memory 2048m\u001b[0m\n",
      "\u001b[35mspark.driver.memoryOverhead 204m\u001b[0m\n",
      "\u001b[35mspark.driver.defaultJavaOptions -XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled\u001b[0m\n",
      "\u001b[35mspark.executor.memory 12399m\u001b[0m\n",
      "\u001b[35mspark.executor.memoryOverhead 1239m\u001b[0m\n",
      "\u001b[35mspark.executor.cores 4\u001b[0m\n",
      "\u001b[35mspark.executor.defaultJavaOptions -verbose:gc -XX:OnOutOfMemoryError='kill -9 %p' -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseParallelGC -XX:InitiatingHeapOccupancyPercent=70 -XX:ConcGCThreads=1 -XX:ParallelGCThreads=3 \u001b[0m\n",
      "\u001b[35mspark.executor.instances 2\u001b[0m\n",
      "\u001b[35mspark.default.parallelism 16\u001b[0m\n",
      "\u001b[35mspark.yarn.appMasterEnv.AWS_REGION eu-west-1\u001b[0m\n",
      "\u001b[35mspark.executorEnv.AWS_REGION eu-west-1\u001b[0m\n",
      "\u001b[35m02-02 13:10 root         INFO     Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[35m02-02 13:10 root         INFO     No file at /opt/ml/processing/input/conf/configuration.json exists, skipping user configuration\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     waiting for cluster to be up\u001b[0m\n",
      "\u001b[35mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[35mWARNING: /usr/lib/hadoop/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[35mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:05,431 INFO nodemanager.NodeManager: STARTUP_MSG: \u001b[0m\n",
      "\u001b[35m/************************************************************\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG: Starting NodeManager\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   host = algo-2/10.0.73.224\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   version = 3.2.1-amzn-3\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.5.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanag\u001b[0m\n",
      "\u001b[35mer-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-protocol-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-csv-1.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-common-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/jcodings-1.0.13.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/metrics-core-2.2.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/joni-2.1.2.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-annotations-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-client-1.2.6.jar\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   build = Unknown -r Unknown; compiled by 'release' on 2021-03-30T23:42Z\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[35m************************************************************/\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark.cli  INFO     Parsing arguments. argv: ['/usr/local/bin/smspark-submit', '--local-spark-event-logs-dir', '/opt/ml/processing/spark-events/', '/opt/ml/processing/input/code/processing.py', '--copy_hdfs', '1', '--bucket_name', 'sagemaker-eu-west-1-691148928602', '--processing_input_files_path', 'electricity-forecasting/data/input', '--processing_output_files_path', 'electricity-forecasting/data/output']\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark.cli  INFO     Raw spark options before processing: {'class_': None, 'jars': None, 'py_files': None, 'files': None, 'verbose': False}\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark.cli  INFO     App and app arguments: ['/opt/ml/processing/input/code/processing.py', '--copy_hdfs', '1', '--bucket_name', 'sagemaker-eu-west-1-691148928602', '--processing_input_files_path', 'electricity-forecasting/data/input', '--processing_output_files_path', 'electricity-forecasting/data/output']\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark.cli  INFO     Rendered spark options: {'class_': None, 'jars': None, 'py_files': None, 'files': None, 'verbose': False}\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark.cli  INFO     Initializing processing job.\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     {'current_host': 'algo-1', 'hosts': ['algo-1', 'algo-2']}\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     {'ProcessingJobArn': 'arn:aws:sagemaker:eu-west-1:691148928602:processing-job/sagemaker-spark-processing-2023-02-02-13-06-02-090', 'ProcessingJobName': 'sagemaker-spark-processing-2023-02-02-13-06-02-090', 'AppSpecification': {'ImageUri': '571004829621.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-spark-processing:3.1-cpu', 'ContainerEntrypoint': ['smspark-submit', '--local-spark-event-logs-dir', '/opt/ml/processing/spark-events/', '/opt/ml/processing/input/code/processing.py'], 'ContainerArguments': ['--copy_hdfs', '1', '--bucket_name', 'sagemaker-eu-west-1-691148928602', '--processing_input_files_path', 'electricity-forecasting/data/input', '--processing_output_files_path', 'electricity-forecasting/data/output']}, 'ProcessingInputs': [{'InputName': 'input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input', 'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/data/input', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/code', 'S3Uri': 's3://sagemaker-eu-west-1-691148928602/sagemaker-spark-processing-2023-02-02-13-06-02-090/input/code/processing.py', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/data/output', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}, {'OutputName': 'output-2', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/spark-events/', 'S3Uri': 's3://sagemaker-eu-west-1-691148928602/electricity-forecasting/logs', 'S3UploadMode': 'Continuous'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 2, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::691148928602:role/mlops-sagemaker-execution-role', 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}}\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark.cli  INFO     running spark submit command: spark-submit --master yarn --deploy-mode client /opt/ml/processing/input/code/processing.py --copy_hdfs 1 --bucket_name sagemaker-eu-west-1-691148928602 --processing_input_files_path electricity-forecasting/data/input --processing_output_files_path electricity-forecasting/data/output\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     waiting for hosts\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     starting status server\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     Status server listening on algo-1:5555\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     bootstrapping cluster\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     transitioning from status INITIALIZING to BOOTSTRAPPING\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     copying aws jars\u001b[0m\n",
      "\u001b[34m02-02 13:10 waitress     INFO     Serving on http://10.0.127.243:5555\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     Found hadoop jar hadoop-aws-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     Optional jar jets3t-0.9.0.jar in /usr/lib/hadoop/lib does not exist\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     copying cluster config\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/hdfs-site.xml to /usr/lib/hadoop/etc/hadoop/hdfs-site.xml\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/core-site.xml to /usr/lib/hadoop/etc/hadoop/core-site.xml\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/yarn-site.xml to /usr/lib/hadoop/etc/hadoop/yarn-site.xml\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/spark-defaults.conf to /usr/lib/spark/conf/spark-defaults.conf\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     copying /opt/hadoop-config/spark-env.sh to /usr/lib/spark/conf/spark-env.sh\u001b[0m\n",
      "\u001b[34m02-02 13:10 root         INFO     Detected instance type: m5.xlarge with total memory: 16384M and total cores: 4\u001b[0m\n",
      "\u001b[34m02-02 13:10 root         INFO     Writing default config to /usr/lib/hadoop/etc/hadoop/yarn-site.xml\u001b[0m\n",
      "\u001b[34m02-02 13:10 root         INFO     Configuration at /usr/lib/hadoop/etc/hadoop/yarn-site.xml is: \u001b[0m\n",
      "\u001b[34m<?xml version=\"1.0\"?>\u001b[0m\n",
      "\u001b[34m<!-- Site specific YARN configuration properties -->\n",
      " <configuration>\n",
      "     <property>\n",
      "         <name>yarn.resourcemanager.hostname</name>\n",
      "         <value>10.0.127.243</value>\n",
      "         <description>The hostname of the RM.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.hostname</name>\n",
      "         <value>algo-1</value>\n",
      "         <description>The hostname of the NM.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.webapp.address</name>\n",
      "         <value>algo-1:8042</value>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.vmem-pmem-ratio</name>\n",
      "         <value>5</value>\n",
      "         <description>Ratio between virtual memory to physical memory.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.resourcemanager.am.max-attempts</name>\n",
      "         <value>1</value>\n",
      "         <description>The maximum number of application attempts.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.env-whitelist</name>\n",
      "         <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,YARN_HOME,AWS_CONTAINER_CREDENTIALS_RELATIVE_URI,AWS_REGION</value>\n",
      "         <description>Environment variable whitelist</description>\n",
      "     </property>\n",
      " \n",
      "  <property>\n",
      "    <name>yarn.scheduler.minimum-allocation-mb</name>\n",
      "    <value>1</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.maximum-allocation-mb</name>\n",
      "    <value>15892</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.minimum-allocation-vcores</name>\n",
      "    <value>1</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.maximum-allocation-vcores</name>\n",
      "    <value>4</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.nodemanager.resource.memory-mb</name>\n",
      "    <value>15892</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.nodemanager.resource.cpu-vcores</name>\n",
      "    <value>4</value>\n",
      "  </property>\u001b[0m\n",
      "\u001b[34m</configuration>\u001b[0m\n",
      "\u001b[34m02-02 13:10 root         INFO     Writing default config to /usr/lib/spark/conf/spark-defaults.conf\u001b[0m\n",
      "\u001b[34m02-02 13:10 root         INFO     Configuration at /usr/lib/spark/conf/spark-defaults.conf is: \u001b[0m\n",
      "\u001b[34mspark.driver.extraClassPath      /usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar\u001b[0m\n",
      "\u001b[34mspark.driver.extraLibraryPath    /usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native\u001b[0m\n",
      "\u001b[34mspark.executor.extraClassPath    /usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar\u001b[0m\n",
      "\u001b[34mspark.executor.extraLibraryPath  /usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native\u001b[0m\n",
      "\u001b[34mspark.driver.host=10.0.127.243\u001b[0m\n",
      "\u001b[34mspark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2\u001b[0m\n",
      "\u001b[34m# Fix for \"Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot\u001b[0m\n",
      "\u001b[34m# receive any reply from 10.0.109.30:35219 in 120 seconds.\"\"\u001b[0m\n",
      "\u001b[34mspark.rpc.askTimeout=300s\u001b[0m\n",
      "\u001b[34mspark.driver.memory 2048m\u001b[0m\n",
      "\u001b[34mspark.driver.memoryOverhead 204m\u001b[0m\n",
      "\u001b[34mspark.driver.defaultJavaOptions -XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled\u001b[0m\n",
      "\u001b[34mspark.executor.memory 12399m\u001b[0m\n",
      "\u001b[34mspark.executor.memoryOverhead 1239m\u001b[0m\n",
      "\u001b[34mspark.executor.cores 4\u001b[0m\n",
      "\u001b[34mspark.executor.defaultJavaOptions -verbose:gc -XX:OnOutOfMemoryError='kill -9 %p' -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseParallelGC -XX:InitiatingHeapOccupancyPercent=70 -XX:ConcGCThreads=1 -XX:ParallelGCThreads=3 \u001b[0m\n",
      "\u001b[34mspark.executor.instances 2\u001b[0m\n",
      "\u001b[34mspark.default.parallelism 16\u001b[0m\n",
      "\u001b[34mspark.yarn.appMasterEnv.AWS_REGION eu-west-1\u001b[0m\n",
      "\u001b[34mspark.executorEnv.AWS_REGION eu-west-1\u001b[0m\n",
      "\u001b[34m02-02 13:10 root         INFO     Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m02-02 13:10 root         INFO     No file at /opt/ml/processing/input/conf/configuration.json exists, skipping user configuration\u001b[0m\n",
      "\u001b[34mWARNING: /usr/lib/hadoop/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,336 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.127.243\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-3\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.5.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-plu\u001b[0m\n",
      "\u001b[34mginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = Unknown -r Unknown; compiled by 'release' on 2021-03-30T23:42Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,346 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,415 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-dd3dc1a2-de7b-43b1-ae23-1098e0172026\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,830 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,841 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,842 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,843 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,847 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,847 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,847 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,847 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,885 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,895 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,895 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,899 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,899 INFO blockmanagement.BlockManager: The block deletion will start around 2023 Feb 02 13:10:05\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,900 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,900 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,901 INFO util.GSet: 2.0% max memory 3.1 GB = 63.5 MB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,902 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,926 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,926 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,932 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,932 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,932 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,932 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,932 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,932 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,932 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,932 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,933 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,933 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,933 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,952 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,952 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,952 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,952 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,963 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,963 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,963 INFO util.GSet: 1.0% max memory 3.1 GB = 31.8 MB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,963 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,973 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,973 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,973 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,974 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,978 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,980 INFO snapshot.SnapshotManager: SkipList is disabled\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,984 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,984 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,984 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,984 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,991 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,991 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,991 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,994 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,995 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,996 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,996 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,996 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 976.0 KB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:05,996 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:06,020 INFO namenode.FSImage: Allocated new BlockPoolId: BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:06,034 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:05,448 INFO nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:05,449 INFO datanode.DataNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[35m/************************************************************\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG: Starting DataNode\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   host = algo-2/10.0.73.224\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   version = 3.2.1-amzn-3\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.5.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanag\u001b[0m\n",
      "\u001b[35mer-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   build = Unknown -r Unknown; compiled by 'release' on 2021-03-30T23:42Z\u001b[0m\n",
      "\u001b[35mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[35m************************************************************/\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:05,464 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:05,998 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,043 INFO resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,043 INFO resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,113 INFO nodemanager.NodeManager: Node Manager health check script is not available or doesn't have execute permission, so not starting the node health script runner.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,126 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,157 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,158 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,159 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,159 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,160 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,160 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,161 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,168 INFO tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,185 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,185 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,207 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,208 INFO impl.MetricsSystemImpl: DataNode metrics system started\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,247 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,338 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,339 INFO impl.MetricsSystemImpl: NodeManager metrics system started\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,360 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,370 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,399 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,401 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,405 INFO datanode.DataNode: Configured hostname is algo-2\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,405 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,407 INFO nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@350aac89\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,408 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,408 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,409 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,409 INFO containermanager.ContainerManagerImpl: AMRMProxyService is disabled\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,410 INFO localizer.ResourceLocalizationService: per directory file limit = 8192\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,428 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,431 INFO datanode.DataNode: Balancing bandwidth is 10485760 bytes/s\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,431 INFO datanode.DataNode: Number threads for balancing is 50\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,435 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:06,058 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:06,135 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:06,144 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:06,148 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:06,149 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.127.243\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     waiting for cluster to be up\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,444 INFO resources.ResourceHandlerModule: Using traffic control bandwidth handler\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,447 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@31ea9581\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,447 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,448 INFO monitor.ContainersMonitorImpl: Physical memory check enabled: true\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,448 INFO monitor.ContainersMonitorImpl: Virtual memory check enabled: true\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,448 INFO monitor.ContainersMonitorImpl: Elastic memory control enabled: false\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,448 INFO monitor.ContainersMonitorImpl: Strict memory control enabled: true\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,449 INFO monitor.ContainersMonitorImpl: ContainersMonitor enabled: true\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,452 WARN monitor.ContainersMonitorImpl: NodeManager configured with 15.5 G physical memory allocated to containers, which is more than 80% of the total physical memory available (15.4 G). Thrashing might happen.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,452 INFO containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,474 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,474 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,476 INFO util.log: Logging initialized @1599ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,480 INFO conf.Configuration: node-resources.xml not found\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,480 INFO resource.ResourceUtils: Unable to find 'node-resources.xml'.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,482 INFO nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:15892, vCores:4>\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,505 INFO nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=15892 virtual-memory=79460 virtual-cores=4\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,562 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,586 INFO ipc.Server: Starting Socket Reader #1 for port 0\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,660 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,667 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,674 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,676 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,676 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,676 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,705 INFO http.HttpServer2: Jetty bound to port 34511\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,706 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_312-b07\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,736 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,736 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,738 INFO server.session: node0 Scavenging every 600000ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,758 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5f77d0f9{logs,/logs,file:///usr/lib/hadoop/logs/,AVAILABLE}\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,759 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a3793c7{static,/static,file:///usr/lib/hadoop-hdfs/webapps/static/,AVAILABLE}\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,820 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,830 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7a220c9a{datanode,/,file:///usr/lib/hadoop-hdfs/webapps/datanode/,AVAILABLE}{file:/usr/lib/hadoop-hdfs/webapps/datanode}\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,839 INFO server.AbstractConnector: Started ServerConnector@135606db{HTTP/1.1,[http/1.1]}{localhost:34511}\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,840 INFO server.Server: Started @1963ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,854 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,854 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,855 INFO ipc.Server: IPC Server listener on 0: starting\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,867 INFO security.NMContainerTokenSecretManager: Updating node address : algo-2:43589\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,874 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,875 INFO ipc.Server: Starting Socket Reader #1 for port 8040\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,890 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,891 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,891 INFO ipc.Server: IPC Server listener on 8040: starting\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,892 INFO localizer.ResourceLocalizationService: Localizer started on port 8040\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,898 INFO containermanager.ContainerManagerImpl: ContainerManager started at /10.0.73.224:43589\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,898 INFO containermanager.ContainerManagerImpl: ContainerManager bound to algo-2/10.0.73.224:0\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,898 WARN tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,902 INFO webapp.WebServer: Instantiating NMWebApp at algo-2:8042\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,928 INFO util.log: Logging initialized @2048ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,964 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,971 INFO datanode.DataNode: dnUserName = root\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,971 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:06,971 INFO datanode.DataNode: supergroup = supergroup\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,017 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,030 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,033 INFO http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,034 INFO ipc.Server: Starting Socket Reader #1 for port 9867\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,040 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,042 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,042 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,042 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,044 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,044 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,044 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,046 INFO http.HttpServer2: adding path spec: /node/*\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,046 INFO http.HttpServer2: adding path spec: /ws/*\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,260 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,280 INFO datanode.DataNode: Refresh request received for nameservices: null\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,288 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,297 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to algo-1/10.0.127.243:8020 starting to offer service\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,304 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,304 INFO ipc.Server: IPC Server listener on 9867: starting\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,414 INFO webapp.WebApps: Registered webapp guice modules\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,417 INFO http.HttpServer2: Jetty bound to port 8042\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,418 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_312-b07\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,238 INFO nodemanager.NodeManager: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NodeManager\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.127.243\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-3\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.5.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-plu\u001b[0m\n",
      "\u001b[34mginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-common-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/joni-2.1.2.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-csv-1.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-client-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/metrics-core-2.2.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/jcodings-1.0.13.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-annotations-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-protocol-1.2.6.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = Unknown -r Unknown; compiled by 'release' on 2021-03-30T23:42Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,278 INFO nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,283 INFO resourcemanager.ResourceManager: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting ResourceManager\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.127.243\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-3\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.5.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-plu\u001b[0m\n",
      "\u001b[34mginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-common-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/joni-2.1.2.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-csv-1.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-client-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/metrics-core-2.2.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/jcodings-1.0.13.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-annotations-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-protocol-1.2.6.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = Unknown -r Unknown; compiled by 'release' on 2021-03-30T23:42Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,297 INFO resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,327 INFO datanode.DataNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting DataNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.127.243\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-3\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.5.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-plu\u001b[0m\n",
      "\u001b[34mginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = Unknown -r Unknown; compiled by 'release' on 2021-03-30T23:42Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,339 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,394 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.127.243\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-3\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.5.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-3.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-3-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.5.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-plu\u001b[0m\n",
      "\u001b[34mginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-3.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = Unknown -r Unknown; compiled by 'release' on 2021-03-30T23:42Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,405 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:07,764 INFO namenode.NameNode: createNameNode []\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,451 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,451 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,452 INFO server.session: node0 Scavenging every 600000ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,461 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,463 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@708400f6{logs,/logs,file:///var/log/yarn/,AVAILABLE}\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,464 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b2c4efb{static,/static,jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-3.jar!/webapps/static,AVAILABLE}\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,473 WARN webapp.WebInfConfiguration: Can't generate resourceBase as part of webapp tmp dir name: java.lang.NullPointerException\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:07,560 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[35mFeb 02, 2023 1:10:07 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[35mINFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices as a root resource class\u001b[0m\n",
      "\u001b[35mFeb 02, 2023 1:10:07 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[35mINFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\u001b[0m\n",
      "\u001b[35mFeb 02, 2023 1:10:07 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[35mINFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver as a provider class\u001b[0m\n",
      "\u001b[35mFeb 02, 2023 1:10:07 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\u001b[0m\n",
      "\u001b[35mINFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\u001b[0m\n",
      "\u001b[35mFeb 02, 2023 1:10:07 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[35mINFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[35mFeb 02, 2023 1:10:07 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[35mINFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[35mFeb 02, 2023 1:10:08 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[35mINFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,197 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7c447c76{node,/,file:///tmp/jetty-algo-2-8042-_-any-8452878383101426396.dir/webapp/,AVAILABLE}{jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-3.jar!/webapps/node}\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,204 INFO server.AbstractConnector: Started ServerConnector@5553d0f5{HTTP/1.1,[http/1.1]}{algo-2:8042}\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,204 INFO server.Server: Started @3325ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,204 INFO webapp.WebApps: Web app node started at 8042\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,207 INFO nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : algo-2:43589\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,208 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,214 INFO client.RMProxy: Connecting to ResourceManager at /10.0.127.243:8031\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,261 INFO nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,272 INFO nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:08,369 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,085 INFO conf.Configuration: found resource core-site.xml at file:/etc/hadoop/conf.empty/core-site.xml\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,094 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,218 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,219 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,295 INFO conf.Configuration: found resource yarn-site.xml at file:/etc/hadoop/conf.empty/yarn-site.xml\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,326 INFO resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,326 INFO resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,326 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,381 INFO security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,386 INFO security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,394 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,394 INFO security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,394 INFO impl.MetricsSystemImpl: NameNode metrics system started\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,415 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,452 INFO nodemanager.NodeManager: Node Manager health check script is not available or doesn't have execute permission, so not starting the node health script runner.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,474 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,478 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,479 INFO resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,488 INFO namenode.NameNodeUtils: fs.defaultFS is hdfs://10.0.127.243/\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,515 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,517 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,518 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,519 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,528 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,528 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,529 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,532 INFO tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,539 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.event.EventDispatcher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,544 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,545 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,554 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,554 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,556 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,608 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,645 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,649 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,783 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,783 INFO impl.MetricsSystemImpl: DataNode metrics system started\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,805 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,805 INFO impl.MetricsSystemImpl: NodeManager metrics system started\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,805 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,805 INFO impl.MetricsSystemImpl: ResourceManager metrics system started\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,817 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,826 INFO security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,835 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,838 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,845 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,847 INFO resourcemanager.RMNMInfo: Registered RMNMInfo MBean\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,848 INFO monitor.RMAppLifetimeMonitor: Application lifelime monitor interval set to 3000 ms.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,849 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,853 INFO placement.MultiNodeSortingManager: Initializing NodeSortingService=MultiNodeSortingManager\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,856 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,861 INFO conf.Configuration: found resource capacity-scheduler.xml at file:/etc/hadoop/conf.empty/capacity-scheduler.xml\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,875 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,897 INFO util.log: Logging initialized @2591ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,916 INFO scheduler.AbstractYarnScheduler: Minimum allocation = <memory:1, vCores:1>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,917 INFO scheduler.AbstractYarnScheduler: Maximum allocation = <memory:15892, vCores:4>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,955 INFO nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@1c5920df\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,956 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,958 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,958 INFO containermanager.ContainerManagerImpl: AMRMProxyService is disabled\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:08,958 INFO localizer.ResourceLocalizationService: per directory file limit = 8192\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,004 INFO capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,004 INFO capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,018 INFO capacity.ParentQueue: root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,\u001b[0m\n",
      "\u001b[34m, reservationsContinueLooking=true, orderingPolicy=utilization, priority=0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,018 INFO capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,035 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,048 INFO resources.ResourceHandlerModule: Using traffic control bandwidth handler\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     cluster is up\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     transitioning from status BOOTSTRAPPING to WAITING\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     starting executor logs watcher\u001b[0m\n",
      "\u001b[35mStarting executor logs watcher on log_dir: /var/log/yarn\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     waiting for the primary to come up\u001b[0m\n",
      "\u001b[35m02-02 13:10 smspark-submit INFO     waiting for the primary to go down\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:09,370 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:09,385 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,052 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@231f98ef\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,052 INFO capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,053 INFO capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,054 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,055 INFO monitor.ContainersMonitorImpl: Physical memory check enabled: true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,055 INFO monitor.ContainersMonitorImpl: Virtual memory check enabled: true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,056 INFO monitor.ContainersMonitorImpl: Elastic memory control enabled: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,056 INFO monitor.ContainersMonitorImpl: Strict memory control enabled: true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,056 INFO monitor.ContainersMonitorImpl: ContainersMonitor enabled: true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,065 WARN monitor.ContainersMonitorImpl: NodeManager configured with 15.5 G physical memory allocated to containers, which is more than 80% of the total physical memory available (15.4 G). Thrashing might happen.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,066 INFO containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,072 INFO capacity.LeafQueue: Initializing default\u001b[0m\n",
      "\u001b[34mcapacity = 1.0 [= (float) configuredCapacity / 100 ]\u001b[0m\n",
      "\u001b[34mabsoluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]\u001b[0m\n",
      "\u001b[34mmaxCapacity = 1.0 [= configuredMaxCapacity ]\u001b[0m\n",
      "\u001b[34mabsoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]\u001b[0m\n",
      "\u001b[34meffectiveMinResource=<memory:0, vCores:0>\n",
      " , effectiveMaxResource=<memory:0, vCores:0>\u001b[0m\n",
      "\u001b[34muserLimit = 100 [= configuredUserLimit ]\u001b[0m\n",
      "\u001b[34muserLimitFactor = 1.0 [= configuredUserLimitFactor ]\u001b[0m\n",
      "\u001b[34mmaxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]\u001b[0m\n",
      "\u001b[34mmaxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]\u001b[0m\n",
      "\u001b[34musedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]\u001b[0m\n",
      "\u001b[34mabsoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]\u001b[0m\n",
      "\u001b[34mmaxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]\u001b[0m\n",
      "\u001b[34mminimumAllocationFactor = 0.99993706 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]\u001b[0m\n",
      "\u001b[34mmaximumAllocation = <memory:15892, vCores:4> [= configuredMaxAllocation ]\u001b[0m\n",
      "\u001b[34mnumContainers = 0 [= currentNumContainers ]\u001b[0m\n",
      "\u001b[34mstate = RUNNING [= configuredState ]\u001b[0m\n",
      "\u001b[34macls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]\u001b[0m\n",
      "\u001b[34mnodeLocalityDelay = 40\u001b[0m\n",
      "\u001b[34mrackLocalityAdditionalDelay = -1\u001b[0m\n",
      "\u001b[34mlabels=*,\u001b[0m\n",
      "\u001b[34mreservationsContinueLooking = true\u001b[0m\n",
      "\u001b[34mpreemptionDisabled = true\u001b[0m\n",
      "\u001b[34mdefaultAppPriorityPerQueue = 0\u001b[0m\n",
      "\u001b[34mpriority = 0\u001b[0m\n",
      "\u001b[34mmaxLifetime = -1 seconds\u001b[0m\n",
      "\u001b[34mdefaultLifetime = -1 seconds\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,073 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0, effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,073 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,075 INFO capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,077 INFO placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,078 INFO placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,079 INFO capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1, vCores:1>>, maximumAllocation=<<memory:15892, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,082 INFO conf.Configuration: dynamic-resources.xml not found\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,096 INFO resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,097 INFO resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,098 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,098 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,100 INFO resourcemanager.AMSProcessingChain: Adding [org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor] tp top of AMS Processing chain. \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,106 INFO conf.Configuration: node-resources.xml not found\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,109 INFO resourcemanager.ResourceManager: TimelineServicePublisher is not configured\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,107 INFO resource.ResourceUtils: Unable to find 'node-resources.xml'.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,116 INFO nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:15892, vCores:4>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,116 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,122 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,124 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,128 INFO datanode.DataNode: Configured hostname is algo-1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,130 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,134 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,154 INFO http.HttpRequestLog: Http request log for http.requests.namenode is not defined\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,158 INFO nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=15892 virtual-memory=79460 virtual-cores=4\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,168 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,169 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,170 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,170 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,170 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,182 INFO datanode.DataNode: Balancing bandwidth is 10485760 bytes/s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,182 INFO datanode.DataNode: Number threads for balancing is 50\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,192 INFO util.log: Logging initialized @2892ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,227 INFO http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,227 INFO http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,239 INFO http.HttpServer2: Jetty bound to port 9870\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,240 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_312-b07\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,253 INFO util.log: Logging initialized @2954ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,329 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,361 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,362 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,363 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,364 INFO server.session: node0 Scavenging every 600000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,377 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@514646ef{logs,/logs,file:///usr/lib/hadoop/logs/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,379 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7ae0a9ec{static,/static,file:///usr/lib/hadoop-hdfs/webapps/static/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,379 INFO http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,393 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,397 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,397 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,397 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,398 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,398 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,398 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,400 INFO http.HttpServer2: adding path spec: /cluster/*\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,400 INFO http.HttpServer2: adding path spec: /ws/*\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,400 INFO http.HttpServer2: adding path spec: /app/*\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,421 INFO ipc.Server: Starting Socket Reader #1 for port 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,492 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,514 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@589da3f3{hdfs,/,file:///usr/lib/hadoop-hdfs/webapps/hdfs/,AVAILABLE}{file:/usr/lib/hadoop-hdfs/webapps/hdfs}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,533 INFO server.AbstractConnector: Started ServerConnector@7b4c50bc{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,533 INFO server.Server: Started @3227ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,564 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,587 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,596 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,605 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,605 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,605 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,639 INFO http.HttpServer2: Jetty bound to port 44427\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,641 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_312-b07\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,726 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,726 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,735 INFO server.session: node0 Scavenging every 660000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,755 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5f77d0f9{logs,/logs,file:///usr/lib/hadoop/logs/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,763 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a3793c7{static,/static,file:///usr/lib/hadoop-hdfs/webapps/static/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,851 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,856 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,859 INFO ipc.Server: IPC Server listener on 0: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,905 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,932 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7a220c9a{datanode,/,file:///usr/lib/hadoop-hdfs/webapps/datanode/,AVAILABLE}{file:/usr/lib/hadoop-hdfs/webapps/datanode}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,946 INFO server.AbstractConnector: Started ServerConnector@135606db{HTTP/1.1,[http/1.1]}{localhost:44427}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,946 INFO server.Server: Started @3647ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:09,983 INFO security.NMContainerTokenSecretManager: Updating node address : algo-1:42563\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,001 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,024 INFO ipc.Server: Starting Socket Reader #1 for port 8040\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,051 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:10,371 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:10,386 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,060 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,062 INFO ipc.Server: IPC Server listener on 8040: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,063 INFO localizer.ResourceLocalizationService: Localizer started on port 8040\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,077 INFO containermanager.ContainerManagerImpl: ContainerManager started at /10.0.127.243:42563\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,077 INFO containermanager.ContainerManagerImpl: ContainerManager bound to algo-1/10.0.127.243:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,078 WARN tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,088 INFO webapp.WebServer: Instantiating NMWebApp at algo-1:8042\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,104 WARN namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,104 WARN namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,154 INFO util.log: Logging initialized @3827ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,212 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,239 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,246 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,250 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,256 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,260 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,266 INFO datanode.DataNode: dnUserName = root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,266 INFO datanode.DataNode: supergroup = supergroup\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,276 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,276 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,276 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,276 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,350 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,360 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,366 INFO webapp.WebApps: Registered webapp guice modules\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,371 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,374 INFO http.HttpServer2: Jetty bound to port 8088\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,375 INFO http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,376 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_312-b07\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,378 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,378 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,383 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,385 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,385 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,385 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,386 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,386 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,386 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,388 INFO http.HttpServer2: adding path spec: /node/*\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,389 INFO http.HttpServer2: adding path spec: /ws/*\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,402 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,402 INFO blockmanagement.BlockManager: The block deletion will start around 2023 Feb 02 13:10:10\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,404 INFO ipc.Server: Starting Socket Reader #1 for port 9867\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,407 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,408 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,411 INFO util.GSet: 2.0% max memory 3.1 GB = 63.5 MB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,411 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,419 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,419 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,422 INFO server.session: node0 Scavenging every 660000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,430 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,430 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,439 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,440 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,441 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,441 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,442 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,442 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,442 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,442 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,443 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,443 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,443 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,451 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,467 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,480 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,484 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,512 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6853425f{logs,/logs,file:///var/log/yarn/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,513 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@282cb7c7{static,/static,jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-3.jar!/webapps/static,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,519 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,519 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,519 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,520 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,538 WARN webapp.WebInfConfiguration: Can't generate resourceBase as part of webapp tmp dir name: java.lang.NullPointerException\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,553 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,554 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,554 INFO util.GSet: 1.0% max memory 3.1 GB = 31.8 MB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,564 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,575 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,579 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,579 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,579 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,601 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,603 INFO snapshot.SnapshotManager: SkipList is disabled\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,609 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,609 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,610 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,610 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,636 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,636 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,637 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,641 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,644 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,646 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,656 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,656 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 976.0 KB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,656 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,699 INFO common.Storage: Lock on /opt/amazon/hadoop/hdfs/namenode/in_use.lock acquired by nodename 114@algo-1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,756 INFO namenode.FileJournalManager: Recovering unfinalized segments in /opt/amazon/hadoop/hdfs/namenode/current\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,757 INFO namenode.FSImage: No edit log streams selected.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,758 INFO namenode.FSImage: Planning to load image: FSImageFile(file=/opt/amazon/hadoop/hdfs/namenode/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,842 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,842 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,860 INFO namenode.FSImageFormatPBINode: Loading 1 INodes.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,891 INFO datanode.DataNode: Refresh request received for nameservices: null\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,920 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:10,963 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to algo-1/10.0.127.243:8020 starting to offer service\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,035 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,039 INFO ipc.Server: IPC Server listener on 9867: starting\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver as a provider class\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:11,371 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:11,386 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices as a root resource class\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\u001b[0m\n",
      "\u001b[34mINFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,110 INFO namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,110 INFO namenode.FSImage: Loaded image for txid 0 from /opt/amazon/hadoop/hdfs/namenode/current/fsimage_0000000000000000000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,116 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,117 INFO namenode.FSEditLog: Starting log segment at 1\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,214 INFO webapp.WebApps: Registered webapp guice modules\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,217 INFO http.HttpServer2: Jetty bound to port 8042\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,219 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_312-b07\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,279 INFO namenode.NameCache: initialized with 0 entries 0 lookups\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,279 INFO namenode.FSNamesystem: Finished loading FSImage in 618 msecs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,300 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,300 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,302 INFO server.session: node0 Scavenging every 600000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,341 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,360 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5829e4f4{logs,/logs,file:///var/log/yarn/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,362 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@c35172e{static,/static,jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-3.jar!/webapps/static,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,393 WARN webapp.WebInfConfiguration: Can't generate resourceBase as part of webapp tmp dir name: java.lang.NullPointerException\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,587 INFO namenode.NameNode: RPC server is binding to algo-1:8020\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,641 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,653 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:11,677 INFO ipc.Server: Starting Socket Reader #1 for port 8020\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices as a root resource class\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver as a provider class\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\u001b[0m\n",
      "\u001b[34mINFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:11 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,009 INFO namenode.NameNode: Clients are to use algo-1:8020 to access this namenode/service.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,011 INFO namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,372 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,387 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,085 INFO namenode.LeaseManager: Number of blocks under construction: 0\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:12 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,128 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,182 INFO blockmanagement.BlockManager: initializing replication queues\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,195 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,196 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,196 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,289 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,311 INFO ipc.Server: IPC Server listener on 8020: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,439 INFO namenode.NameNode: NameNode RPC up at: algo-1/10.0.127.243:8020\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,473 INFO namenode.FSNamesystem: Starting services required for active state\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,473 INFO namenode.FSDirectory: Initializing quota with 4 thread(s)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,519 INFO namenode.FSDirectory: Quota initialization completed in 46 milliseconds\u001b[0m\n",
      "\u001b[34mname space=1\u001b[0m\n",
      "\u001b[34mstorage space=0\u001b[0m\n",
      "\u001b[34mstorage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,599 INFO blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,604 INFO blockmanagement.BlockManager: Total number of blocks            = 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,604 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,604 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,605 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,605 INFO blockmanagement.BlockManager: Number of blocks being written    = 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,606 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 410 msec\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:12 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:12 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,942 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2e23c180{cluster,/,file:///tmp/jetty-10_0_127_243-8088-_-any-2045888661103556379.dir/webapp/,AVAILABLE}{jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-3.jar!/webapps/cluster}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,973 INFO server.AbstractConnector: Started ServerConnector@1e8b7643{HTTP/1.1,[http/1.1]}{10.0.127.243:8088}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,973 INFO server.Server: Started @6674ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:12,974 INFO webapp.WebApps: Web app cluster started at 8088\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,049 INFO datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to algo-1/10.0.127.243:8020\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,058 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,942 INFO datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to algo-1/10.0.127.243:8020\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,944 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,950 INFO common.Storage: Lock on /opt/amazon/hadoop/hdfs/datanode/in_use.lock acquired by nodename 16@algo-2\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,951 INFO common.Storage: Storage directory with location [DISK]file:/opt/amazon/hadoop/hdfs/datanode is not formatted for namespace 2017611789. Formatting...\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,951 INFO common.Storage: Generated new storageID DS-36570986-625f-40ae-b471-091b231c9601 for directory /opt/amazon/hadoop/hdfs/datanode \u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,976 INFO common.Storage: Analyzing storage directories for bpid BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,976 INFO common.Storage: Locking is disabled for /opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,977 INFO common.Storage: Block pool storage directory for location [DISK]file:/opt/amazon/hadoop/hdfs/datanode and block pool id BP-679434436-10.0.127.243-1675343406013 is not formatted. Formatting ...\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,977 INFO common.Storage: Formatting block pool BP-679434436-10.0.127.243-1675343406013 directory /opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,982 INFO datanode.DataNode: Setting up storage: nsid=2017611789;bpid=BP-679434436-10.0.127.243-1675343406013;lv=-57;nsInfo=lv=-65;cid=CID-dd3dc1a2-de7b-43b1-ae23-1098e0172026;nsid=2017611789;c=1675343406013;bpid=BP-679434436-10.0.127.243-1675343406013;dnuuid=null\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:12,985 INFO datanode.DataNode: Generated and persisted new Datanode UUID f7374d5e-7d40-4091-8c9c-2ed23a592adf\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,082 INFO impl.FsDatasetImpl: Added new volume: DS-36570986-625f-40ae-b471-091b231c9601\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,082 INFO impl.FsDatasetImpl: Added volume - [DISK]file:/opt/amazon/hadoop/hdfs/datanode, StorageType: DISK\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,086 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,094 INFO checker.ThrottledAsyncChecker: Scheduling a check for /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,102 INFO checker.DatasetVolumeChecker: Scheduled health check for volume /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,104 INFO impl.FsDatasetImpl: Adding block pool BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,105 INFO impl.FsDatasetImpl: Scanning block pool BP-679434436-10.0.127.243-1675343406013 on volume /opt/amazon/hadoop/hdfs/datanode...\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,134 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-679434436-10.0.127.243-1675343406013 on /opt/amazon/hadoop/hdfs/datanode: 30ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,135 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-679434436-10.0.127.243-1675343406013: 31ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,136 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-679434436-10.0.127.243-1675343406013 on volume /opt/amazon/hadoop/hdfs/datanode...\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,137 INFO impl.BlockPoolSlice: Replica Cache file: /opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/replicas doesn't exist \u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,138 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-679434436-10.0.127.243-1675343406013 on volume /opt/amazon/hadoop/hdfs/datanode: 1ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,138 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-679434436-10.0.127.243-1675343406013: 3ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,140 INFO datanode.VolumeScanner: Now scanning bpid BP-679434436-10.0.127.243-1675343406013 on volume /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,142 INFO datanode.VolumeScanner: VolumeScanner(/opt/amazon/hadoop/hdfs/datanode, DS-36570986-625f-40ae-b471-091b231c9601): finished scanning block pool BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,154 INFO datanode.VolumeScanner: VolumeScanner(/opt/amazon/hadoop/hdfs/datanode, DS-36570986-625f-40ae-b471-091b231c9601): no suitable block pools found to scan.  Waiting 1814399986 ms.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,155 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/2/23 2:10 PM with interval of 21600000ms\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,160 INFO datanode.DataNode: Block pool BP-679434436-10.0.127.243-1675343406013 (Datanode Uuid f7374d5e-7d40-4091-8c9c-2ed23a592adf) service to algo-1/10.0.127.243:8020 beginning handshake with NN\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,235 INFO datanode.DataNode: Block pool Block pool BP-679434436-10.0.127.243-1675343406013 (Datanode Uuid f7374d5e-7d40-4091-8c9c-2ed23a592adf) service to algo-1/10.0.127.243:8020 successfully registered with NN\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,235 INFO datanode.DataNode: For namenode algo-1/10.0.127.243:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,388 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,072 INFO common.Storage: Lock on /opt/amazon/hadoop/hdfs/datanode/in_use.lock acquired by nodename 115@algo-1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,074 INFO common.Storage: Storage directory with location [DISK]file:/opt/amazon/hadoop/hdfs/datanode is not formatted for namespace 2017611789. Formatting...\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,075 INFO common.Storage: Generated new storageID DS-50271d6c-6b61-4cb0-90e1-8611fe562dc7 for directory /opt/amazon/hadoop/hdfs/datanode \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,104 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,123 INFO common.Storage: Analyzing storage directories for bpid BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,123 INFO common.Storage: Locking is disabled for /opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,123 INFO common.Storage: Block pool storage directory for location [DISK]file:/opt/amazon/hadoop/hdfs/datanode and block pool id BP-679434436-10.0.127.243-1675343406013 is not formatted. Formatting ...\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,124 INFO common.Storage: Formatting block pool BP-679434436-10.0.127.243-1675343406013 directory /opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,128 INFO ipc.Server: Starting Socket Reader #1 for port 8033\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,130 INFO datanode.DataNode: Setting up storage: nsid=2017611789;bpid=BP-679434436-10.0.127.243-1675343406013;lv=-57;nsInfo=lv=-65;cid=CID-dd3dc1a2-de7b-43b1-ae23-1098e0172026;nsid=2017611789;c=1675343406013;bpid=BP-679434436-10.0.127.243-1675343406013;dnuuid=null\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,132 INFO datanode.DataNode: Generated and persisted new Datanode UUID 4b81e253-b887-4691-a79a-c4f0d69060f0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,202 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.73.224:9866, datanodeUuid=f7374d5e-7d40-4091-8c9c-2ed23a592adf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-dd3dc1a2-de7b-43b1-ae23-1098e0172026;nsid=2017611789;c=1675343406013) storage f7374d5e-7d40-4091-8c9c-2ed23a592adf\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,214 INFO net.NetworkTopology: Adding a new node: /default-rack/10.0.73.224:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,214 INFO blockmanagement.BlockReportLeaseManager: Registered DN f7374d5e-7d40-4091-8c9c-2ed23a592adf (10.0.73.224:9866).\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,366 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,368 INFO resourcemanager.ResourceManager: Transitioning to active state\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,367 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,368 INFO ipc.Server: IPC Server listener on 8033: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,388 INFO impl.FsDatasetImpl: Added new volume: DS-50271d6c-6b61-4cb0-90e1-8611fe562dc7\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,388 INFO impl.FsDatasetImpl: Added volume - [DISK]file:/opt/amazon/hadoop/hdfs/datanode, StorageType: DISK\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,392 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,396 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-36570986-625f-40ae-b471-091b231c9601 for DN 10.0.73.224:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,413 INFO recovery.RMStateStore: Updating AMRMToken\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,413 INFO security.RMContainerTokenSecretManager: Rolling master-key for container-tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,417 INFO security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,417 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,417 INFO security.RMDelegationTokenSecretManager: storing master key with keyID 1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,417 INFO recovery.RMStateStore: Storing RMDTMasterKey.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,418 INFO checker.ThrottledAsyncChecker: Scheduling a check for /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,434 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,434 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,434 INFO security.RMDelegationTokenSecretManager: storing master key with keyID 2\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,434 INFO recovery.RMStateStore: Storing RMDTMasterKey.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,448 INFO checker.DatasetVolumeChecker: Scheduled health check for volume /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,450 INFO impl.FsDatasetImpl: Adding block pool BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,450 INFO impl.FsDatasetImpl: Scanning block pool BP-679434436-10.0.127.243-1675343406013 on volume /opt/amazon/hadoop/hdfs/datanode...\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,456 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,475 INFO BlockStateChange: BLOCK* processReport 0xfeee21bd908a8d2c: Processing first storage report for DS-36570986-625f-40ae-b471-091b231c9601 from datanode f7374d5e-7d40-4091-8c9c-2ed23a592adf\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,477 INFO BlockStateChange: BLOCK* processReport 0xfeee21bd908a8d2c: from storage DS-36570986-625f-40ae-b471-091b231c9601 node DatanodeRegistration(10.0.73.224:9866, datanodeUuid=f7374d5e-7d40-4091-8c9c-2ed23a592adf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-dd3dc1a2-de7b-43b1-ae23-1098e0172026;nsid=2017611789;c=1675343406013), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0\u001b[0m\n",
      "\u001b[34mFeb 02, 2023 1:10:13 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,579 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@64fc097e{node,/,file:///tmp/jetty-algo-1-8042-_-any-3182178575199029205.dir/webapp/,AVAILABLE}{jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-3.jar!/webapps/node}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,586 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-679434436-10.0.127.243-1675343406013 on /opt/amazon/hadoop/hdfs/datanode: 135ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,586 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-679434436-10.0.127.243-1675343406013: 136ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,596 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-679434436-10.0.127.243-1675343406013 on volume /opt/amazon/hadoop/hdfs/datanode...\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,596 INFO impl.BlockPoolSlice: Replica Cache file: /opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/replicas doesn't exist \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,614 INFO server.AbstractConnector: Started ServerConnector@1af687fe{HTTP/1.1,[http/1.1]}{algo-1:8042}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,615 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-679434436-10.0.127.243-1675343406013 on volume /opt/amazon/hadoop/hdfs/datanode: 19ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,616 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-679434436-10.0.127.243-1675343406013: 28ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,615 INFO server.Server: Started @7288ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,616 INFO webapp.WebApps: Web app node started at 8042\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,620 INFO datanode.VolumeScanner: Now scanning bpid BP-679434436-10.0.127.243-1675343406013 on volume /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,625 INFO datanode.VolumeScanner: VolumeScanner(/opt/amazon/hadoop/hdfs/datanode, DS-50271d6c-6b61-4cb0-90e1-8611fe562dc7): finished scanning block pool BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,643 INFO nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : algo-1:42563\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,648 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,655 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/2/23 1:47 PM with interval of 21600000ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,657 INFO client.RMProxy: Connecting to ResourceManager at /10.0.127.243:8031\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,658 INFO datanode.VolumeScanner: VolumeScanner(/opt/amazon/hadoop/hdfs/datanode, DS-50271d6c-6b61-4cb0-90e1-8611fe562dc7): no suitable block pools found to scan.  Waiting 1814399959 ms.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,669 INFO datanode.DataNode: Block pool BP-679434436-10.0.127.243-1675343406013 (Datanode Uuid 4b81e253-b887-4691-a79a-c4f0d69060f0) service to algo-1/10.0.127.243:8020 beginning handshake with NN\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,698 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.127.243:9866, datanodeUuid=4b81e253-b887-4691-a79a-c4f0d69060f0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-dd3dc1a2-de7b-43b1-ae23-1098e0172026;nsid=2017611789;c=1675343406013) storage 4b81e253-b887-4691-a79a-c4f0d69060f0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,698 INFO net.NetworkTopology: Adding a new node: /default-rack/10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,698 INFO blockmanagement.BlockReportLeaseManager: Registered DN 4b81e253-b887-4691-a79a-c4f0d69060f0 (10.0.127.243:9866).\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,702 INFO datanode.DataNode: Block pool Block pool BP-679434436-10.0.127.243-1675343406013 (Datanode Uuid 4b81e253-b887-4691-a79a-c4f0d69060f0) service to algo-1/10.0.127.243:8020 successfully registered with NN\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,703 INFO datanode.DataNode: For namenode algo-1/10.0.127.243:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,743 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-50271d6c-6b61-4cb0-90e1-8611fe562dc7 for DN 10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,771 INFO BlockStateChange: BLOCK* processReport 0x73529fd7e85cefea: Processing first storage report for DS-50271d6c-6b61-4cb0-90e1-8611fe562dc7 from datanode 4b81e253-b887-4691-a79a-c4f0d69060f0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,771 INFO BlockStateChange: BLOCK* processReport 0x73529fd7e85cefea: from storage DS-50271d6c-6b61-4cb0-90e1-8611fe562dc7 node DatanodeRegistration(10.0.127.243:9866, datanodeUuid=4b81e253-b887-4691-a79a-c4f0d69060f0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-dd3dc1a2-de7b-43b1-ae23-1098e0172026;nsid=2017611789;c=1675343406013), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,807 INFO nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,818 INFO nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,898 INFO store.AbstractFSNodeStore: Created store directory :file:/tmp/hadoop-yarn-root/node-attribute\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,919 INFO store.AbstractFSNodeStore: Finished write mirror at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.mirror\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,920 INFO store.AbstractFSNodeStore: Finished create editlog file at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.editlog\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,931 INFO datanode.DataNode: Successfully sent block report 0x73529fd7e85cefea,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 174 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,932 INFO datanode.DataNode: Got finalize command for block pool BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,934 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$ForwardingEventHandler\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,934 INFO placement.MultiNodeSortingManager: Starting NodeSortingService=MultiNodeSortingManager\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,951 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,952 INFO ipc.Server: Starting Socket Reader #1 for port 8031\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,954 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,960 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:13,960 INFO ipc.Server: IPC Server listener on 8031: starting\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,603 INFO datanode.DataNode: Successfully sent block report 0xfeee21bd908a8d2c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 154 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:13,603 INFO datanode.DataNode: Got finalize command for block pool BP-679434436-10.0.127.243-1675343406013\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:14,388 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     cluster is up\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     transitioning from status BOOTSTRAPPING to WAITING\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     starting executor logs watcher\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     start log event log publisher\u001b[0m\n",
      "\u001b[34mStarting executor logs watcher on log_dir: /var/log/yarn\u001b[0m\n",
      "\u001b[34m02-02 13:10 sagemaker-spark-event-logs-publisher INFO     Start to copy the spark event logs file.\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     Waiting for hosts to bootstrap: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,165 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[34m02-02 13:10 sagemaker-spark-event-logs-publisher INFO     Writing event log config to spark-defaults.conf\u001b[0m\n",
      "\u001b[34m02-02 13:10 sagemaker-spark-event-logs-publisher INFO     Event log file does not exist.\u001b[0m\n",
      "\u001b[34m02-02 13:10 smspark-submit INFO     Received host statuses: dict_items([('algo-1', StatusMessage(status='WAITING', timestamp='2023-02-02T13:10:14.163141')), ('algo-2', StatusMessage(status='WAITING', timestamp='2023-02-02T13:10:14.166287'))])\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,170 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,176 INFO ipc.Server: Starting Socket Reader #1 for port 8030\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,196 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,212 INFO ipc.Server: IPC Server listener on 8030: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,217 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,434 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,435 INFO ipc.Server: Starting Socket Reader #1 for port 8032\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,438 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,462 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,462 INFO ipc.Server: IPC Server listener on 8032: starting\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,475 INFO resourcemanager.ResourceManager: Transitioned to active state\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,505 INFO resourcemanager.ResourceTrackerService: NodeManager from node algo-1(cmPort: 42563 httpPort: 8042) registered with capability: <memory:15892, vCores:4>, assigned nodeId algo-1:42563\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,507 INFO resourcemanager.ResourceTrackerService: NodeManager from node algo-2(cmPort: 43589 httpPort: 8042) registered with capability: <memory:15892, vCores:4>, assigned nodeId algo-2:43589\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,511 INFO rmnode.RMNodeImpl: algo-1:42563 Node Transitioned from NEW to RUNNING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,511 INFO rmnode.RMNodeImpl: algo-2:43589 Node Transitioned from NEW to RUNNING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,540 INFO security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1531615723\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,541 INFO security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -245449074\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,541 INFO nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as algo-1:42563 with total resource of <memory:15892, vCores:4>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,558 INFO capacity.CapacityScheduler: Added node algo-1:42563 clusterResource: <memory:15892, vCores:4>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:14,561 INFO capacity.CapacityScheduler: Added node algo-2:43589 clusterResource: <memory:31784, vCores:8>\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:14,539 INFO security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1531615723\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:14,540 INFO security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -245449074\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:14,540 INFO nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as algo-2:43589 with total resource of <memory:15892, vCores:4>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,852 INFO spark.SparkContext: Running Spark version 3.1.1-amzn-0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,894 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,894 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,894 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,895 INFO spark.SparkContext: Submitted application: processing.py\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,918 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 1239, script: , vendor: , cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 12399, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,931 INFO resource.ResourceProfile: Limiting resource is cpus at 4 tasks per executor\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,933 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,991 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,991 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,992 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,992 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:16,992 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,223 INFO util.Utils: Successfully started service 'sparkDriver' on port 42921.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,249 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,278 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,299 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,299 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,332 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,345 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-eb535ed5-59be-447b-9e8d-9f42532178ec\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,365 INFO memory.MemoryStore: MemoryStore started with capacity 1028.8 MiB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,400 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,499 INFO util.log: Logging initialized @2933ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,579 INFO server.Server: jetty-9.4.37.v20210219; built: 2021-02-19T15:16:47.689Z; git: 27afab2bd37780d179836e313e0fe11bc4fa0ce9; jvm 1.8.0_312-b07\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,602 INFO server.Server: Started @3037ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,636 INFO server.AbstractConnector: Started ServerConnector@3cd5f0c0{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,636 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,659 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2c34433c{/jobs,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,662 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57a04d07{/jobs/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,662 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7d0eb02f{/jobs/job,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,664 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e1dab59{/jobs/job/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,665 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@60e2bdae{/stages,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,665 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d657600{/stages/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,666 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@39bf9a27{/stages/stage,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,668 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18006e18{/stages/stage/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,669 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@731e2db6{/stages/pool,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,670 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6897784d{/stages/pool/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,671 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@376261ca{/storage,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,671 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72ca06de{/storage/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,672 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f7286c9{/storage/rdd,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,673 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1e9e62aa{/storage/rdd/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,674 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78043926{/environment,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,675 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ae500fb{/environment/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,676 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d1e7d4c{/executors,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,676 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65abea8f{/executors/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,677 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a05853b{/executors/threadDump,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,678 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1950b2a5{/executors/threadDump/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,687 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@ed5044{/static,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,687 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1d18e66a{/,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,689 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7e440fb{/api,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,689 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@25667cc4{/jobs/job/kill,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,690 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@28bdc209{/stages/stage/kill,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,692 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.127.243:4040\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:17,953 INFO client.RMProxy: Connecting to ResourceManager at /10.0.127.243:8032\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,270 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,310 INFO resourcemanager.ClientRMService: Allocated new applicationId: 1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,859 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,860 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,877 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (15892 MB per container)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,877 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,878 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,879 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,886 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:18,963 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:22,694 INFO yarn.Client: Uploading resource file:/tmp/spark-ed2ca6b2-1a51-4a82-b916-65a54de8b19a/__spark_libs__7287418884805699915.zip -> hdfs://10.0.127.243/user/root/.sparkStaging/application_1675343413375_0001/__spark_libs__7287418884805699915.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:24,338 INFO hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /user/root/.sparkStaging/application_1675343413375_0001/__spark_libs__7287418884805699915.zip\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:25,185 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741825_1001 src: /10.0.127.243:38836 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:25,120 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741825_1001 src: /10.0.127.243:50154 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:25,676 INFO DataNode.clienttrace: src: /10.0.127.243:50154, dest: /10.0.127.243:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741825_1001, duration(ns): 462573441\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:25,677 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:25,684 INFO hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /user/root/.sparkStaging/application_1675343413375_0001/__spark_libs__7287418884805699915.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:25,693 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741826_1002 src: /10.0.127.243:50170 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:25,672 INFO DataNode.clienttrace: src: /10.0.127.243:38836, dest: /10.0.73.224:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741825_1001, duration(ns): 464218110\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:25,672 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:25,695 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741826_1002 src: /10.0.127.243:38848 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:26,109 INFO DataNode.clienttrace: src: /10.0.127.243:38848, dest: /10.0.73.224:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741826_1002, duration(ns): 412034930\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:26,109 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:26,118 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741827_1003 src: /10.0.127.243:38850 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:26,110 INFO DataNode.clienttrace: src: /10.0.127.243:50170, dest: /10.0.127.243:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741826_1002, duration(ns): 405625676\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:26,110 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:26,113 INFO hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /user/root/.sparkStaging/application_1675343413375_0001/__spark_libs__7287418884805699915.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:26,116 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741827_1003 src: /10.0.127.243:50174 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:26,895 INFO DataNode.clienttrace: src: /10.0.127.243:50174, dest: /10.0.127.243:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741827_1003, duration(ns): 775035584\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:26,895 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:26,899 INFO hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /user/root/.sparkStaging/application_1675343413375_0001/__spark_libs__7287418884805699915.zip\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:26,893 INFO DataNode.clienttrace: src: /10.0.127.243:38850, dest: /10.0.73.224:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741827_1003, duration(ns): 773984613\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:26,893 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,403 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741828_1004 src: /10.0.127.243:38864 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,401 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741828_1004 src: /10.0.127.243:50176 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,553 INFO DataNode.clienttrace: src: /10.0.127.243:50176, dest: /10.0.127.243:9866, bytes: 46002121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741828_1004, duration(ns): 147693570\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,554 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,560 INFO hdfs.StateChange: DIR* completeFile: /user/root/.sparkStaging/application_1675343413375_0001/__spark_libs__7287418884805699915.zip is closed by DFSClient_NONMAPREDUCE_1716286353_18\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,675 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://10.0.127.243/user/root/.sparkStaging/application_1675343413375_0001/pyspark.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,690 INFO hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /user/root/.sparkStaging/application_1675343413375_0001/pyspark.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,696 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741829_1005 src: /10.0.127.243:50192 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,708 INFO DataNode.clienttrace: src: /10.0.127.243:50192, dest: /10.0.127.243:9866, bytes: 889814, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741829_1005, duration(ns): 3289746\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,709 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,711 INFO hdfs.StateChange: DIR* completeFile: /user/root/.sparkStaging/application_1675343413375_0001/pyspark.zip is closed by DFSClient_NONMAPREDUCE_1716286353_18\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,725 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.9-src.zip -> hdfs://10.0.127.243/user/root/.sparkStaging/application_1675343413375_0001/py4j-0.10.9-src.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,736 INFO hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /user/root/.sparkStaging/application_1675343413375_0001/py4j-0.10.9-src.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,740 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741830_1006 src: /10.0.127.243:50196 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,749 INFO DataNode.clienttrace: src: /10.0.127.243:50196, dest: /10.0.127.243:9866, bytes: 41587, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741830_1006, duration(ns): 3153832\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,750 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,751 INFO hdfs.StateChange: DIR* completeFile: /user/root/.sparkStaging/application_1675343413375_0001/py4j-0.10.9-src.zip is closed by DFSClient_NONMAPREDUCE_1716286353_18\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,880 INFO yarn.Client: Uploading resource file:/tmp/spark-ed2ca6b2-1a51-4a82-b916-65a54de8b19a/__spark_conf__4094333659110180555.zip -> hdfs://10.0.127.243/user/root/.sparkStaging/application_1675343413375_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,887 INFO hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /user/root/.sparkStaging/application_1675343413375_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,891 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741831_1007 src: /10.0.127.243:50200 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,898 INFO DataNode.clienttrace: src: /10.0.127.243:50200, dest: /10.0.127.243:9866, bytes: 266144, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741831_1007, duration(ns): 2547881\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,898 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,900 INFO hdfs.StateChange: DIR* completeFile: /user/root/.sparkStaging/application_1675343413375_0001/__spark_conf__.zip is closed by DFSClient_NONMAPREDUCE_1716286353_18\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,923 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,923 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,924 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,924 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,924 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:29,946 INFO yarn.Client: Submitting application application_1675343413375_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,024 INFO capacity.CapacityScheduler: Application 'application_1675343413375_0001' is submitted without priority hence considering default queue/cluster priority: 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,025 INFO capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,041 WARN rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 1]. Use the global max attempts instead.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,042 INFO resourcemanager.ClientRMService: Application with id 1 submitted by user root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,043 INFO rmapp.RMAppImpl: Storing application with id application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,045 INFO resourcemanager.RMAuditLogger: USER=root#011IP=10.0.127.243#011OPERATION=Submit Application Request#011TARGET=ClientRMService#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,051 INFO rmapp.RMAppImpl: application_1675343413375_0001 State change from NEW to NEW_SAVING on event = START\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,051 INFO recovery.RMStateStore: Storing info for app: application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,052 INFO rmapp.RMAppImpl: application_1675343413375_0001 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,053 INFO capacity.ParentQueue: Application added - appId: application_1675343413375_0001 user: root leaf-queue of parent: root #applications: 1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,054 INFO capacity.CapacityScheduler: Accepted application application_1675343413375_0001 from user: root, in queue: default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,065 INFO rmapp.RMAppImpl: application_1675343413375_0001 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,090 INFO resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,091 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from NEW to SUBMITTED on event = START\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,143 INFO impl.YarnClientImpl: Submitted application application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,165 INFO capacity.LeafQueue: Application application_1675343413375_0001 from user: root activated in queue: default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,165 INFO capacity.LeafQueue: Application added - appId: application_1675343413375_0001 user: root, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,165 INFO capacity.CapacityScheduler: Added Application Attempt appattempt_1675343413375_0001_000001 to scheduler from user root in queue default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,172 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,692 INFO allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1675343413375_0001_000001 container=null queue=default clusterResource=<memory:31784, vCores:8> type=OFF_SWITCH requestedPartition=\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,695 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000001 Container Transitioned from NEW to ALLOCATED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,696 INFO fica.FiCaSchedulerNode: Assigned container container_1675343413375_0001_01_000001 of capacity <memory:896, max memory:15892, vCores:1, max vCores:4> on host algo-1:42563, which has 1 containers, <memory:896, vCores:1> used and <memory:14996, vCores:3> available after allocation\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,696 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Allocated Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000001#011RESOURCE=<memory:896, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,719 INFO security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : algo-1:42563 for container : container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,727 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,728 INFO security.NMTokenSecretManagerInRM: Clear node set for appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,728 INFO attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1675343413375_0001 AttemptId: appattempt_1675343413375_0001_000001 MasterContainer: Container: [ContainerId: container_1675343413375_0001_01_000001, AllocationRequestId: -1, Version: 0, NodeId: algo-1:42563, NodeHttpAddress: algo-1:8042, Resource: <memory:896, max memory:15892, vCores:1, max vCores:4>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.0.127.243:42563 }, ExecutionType: GUARANTEED, ]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,728 INFO capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.028190285 absoluteUsedCapacity=0.028190285 used=<memory:896, vCores:1> cluster=<memory:31784, vCores:8>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,729 INFO capacity.CapacityScheduler: Allocation proposal accepted\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,739 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,743 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,758 INFO amlauncher.AMLauncher: Launching masterappattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,828 INFO amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1675343413375_0001_01_000001, AllocationRequestId: -1, Version: 0, NodeId: algo-1:42563, NodeHttpAddress: algo-1:8042, Resource: <memory:896, max memory:15892, vCores:1, max vCores:4>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.0.127.243:42563 }, ExecutionType: GUARANTEED, ] for AM appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,828 INFO security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:30,832 INFO security.AMRMTokenSecretManager: Creating password for appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,016 INFO ipc.Server: Auth successful for appattempt_1675343413375_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,147 INFO yarn.Client: Application report for application_1675343413375_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,153 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Thu Feb 02 13:10:30 +0000 2023] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1675343430041\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1675343413375_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,154 INFO containermanager.ContainerManagerImpl: Start request for container_1675343413375_0001_01_000001 by user root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,230 INFO containermanager.ContainerManagerImpl: Creating a new application reference for app application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,243 INFO application.ApplicationImpl: Application application_1675343413375_0001 transitioned from NEW to INITING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,243 INFO application.ApplicationImpl: Adding container_1675343413375_0001_01_000001 to application application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,244 INFO nodemanager.NMAuditLogger: USER=root#011IP=10.0.127.243#011OPERATION=Start Container Request#011TARGET=ContainerManageImpl#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,249 INFO application.ApplicationImpl: Application application_1675343413375_0001 transitioned from INITING to RUNNING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,259 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000001 transitioned from NEW to LOCALIZING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,259 INFO containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,262 INFO amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1675343413375_0001_01_000001, AllocationRequestId: -1, Version: 0, NodeId: algo-1:42563, NodeHttpAddress: algo-1:8042, Resource: <memory:896, max memory:15892, vCores:1, max vCores:4>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.0.127.243:42563 }, ExecutionType: GUARANTEED, ] for AM appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,263 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from ALLOCATED to LAUNCHED on event = LAUNCHED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,263 INFO rmapp.RMAppImpl: update the launch time for applicationId: application_1675343413375_0001, attemptId: appattempt_1675343413375_0001_000001launchTime: 1675343431262\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,264 INFO recovery.RMStateStore: Updating info for app: application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,271 INFO localizer.ResourceLocalizationService: Created localizer for container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,370 INFO localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-root/nm-local-dir/nmPrivate/container_1675343413375_0001_01_000001.tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,391 INFO nodemanager.DefaultContainerExecutor: Initializing user root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,398 INFO nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-root/nm-local-dir/nmPrivate/container_1675343413375_0001_01_000001.tokens to /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001.tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,398 INFO nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001 = file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:31,708 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:32,158 INFO yarn.Client: Application report for application_1675343413375_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:33,161 INFO yarn.Client: Application report for application_1675343413375_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,552 INFO DataNode.clienttrace: src: /10.0.127.243:38864, dest: /10.0.73.224:9866, bytes: 46002121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741828_1004, duration(ns): 147275816\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,552 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,698 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741829_1005 src: /10.0.127.243:38876 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,707 INFO DataNode.clienttrace: src: /10.0.127.243:38876, dest: /10.0.73.224:9866, bytes: 889814, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741829_1005, duration(ns): 7253529\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,707 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,742 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741830_1006 src: /10.0.127.243:38892 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,746 INFO DataNode.clienttrace: src: /10.0.127.243:38892, dest: /10.0.73.224:9866, bytes: 41587, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741830_1006, duration(ns): 2538382\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,746 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,893 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741831_1007 src: /10.0.127.243:38898 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,897 INFO DataNode.clienttrace: src: /10.0.127.243:38898, dest: /10.0.73.224:9866, bytes: 266144, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1716286353_18, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741831_1007, duration(ns): 2175496\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:29,897 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:34,164 INFO yarn.Client: Application report for application_1675343413375_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m02-02 13:10 sagemaker-spark-event-logs-publisher INFO     Event log file does not exist.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:34,871 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000001 transitioned from LOCALIZING to SCHEDULED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:34,872 INFO scheduler.ContainerScheduler: Starting container [container_1675343413375_0001_01_000001]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:34,901 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000001 transitioned from SCHEDULED to RUNNING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:34,901 INFO monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:34,905 INFO nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001/default_container_executor.sh]\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/prelaunch.out\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/prelaunch.err\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/launch_container.sh\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stdout\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:35,169 INFO yarn.Client: Application report for application_1675343413375_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] lrwxrwxrwx 1 root root   76 Feb  2 13:10 __spark_conf__ -> /tmp/hadoop-root/nm-local-dir/usercache/root/filecache/12/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] lrwxrwxrwx 1 root root   95 Feb  2 13:10 __spark_libs__ -> /tmp/hadoop-root/nm-local-dir/usercache/root/filecache/11/__spark_libs__7287418884805699915.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] -rw-r--r-- 1 root root   74 Feb  2 13:10 container_tokens\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] -rwx------ 1 root root  723 Feb  2 13:10 default_container_executor.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] -rwx------ 1 root root  668 Feb  2 13:10 default_container_executor_session.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] -rwx------ 1 root root 4835 Feb  2 13:10 launch_container.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] lrwxrwxrwx 1 root root   77 Feb  2 13:10 py4j-0.10.9-src.zip -> /tmp/hadoop-root/nm-local-dir/usercache/root/filecache/13/py4j-0.10.9-src.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] lrwxrwxrwx 1 root root   69 Feb  2 13:10 pyspark.zip -> /tmp/hadoop-root/nm-local-dir/usercache/root/filecache/10/pyspark.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] drwx--x--- 2 root root 4096 Feb  2 13:10 tmp\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] find -L . -maxdepth 5 -ls:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917837    4 drwx--x---   3 root     root         4096 Feb  2 13:10 .\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917839    4 drwx--x---   2 root     root         4096 Feb  2 13:10 ./tmp\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917840    4 -rw-r--r--   1 root     root           74 Feb  2 13:10 ./container_tokens\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917847    4 -rw-r--r--   1 root     root           16 Feb  2 13:10 ./.default_container_executor.sh.crc\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917845    4 -rw-r--r--   1 root     root           16 Feb  2 13:10 ./.default_container_executor_session.sh.crc\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917844    4 -rwx------   1 root     root          668 Feb  2 13:10 ./default_container_executor_session.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917829   44 -r-x------   1 root     root        41587 Feb  2 13:10 ./py4j-0.10.9-src.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917843    4 -rw-r--r--   1 root     root           48 Feb  2 13:10 ./.launch_container.sh.crc\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917515   20 drwx------   2 root     root        20480 Feb  2 13:10 ./__spark_libs__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917516   20 -r-x------   1 root     root        20409 Feb  2 13:10 ./__spark_libs__/kerb-simplekdc-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917517   28 -r-x------   1 root     root        27006 Feb  2 13:10 ./__spark_libs__/aopalliance-repackaged-2.6.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917518  164 -r-x------   1 root     root       166244 Feb  2 13:10 ./__spark_libs__/commons-crypto-1.1.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917519  304 -r-x------   1 root     root       309001 Feb  2 13:10 ./__spark_libs__/snakeyaml-1.26.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917520 5156 -r-x------   1 root     root      5276900 Feb  2 13:10 ./__spark_libs__/scala-library-2.12.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917521   20 -r-x------   1 root     root        18763 Feb  2 13:10 ./__spark_libs__/token-provider-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917522   28 -r-x------   1 root     root        25475 Feb  2 13:10 ./__spark_libs__/json-1.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917523  832 -r-x------   1 root     root       848783 Feb  2 13:10 ./__spark_libs__/parquet-encoding-1.10.1-spark-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917524   24 -r-x------   1 root     root        20889 Feb  2 13:10 ./__spark_libs__/metrics-jmx-4.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917525 1144 -r-x------   1 root     root      1168113 Feb  2 13:10 ./__spark_libs__/algebra_2.12-2.0.0-M2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917526  404 -r-x------   1 root     root       410874 Feb  2 13:10 ./__spark_libs__/kryo-shaded-4.0.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917527  128 -r-x------   1 root     root       127223 Feb  2 13:10 ./__spark_libs__/remotetea-oncrpc-1.1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917528  908 -r-x------   1 root     root       927721 Feb  2 13:10 ./__spark_libs__/jersey-server-2.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917529  112 -r-x------   1 root     root       110600 Feb  2 13:10 ./__spark_libs__/bonecp-0.8.0.RELEASE.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917530   64 -r-x------   1 root     root        61835 Feb  2 13:10 ./__spark_libs__/spark-kvstore_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917531  344 -r-x------   1 root     root       349059 Feb  2 13:10 ./__spark_libs__/json4s-scalap_2.12-3.7.0-M5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917532    4 -r-x------   1 root     root         3180 Feb  2 13:10 ./__spark_libs__/macro-compat_2.12-1.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917533  420 -r-x------   1 root     root       427674 Feb  2 13:10 ./__spark_libs__/okhttp-3.12.12.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917534 2368 -r-x------   1 root     root      2423157 Feb  2 13:10 ./__spark_libs__/curator-client-2.13.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917535  992 -r-x------   1 root     root      1013367 Feb  2 13:10 ./__spark_libs__/jaxb-runtime-2.3.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917536   92 -r-x------   1 root     root        93210 Feb  2 13:10 ./__spark_libs__/super-csv-2.2.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917537    8 -r-x------   1 root     root         5711 Feb  2 13:10 ./__spark_libs__/minlog-1.3.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917538  280 -r-x------   1 root     root       284184 Feb  2 13:10 ./__spark_libs__/commons-codec-1.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917539 4080 -r-x------   1 root     root      4175105 Feb  2 13:10 ./__spark_libs__/hadoop-common-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917540  132 -r-x------   1 root     root       131590 Feb  2 13:10 ./__spark_libs__/hk2-utils-2.6.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917541  232 -r-x------   1 root     root       236660 Feb  2 13:10 ./__spark_libs__/ST4-4.0.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917542  244 -r-x------   1 root     root       246445 Feb  2 13:10 ./__spark_libs__/libthrift-0.12.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917543 1688 -r-x------   1 root     root      1726527 Feb  2 13:10 ./__spark_libs__/ehcache-3.3.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917544 10424 -r-x------   1 root     root     10672015 Feb  2 13:10 ./__spark_libs__/scala-compiler-2.12.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917545 1468 -r-x------   1 root     root      1502280 Feb  2 13:10 ./__spark_libs__/htrace-core4-4.1.0-incubating.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917546 10640 -r-x------   1 root     root     10892246 Feb  2 13:10 ./__spark_libs__/hive-exec-2.3.7-amzn-4-core.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917547   20 -r-x------   1 root     root        19827 Feb  2 13:10 ./__spark_libs__/opencsv-2.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917548  120 -r-x------   1 root     root       121048 Feb  2 13:10 ./__spark_libs__/hive-shims-common-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917549  268 -r-x------   1 root     root       273370 Feb  2 13:10 ./__spark_libs__/commons-net-3.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917550  280 -r-x------   1 root     root       284220 Feb  2 13:10 ./__spark_libs__/commons-lang-2.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917792  492 -r-x------   1 root     root       501704 Feb  2 13:10 ./__spark_libs__/hadoop-aws-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917551   32 -r-x------   1 root     root        30517 Feb  2 13:10 ./__spark_libs__/spark-sketch_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917552 7020 -r-x------   1 root     root      7188024 Feb  2 13:10 ./__spark_libs__/spire_2.12-0.17.0-M1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917553  136 -r-x------   1 root     root       136363 Feb  2 13:10 ./__spark_libs__/HikariCP-2.5.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917554 6012 -r-x------   1 root     root      6154474 Feb  2 13:10 ./__spark_libs__/spark-mllib_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917555  196 -r-x------   1 root     root       197176 Feb  2 13:10 ./__spark_libs__/commons-text-1.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917556 1456 -r-x------   1 root     root      1489507 Feb  2 13:10 ./__spark_libs__/netlib-native_ref-linux-i686-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917557   40 -r-x------   1 root     root        39931 Feb  2 13:10 ./__spark_libs__/arrow-memory-netty-2.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917558   32 -r-x------   1 root     root        30035 Feb  2 13:10 ./__spark_libs__/accessors-smart-1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917559 1524 -r-x------   1 root     root      1556863 Feb  2 13:10 ./__spark_libs__/avro-1.8.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917560 2864 -r-x------   1 root     root      2929005 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-common-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917561   12 -r-x------   1 root     root         9928 Feb  2 13:10 ./__spark_libs__/spark-tags_2.12-3.1.1-amzn-0-tests.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917562  780 -r-x------   1 root     root       796532 Feb  2 13:10 ./__spark_libs__/bcpkix-jdk15on-1.60.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917563   16 -r-x------   1 root     root        15071 Feb  2 13:10 ./__spark_libs__/transaction-api-1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917564  132 -r-x------   1 root     root       132989 Feb  2 13:10 ./__spark_libs__/avro-ipc-1.8.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917565   76 -r-x------   1 root     root        76983 Feb  2 13:10 ./__spark_libs__/guice-servlet-4.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917566   20 -r-x------   1 root     root        16642 Feb  2 13:10 ./__spark_libs__/metrics-json-4.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917793  160 -r-x------   1 root     root       159755 Feb  2 13:10 ./__spark_libs__/aws-glue-datacatalog-hive3-client-3.2.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917567  788 -r-x------   1 root     root       805850 Feb  2 13:10 ./__spark_libs__/hadoop-mapreduce-client-common-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917568  432 -r-x------   1 root     root       439465 Feb  2 13:10 ./__spark_libs__/hive-common-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917569 1784 -r-x------   1 root     root      1826785 Feb  2 13:10 ./__spark_libs__/netlib-native_ref-win-i686-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917570    8 -r-x------   1 root     root         4467 Feb  2 13:10 ./__spark_libs__/aopalliance-1.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917571 4092 -r-x------   1 root     root      4189874 Feb  2 13:10 ./__spark_libs__/bcprov-jdk15on-1.60.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917572  176 -r-x------   1 root     root       176285 Feb  2 13:10 ./__spark_libs__/automaton-1.11-8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917573  128 -r-x------   1 root     root       128414 Feb  2 13:10 ./__spark_libs__/re2j-1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917574  196 -r-x------   1 root     root       200223 Feb  2 13:10 ./__spark_libs__/hk2-api-2.6.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917575  552 -r-x------   1 root     root       561459 Feb  2 13:10 ./__spark_libs__/netlib-native_system-win-i686-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917576   12 -r-x------   1 root     root        12131 Feb  2 13:10 ./__spark_libs__/jpam-1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917577  116 -r-x------   1 root     root       115498 Feb  2 13:10 ./__spark_libs__/jakarta.xml.bind-api-2.3.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917578   76 -r-x------   1 root     root        76733 Feb  2 13:10 ./__spark_libs__/jersey-hk2-2.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917579   48 -r-x------   1 root     root        46781 Feb  2 13:10 ./__spark_libs__/jackson-dataformat-yaml-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917580  164 -r-x------   1 root     root       164422 Feb  2 13:10 ./__spark_libs__/core-1.1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917581   32 -r-x------   1 root     root        32091 Feb  2 13:10 ./__spark_libs__/jersey-container-servlet-2.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917582   24 -r-x------   1 root     root        22042 Feb  2 13:10 ./__spark_libs__/metrics-graphite-4.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917794  152 -r-x------   1 root     root       153385 Feb  2 13:10 ./__spark_libs__/aws-glue-datacatalog-spark-client-3.2.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917583  164 -r-x------   1 root     root       167761 Feb  2 13:10 ./__spark_libs__/antlr-runtime-3.5.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917584   20 -r-x------   1 root     root        16537 Feb  2 13:10 ./__spark_libs__/jcl-over-slf4j-1.7.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917585  100 -r-x------   1 root     root       100431 Feb  2 13:10 ./__spark_libs__/pyrolite-4.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917586  360 -r-x------   1 root     root       366748 Feb  2 13:10 ./__spark_libs__/datanucleus-api-jdo-4.2.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917587  316 -r-x------   1 root     root       323162 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-client-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917588   52 -r-x------   1 root     root        52877 Feb  2 13:10 ./__spark_libs__/spark-repl_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917589   72 -r-x------   1 root     root        73349 Feb  2 13:10 ./__spark_libs__/jersey-container-servlet-core-2.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917590   12 -r-x------   1 root     root        10486 Feb  2 13:10 ./__spark_libs__/hive-shims-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917591  224 -r-x------   1 root     root       226672 Feb  2 13:10 ./__spark_libs__/kerb-core-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917592  796 -r-x------   1 root     root       814000 Feb  2 13:10 ./__spark_libs__/orc-core-1.5.12.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917593   68 -r-x------   1 root     root        69409 Feb  2 13:10 ./__spark_libs__/activation-1.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917594 1256 -r-x------   1 root     root      1282424 Feb  2 13:10 ./__spark_libs__/ivy-2.4.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917595  576 -r-x------   1 root     root       588337 Feb  2 13:10 ./__spark_libs__/commons-collections-3.2.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917596 10008 -r-x------   1 root     root     10247828 Feb  2 13:10 ./__spark_libs__/spark-catalyst_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917597 2140 -r-x------   1 root     root      2189117 Feb  2 13:10 ./__spark_libs__/guava-14.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917598  180 -r-x------   1 root     root       184274 Feb  2 13:10 ./__spark_libs__/hive-beeline-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917599   36 -r-x------   1 root     root        34998 Feb  2 13:10 ./__spark_libs__/jackson-module-jaxb-annotations-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917600   56 -r-x------   1 root     root        55684 Feb  2 13:10 ./__spark_libs__/objenesis-2.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917601   20 -r-x------   1 root     root        18497 Feb  2 13:10 ./__spark_libs__/flatbuffers-java-1.9.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917602   84 -r-x------   1 root     root        85904 Feb  2 13:10 ./__spark_libs__/hadoop-mapreduce-client-jobclient-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917603 3152 -r-x------   1 root     root      3224708 Feb  2 13:10 ./__spark_libs__/derby-10.12.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917604   32 -r-x------   1 root     root        30674 Feb  2 13:10 ./__spark_libs__/kerby-config-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917605 1712 -r-x------   1 root     root      1749371 Feb  2 13:10 ./__spark_libs__/netlib-native_ref-linux-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917606   28 -r-x------   1 root     root        27755 Feb  2 13:10 ./__spark_libs__/orc-shims-1.5.12.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917607    4 -r-x------   1 root     root         2500 Feb  2 13:10 ./__spark_libs__/shims-0.9.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917608   44 -r-x------   1 root     root        41472 Feb  2 13:10 ./__spark_libs__/slf4j-api-1.7.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917609  624 -r-x------   1 root     root       637428 Feb  2 13:10 ./__spark_libs__/netlib-native_system-win-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917610  176 -r-x------   1 root     root       178149 Feb  2 13:10 ./__spark_libs__/stream-2.9.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917611   16 -r-x------   1 root     root        15071 Feb  2 13:10 ./__spark_libs__/jta-1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917612   36 -r-x------   1 root     root        33786 Feb  2 13:10 ./__spark_libs__/machinist_2.12-0.6.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917613  504 -r-x------   1 root     root       512151 Feb  2 13:10 ./__spark_libs__/json4s-core_2.12-3.7.0-M5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917614   16 -r-x------   1 root     root        12483 Feb  2 13:10 ./__spark_libs__/logging-interceptor-3.12.12.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917795  116 -r-x------   1 root     root       116694 Feb  2 13:10 ./__spark_libs__/aws-glue-datacatalog-client-common-3.2.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917615 1924 -r-x------   1 root     root      1969177 Feb  2 13:10 ./__spark_libs__/snappy-java-1.1.8.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917616  100 -r-x------   1 root     root        99555 Feb  2 13:10 ./__spark_libs__/xz-1.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917617  112 -r-x------   1 root     root       111007 Feb  2 13:10 ./__spark_libs__/jackson-datatype-jsr310-2.11.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917618  532 -r-x------   1 root     root       542288 Feb  2 13:10 ./__spark_libs__/spark-hive-thriftserver_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917619   36 -r-x------   1 root     root        34654 Feb  2 13:10 ./__spark_libs__/paranamer-2.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917620  200 -r-x------   1 root     root       201965 Feb  2 13:10 ./__spark_libs__/curator-framework-2.13.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917621  204 -r-x------   1 root     root       208700 Feb  2 13:10 ./__spark_libs__/commons-io-2.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917622   36 -r-x------   1 root     root        35943 Feb  2 13:10 ./__spark_libs__/json4s-jackson_2.12-3.7.0-M5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917623   12 -r-x------   1 root     root         8261 Feb  2 13:10 ./__spark_libs__/spire-platform_2.12-0.17.0-M1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917624   36 -r-x------   1 root     root        35518 Feb  2 13:10 ./__spark_libs__/zjsonpatch-0.3.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917625 1376 -r-x------   1 root     root      1404939 Feb  2 13:10 ./__spark_libs__/jackson-databind-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917626   16 -r-x------   1 root     root        15171 Feb  2 13:10 ./__spark_libs__/spark-tags_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917627   28 -r-x------   1 root     root        28313 Feb  2 13:10 ./__spark_libs__/spark-ganglia-lgpl_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917628 3152 -r-x------   1 root     root      3226851 Feb  2 13:10 ./__spark_libs__/cats-kernel_2.12-2.0.0-M4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917629  112 -r-x------   1 root     root       112235 Feb  2 13:10 ./__spark_libs__/scala-collection-compat_2.12-2.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917630 1152 -r-x------   1 root     root      1175798 Feb  2 13:10 ./__spark_libs__/JTransforms-3.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917631   72 -r-x------   1 root     root        71626 Feb  2 13:10 ./__spark_libs__/commons-compiler-3.0.16.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917632 1632 -r-x------   1 root     root      1669989 Feb  2 13:10 ./__spark_libs__/hadoop-mapreduce-client-core-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917633   56 -r-x------   1 root     root        55236 Feb  2 13:10 ./__spark_libs__/geronimo-jcache_1.0_spec-1.0-alpha-1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917634   56 -r-x------   1 root     root        54461 Feb  2 13:10 ./__spark_libs__/native_ref-java-1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917635  140 -r-x------   1 root     root       140376 Feb  2 13:10 ./__spark_libs__/jakarta.ws.rs-api-2.1.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917636   16 -r-x------   1 root     root        15935 Feb  2 13:10 ./__spark_libs__/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917637   44 -r-x------   1 root     root        44513 Feb  2 13:10 ./__spark_libs__/gmetric4j-1.0.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917638  424 -r-x------   1 root     root       431100 Feb  2 13:10 ./__spark_libs__/spark-graphx_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917639   16 -r-x------   1 root     root        15562 Feb  2 13:10 ./__spark_libs__/jackson-jaxrs-json-provider-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917640   16 -r-x------   1 root     root        13942 Feb  2 13:10 ./__spark_libs__/hive-shims-scheduler-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917641  244 -r-x------   1 root     root       249790 Feb  2 13:10 ./__spark_libs__/javax.jdo-3.2.0-m3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917642  324 -r-x------   1 root     root       331034 Feb  2 13:10 ./__spark_libs__/okhttp-2.7.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917643  344 -r-x------   1 root     root       349331 Feb  2 13:10 ./__spark_libs__/jackson-core-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917644   28 -r-x------   1 root     root        26514 Feb  2 13:10 ./__spark_libs__/stax-api-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917645   36 -r-x------   1 root     root        34392 Feb  2 13:10 ./__spark_libs__/jetty-rewrite-9.3.27.v20190418.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917646   64 -r-x------   1 root     root        65464 Feb  2 13:10 ./__spark_libs__/kerb-common-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917647   56 -r-x------   1 root     root        56951 Feb  2 13:10 ./__spark_libs__/hive-shims-0.23-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917648   96 -r-x------   1 root     root        95806 Feb  2 13:10 ./__spark_libs__/javax.servlet-api-3.1.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917649   84 -r-x------   1 root     root        85815 Feb  2 13:10 ./__spark_libs__/jersey-media-jaxb-2.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917650 1116 -r-x------   1 root     root      1141204 Feb  2 13:10 ./__spark_libs__/spark-streaming_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917796  160 -r-x------   1 root     root       159755 Feb  2 13:10 ./__spark_libs__/aws-glue-datacatalog-hive3-client.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917651 6260 -r-x------   1 root     root      6407352 Feb  2 13:10 ./__spark_libs__/zstd-jni-1.4.8-1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917652 1972 -r-x------   1 root     root      2016766 Feb  2 13:10 ./__spark_libs__/datanucleus-core-4.1.17.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917653  764 -r-x------   1 root     root       780664 Feb  2 13:10 ./__spark_libs__/jackson-mapper-asl-1.9.13.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917654   80 -r-x------   1 root     root        79845 Feb  2 13:10 ./__spark_libs__/compress-lzf-1.0.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917655   24 -r-x------   1 root     root        23909 Feb  2 13:10 ./__spark_libs__/metrics-jvm-4.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917656  708 -r-x------   1 root     root       723203 Feb  2 13:10 ./__spark_libs__/parquet-format-2.4.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917657   16 -r-x------   1 root     root        14395 Feb  2 13:10 ./__spark_libs__/generex-1.0.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917658  320 -r-x------   1 root     root       326874 Feb  2 13:10 ./__spark_libs__/httpcore-4.4.11.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917659  200 -r-x------   1 root     root       203358 Feb  2 13:10 ./__spark_libs__/hk2-locator-2.6.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917660  544 -r-x------   1 root     root       556575 Feb  2 13:10 ./__spark_libs__/scala-xml_2.12-1.2.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917661   80 -r-x------   1 root     root        80980 Feb  2 13:10 ./__spark_libs__/kerb-admin-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917662   92 -r-x------   1 root     root        91930 Feb  2 13:10 ./__spark_libs__/jakarta.validation-api-2.0.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917663  428 -r-x------   1 root     root       435365 Feb  2 13:10 ./__spark_libs__/netlib-native_system-linux-i686-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917664   44 -r-x------   1 root     root        44399 Feb  2 13:10 ./__spark_libs__/jakarta.activation-api-1.2.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917665 10504 -r-x------   1 root     root     10752238 Feb  2 13:10 ./__spark_libs__/spark-core_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917666 1800 -r-x------   1 root     root      1839499 Feb  2 13:10 ./__spark_libs__/netlib-native_ref-osx-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917667   56 -r-x------   1 root     root        54509 Feb  2 13:10 ./__spark_libs__/native_system-java-1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917668  160 -r-x------   1 root     root       161867 Feb  2 13:10 ./__spark_libs__/stax2-api-3.1.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917669 7948 -r-x------   1 root     root      8135275 Feb  2 13:10 ./__spark_libs__/spark-sql_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917670  332 -r-x------   1 root     root       337869 Feb  2 13:10 ./__spark_libs__/antlr4-runtime-4.8-1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917671  128 -r-x------   1 root     root       127582 Feb  2 13:10 ./__spark_libs__/spark-network-shuffle_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917672    4 -r-x------   1 root     root         2497 Feb  2 13:10 ./__spark_libs__/javax.inject-1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917673  356 -r-x------   1 root     root       363074 Feb  2 13:10 ./__spark_libs__/spark-yarn_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917674 2348 -r-x------   1 root     root      2400610 Feb  2 13:10 ./__spark_libs__/spark-network-common_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917675  420 -r-x------   1 root     root       427780 Feb  2 13:10 ./__spark_libs__/jodd-core-3.5.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917676   84 -r-x------   1 root     root        82872 Feb  2 13:10 ./__spark_libs__/jakarta.servlet-api-4.0.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917677  100 -r-x------   1 root     root       102244 Feb  2 13:10 ./__spark_libs__/jaxb-api-2.2.11.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917678  228 -r-x------   1 root     root       232248 Feb  2 13:10 ./__spark_libs__/jackson-core-asl-1.9.13.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917679 13504 -r-x------   1 root     root     13826799 Feb  2 13:10 ./__spark_libs__/breeze_2.12-1.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917680   12 -r-x------   1 root     root        12211 Feb  2 13:10 ./__spark_libs__/slf4j-log4j12-1.7.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917681  760 -r-x------   1 root     root       774384 Feb  2 13:10 ./__spark_libs__/httpclient-4.5.9.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917682   40 -r-x------   1 root     root        40554 Feb  2 13:10 ./__spark_libs__/kerby-util-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917683 1140 -r-x------   1 root     root      1166647 Feb  2 13:10 ./__spark_libs__/jersey-common-2.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917684   36 -r-x------   1 root     root        33205 Feb  2 13:10 ./__spark_libs__/jackson-jaxrs-base-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917685 3168 -r-x------   1 root     root      3243337 Feb  2 13:10 ./__spark_libs__/shapeless_2.12-2.3.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917686   84 -r-x------   1 root     root        85865 Feb  2 13:10 ./__spark_libs__/json4s-ast_2.12-3.7.0-M5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917687 1168 -r-x------   1 root     root      1194003 Feb  2 13:10 ./__spark_libs__/arpack_combined_all-0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917688  304 -r-x------   1 root     root       310891 Feb  2 13:10 ./__spark_libs__/netlib-native_system-linux-armhf-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917689  232 -r-x------   1 root     root       236672 Feb  2 13:10 ./__spark_libs__/hive-storage-api-2.7.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917690  304 -r-x------   1 root     root       307637 Feb  2 13:10 ./__spark_libs__/dnsjava-2.1.7.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917691   96 -r-x------   1 root     root        96221 Feb  2 13:10 ./__spark_libs__/commons-pool-1.5.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917692  908 -r-x------   1 root     root       926574 Feb  2 13:10 ./__spark_libs__/janino-3.0.16.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917693   48 -r-x------   1 root     root        48202 Feb  2 13:10 ./__spark_libs__/orc-mapreduce-1.5.12.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917694  228 -r-x------   1 root     root       232470 Feb  2 13:10 ./__spark_libs__/JLargeArrays-1.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917695  240 -r-x------   1 root     root       244502 Feb  2 13:10 ./__spark_libs__/jersey-client-2.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917696  284 -r-x------   1 root     root       290168 Feb  2 13:10 ./__spark_libs__/parquet-hadoop-1.10.1-spark-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917697  116 -r-x------   1 root     root       117920 Feb  2 13:10 ./__spark_libs__/hive-jdbc-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917698 1024 -r-x------   1 root     root      1048529 Feb  2 13:10 ./__spark_libs__/parquet-jackson-1.10.1-spark-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917699  388 -r-x------   1 root     root       395195 Feb  2 13:10 ./__spark_libs__/javolution-5.5.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917797 211800 -r-x------   1 root     root     216879203 Feb  2 13:10 ./__spark_libs__/aws-java-sdk-bundle-1.11.977.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917700   36 -r-x------   1 root     root        36708 Feb  2 13:10 ./__spark_libs__/kerb-util-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917701 1480 -r-x------   1 root     root      1515244 Feb  2 13:10 ./__spark_libs__/zookeeper-3.4.14.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917702  136 -r-x------   1 root     root       139121 Feb  2 13:10 ./__spark_libs__/hadoop-auth-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917703 1672 -r-x------   1 root     root      1711185 Feb  2 13:10 ./__spark_libs__/arrow-vector-2.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917704  120 -r-x------   1 root     root       120316 Feb  2 13:10 ./__spark_libs__/json-smart-2.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917798  152 -r-x------   1 root     root       153385 Feb  2 13:10 ./__spark_libs__/aws-glue-datacatalog-spark-client.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917705 1180 -r-x------   1 root     root      1208080 Feb  2 13:10 ./__spark_libs__/netlib-native_ref-linux-armhf-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917706   64 -r-x------   1 root     root        62050 Feb  2 13:10 ./__spark_libs__/commons-logging-1.1.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917707   28 -r-x------   1 root     root        27156 Feb  2 13:10 ./__spark_libs__/istack-commons-runtime-3.0.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917708 3596 -r-x------   1 root     root      3678534 Feb  2 13:10 ./__spark_libs__/scala-reflect-2.12.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917709 1988 -r-x------   1 root     root      2035066 Feb  2 13:10 ./__spark_libs__/commons-math3-3.4.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917710   96 -r-x------   1 root     root        95171 Feb  2 13:10 ./__spark_libs__/parquet-common-1.10.1-spark-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917711   80 -r-x------   1 root     root        79588 Feb  2 13:10 ./__spark_libs__/spire-macros_2.12-0.17.0-M1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917712  132 -r-x------   1 root     root       134044 Feb  2 13:10 ./__spark_libs__/aircompressor-0.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917713  480 -r-x------   1 root     root       489884 Feb  2 13:10 ./__spark_libs__/log4j-1.2.17.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917714 1864 -r-x------   1 root     root      1908681 Feb  2 13:10 ./__spark_libs__/datanucleus-rdbms-4.1.19.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917715  100 -r-x------   1 root     root       100636 Feb  2 13:10 ./__spark_libs__/jsp-api-2.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917716  308 -r-x------   1 root     root       313702 Feb  2 13:10 ./__spark_libs__/libfb303-0.9.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917717  504 -r-x------   1 root     root       512742 Feb  2 13:10 ./__spark_libs__/woodstox-core-5.0.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917718   80 -r-x------   1 root     root        81406 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917719   20 -r-x------   1 root     root        18140 Feb  2 13:10 ./__spark_libs__/jakarta.inject-2.6.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917720  336 -r-x------   1 root     root       342143 Feb  2 13:10 ./__spark_libs__/jackson-module-scala_2.12-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917721   44 -r-x------   1 root     root        41123 Feb  2 13:10 ./__spark_libs__/commons-cli-1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917722  104 -r-x------   1 root     root       105365 Feb  2 13:10 ./__spark_libs__/metrics-core-4.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917723   44 -r-x------   1 root     root        43743 Feb  2 13:10 ./__spark_libs__/jackson-module-paranamer-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917724 1076 -r-x------   1 root     root      1098935 Feb  2 13:10 ./__spark_libs__/parquet-column-1.10.1-spark-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917725  116 -r-x------   1 root     root       115371 Feb  2 13:10 ./__spark_libs__/spark-mllib-local_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917726    8 -r-x------   1 root     root         4592 Feb  2 13:10 ./__spark_libs__/jul-to-slf4j-1.7.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917727 5008 -r-x------   1 root     root      5127896 Feb  2 13:10 ./__spark_libs__/hadoop-hdfs-client-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917728 8084 -r-x------   1 root     root      8274798 Feb  2 13:10 ./__spark_libs__/hive-metastore-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917729 4120 -r-x------   1 root     root      4216895 Feb  2 13:10 ./__spark_libs__/netty-all-4.1.51.Final.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917730   28 -r-x------   1 root     root        25058 Feb  2 13:10 ./__spark_libs__/jakarta.annotation-api-1.3.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917731  124 -r-x------   1 root     root       123052 Feb  2 13:10 ./__spark_libs__/py4j-0.10.9.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917732  276 -r-x------   1 root     root       281356 Feb  2 13:10 ./__spark_libs__/xbean-asm7-shaded-4.15.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917733   72 -r-x------   1 root     root        72668 Feb  2 13:10 ./__spark_libs__/arrow-format-2.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917734  604 -r-x------   1 root     root       616888 Feb  2 13:10 ./__spark_libs__/commons-configuration2-2.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917735  380 -r-x------   1 root     root       386529 Feb  2 13:10 ./__spark_libs__/RoaringBitmap-0.9.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917736  628 -r-x------   1 root     root       643043 Feb  2 13:10 ./__spark_libs__/joda-time-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917737   44 -r-x------   1 root     root        44168 Feb  2 13:10 ./__spark_libs__/hadoop-client-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917738   20 -r-x------   1 root     root        20046 Feb  2 13:10 ./__spark_libs__/kerb-identity-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917739  224 -r-x------   1 root     root       226000 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-registry-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917740 1644 -r-x------   1 root     root      1679364 Feb  2 13:10 ./__spark_libs__/hive-service-rpc-3.1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917741  208 -r-x------   1 root     root       211523 Feb  2 13:10 ./__spark_libs__/chill_2.12-0.9.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917742  220 -r-x------   1 root     root       222980 Feb  2 13:10 ./__spark_libs__/scala-parser-combinators_2.12-1.1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917743   76 -r-x------   1 root     root        76928 Feb  2 13:10 ./__spark_libs__/spark-launcher_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917744  232 -r-x------   1 root     root       233745 Feb  2 13:10 ./__spark_libs__/threeten-extra-1.5.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917745  100 -r-x------   1 root     root       102174 Feb  2 13:10 ./__spark_libs__/kerby-asn1-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917746  132 -r-x------   1 root     root       134696 Feb  2 13:10 ./__spark_libs__/breeze-macros_2.12-1.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917747   60 -r-x------   1 root     root        60263 Feb  2 13:10 ./__spark_libs__/hadoop-annotations-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917748   36 -r-x------   1 root     root        33031 Feb  2 13:10 ./__spark_libs__/jsr305-3.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917749  160 -r-x------   1 root     root       160519 Feb  2 13:10 ./__spark_libs__/commons-dbcp-1.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917750  448 -r-x------   1 root     root       458605 Feb  2 13:10 ./__spark_libs__/netlib-native_system-linux-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917751 3216 -r-x------   1 root     root      3290504 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-api-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917752  764 -r-x------   1 root     root       780265 Feb  2 13:10 ./__spark_libs__/javassist-3.25.0-GA.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917753   20 -r-x------   1 root     root        19479 Feb  2 13:10 ./__spark_libs__/osgi-resource-locator-1.0.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917754   52 -r-x------   1 root     root        51568 Feb  2 13:10 ./__spark_libs__/spark-unsafe_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917755  200 -r-x------   1 root     root       201124 Feb  2 13:10 ./__spark_libs__/jdo-api-3.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917756  440 -r-x------   1 root     root       447005 Feb  2 13:10 ./__spark_libs__/univocity-parsers-2.9.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917757   64 -r-x------   1 root     root        65261 Feb  2 13:10 ./__spark_libs__/oro-2.0.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917758  264 -r-x------   1 root     root       268780 Feb  2 13:10 ./__spark_libs__/jline-2.14.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917759  320 -r-x------   1 root     root       327605 Feb  2 13:10 ./__spark_libs__/hive-llap-common-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917760   84 -r-x------   1 root     root        82756 Feb  2 13:10 ./__spark_libs__/kerb-server-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917761   84 -r-x------   1 root     root        85756 Feb  2 13:10 ./__spark_libs__/okio-1.14.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917762  688 -r-x------   1 root     root       703130 Feb  2 13:10 ./__spark_libs__/spark-hive_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917763  116 -r-x------   1 root     root       116120 Feb  2 13:10 ./__spark_libs__/kerb-crypto-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917764  188 -r-x------   1 root     root       190432 Feb  2 13:10 ./__spark_libs__/gson-2.2.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917765    8 -r-x------   1 root     root         4722 Feb  2 13:10 ./__spark_libs__/jcip-annotations-1.0-1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917766  244 -r-x------   1 root     root       246918 Feb  2 13:10 ./__spark_libs__/commons-beanutils-1.9.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917767  524 -r-x------   1 root     root       533455 Feb  2 13:10 ./__spark_libs__/protobuf-java-2.5.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917768 1024 -r-x------   1 root     root      1045744 Feb  2 13:10 ./__spark_libs__/leveldbjni-all-1.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917769   40 -r-x------   1 root     root        38365 Feb  2 13:10 ./__spark_libs__/hive-vector-code-gen-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917770  184 -r-x------   1 root     root       187052 Feb  2 13:10 ./__spark_libs__/avro-mapred-1.8.2-hadoop2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917771  100 -r-x------   1 root     root       100990 Feb  2 13:10 ./__spark_libs__/arrow-memory-core-2.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917772  620 -r-x------   1 root     root       632424 Feb  2 13:10 ./__spark_libs__/commons-compress-1.20.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917773  280 -r-x------   1 root     root       283653 Feb  2 13:10 ./__spark_libs__/curator-recipes-2.13.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917774  900 -r-x------   1 root     root       919285 Feb  2 13:10 ./__spark_libs__/hive-serde-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917775 1364 -r-x------   1 root     root      1393617 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-server-common-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917776  544 -r-x------   1 root     root       553993 Feb  2 13:10 ./__spark_libs__/netlib-native_system-osx-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917777  656 -r-x------   1 root     root       668235 Feb  2 13:10 ./__spark_libs__/guice-4.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917778  636 -r-x------   1 root     root       649950 Feb  2 13:10 ./__spark_libs__/lz4-java-1.7.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917779  112 -r-x------   1 root     root       113017 Feb  2 13:10 ./__spark_libs__/kerb-client-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917780   68 -r-x------   1 root     root        68080 Feb  2 13:10 ./__spark_libs__/jackson-annotations-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917781   36 -r-x------   1 root     root        34601 Feb  2 13:10 ./__spark_libs__/spire-util_2.12-0.17.0-M1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917782   60 -r-x------   1 root     root        58684 Feb  2 13:10 ./__spark_libs__/chill-java-0.9.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917783   24 -r-x------   1 root     root        24239 Feb  2 13:10 ./__spark_libs__/commons-daemon-1.0.13.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917784  512 -r-x------   1 root     root       523372 Feb  2 13:10 ./__spark_libs__/commons-lang3-3.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917785   32 -r-x------   1 root     root        29134 Feb  2 13:10 ./__spark_libs__/kerby-xdr-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917786  384 -r-x------   1 root     root       392124 Feb  2 13:10 ./__spark_libs__/velocity-1.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917787   48 -r-x------   1 root     root        46219 Feb  2 13:10 ./__spark_libs__/hive-cli-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917788 2252 -r-x------   1 root     root      2305169 Feb  2 13:10 ./__spark_libs__/netlib-native_ref-win-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917789   12 -r-x------   1 root     root         8685 Feb  2 13:10 ./__spark_libs__/jniloader-1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917790  200 -r-x------   1 root     root       204650 Feb  2 13:10 ./__spark_libs__/kerby-pkix-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917791  296 -r-x------   1 root     root       299508 Feb  2 13:10 ./__spark_libs__/nimbus-jose-jwt-4.41.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917511  872 -r-x------   1 root     root       889814 Feb  2 13:10 ./pyspark.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917842    8 -rwx------   1 root     root         4835 Feb  2 13:10 ./launch_container.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917800    4 drwx------   3 root     root         4096 Feb  2 13:10 ./__spark_conf__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917826    4 -r-x------   1 root     root         2766 Feb  2 13:10 ./__spark_conf__/__spark_conf__.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917825  128 -r-x------   1 root     root       130051 Feb  2 13:10 ./__spark_conf__/__spark_hadoop_conf__.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917802    4 drwx------   2 root     root         4096 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917811   12 -r-x------   1 root     root         8260 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/capacity-scheduler.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917819   16 -r-x------   1 root     root        14890 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/log4j.properties.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917806    4 -r-x------   1 root     root         3321 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917814    8 -r-x------   1 root     root         6090 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/yarn-env.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917821    4 -r-x------   1 root     root         3593 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/container-log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917808   12 -r-x------   1 root     root         8260 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/capacity-scheduler.xml.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917817    4 -r-x------   1 root     root         1764 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/mapred-env.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917805   16 -r-x------   1 root     root        16380 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/hadoop-env.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917815    4 -r-x------   1 root     root         2979 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/hdfs-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917818    4 -r-x------   1 root     root         2316 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/ssl-client.xml.example\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917824    4 -r-x------   1 root     root         1764 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/mapred-env.sh.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917812    4 -r-x------   1 root     root         3593 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/container-log4j.properties.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917810    4 -r-x------   1 root     root           10 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/workers\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917816    4 -r-x------   1 root     root         1940 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/container-executor.cfg\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917820   12 -r-x------   1 root     root        11392 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/hadoop-policy.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917804   16 -r-x------   1 root     root        14890 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917813    4 -r-x------   1 root     root         1335 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/configuration.xsl\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917807    4 -r-x------   1 root     root         1912 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/yarn-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917823    8 -r-x------   1 root     root         4113 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/mapred-queues.xml.template\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917803    4 -r-x------   1 root     root          758 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/mapred-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917822    4 -r-x------   1 root     root         2697 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/ssl-server.xml.example\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917809    4 -r-x------   1 root     root          986 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/core-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917801   16 -r-x------   1 root     root        14890 Feb  2 13:10 ./__spark_conf__/log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917827    4 -r-x------   1 root     root          762 Feb  2 13:10 ./__spark_conf__/__spark_dist_cache__.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917846    4 -rwx------   1 root     root          723 Feb  2 13:10 ./default_container_executor.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/directory.info] 917841    4 -rw-r--r--   1 root     root           12 Feb  2 13:10 ./.container_tokens.crc\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:36,174 INFO yarn.Client: Application report for application_1675343413375_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:36,779 INFO ipc.Server: Auth successful for appattempt_1675343413375_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:36,800 INFO resourcemanager.DefaultAMSProcessor: AM registration appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:36,800 INFO resourcemanager.RMAuditLogger: USER=root#011IP=10.0.127.243#011OPERATION=Register App Master#011TARGET=ApplicationMasterService#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011APPATTEMPTID=appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:36,801 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from LAUNCHED to RUNNING on event = REGISTERED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:36,801 INFO rmapp.RMAppImpl: application_1675343413375_0001 State change from ACCEPTED to RUNNING on event = ATTEMPT_REGISTERED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,055 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1675343413375_0001), /proxy/application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,076 INFO monitor.ContainersMonitorImpl: container_1675343413375_0001_01_000001's ip = 10.0.127.243, and hostname = algo-1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,082 INFO monitor.ContainersMonitorImpl: Skipping monitoring container container_1675343413375_0001_01_000001 since CPU usage is not yet available.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,177 INFO yarn.Client: Application report for application_1675343413375_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,179 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.127.243\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1675343430041\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1675343413375_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,180 INFO cluster.YarnClientSchedulerBackend: Application application_1675343413375_0001 has started running.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,189 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34087.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,189 INFO netty.NettyBlockTransferService: Server created on 10.0.127.243:34087\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,190 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,203 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.127.243, 34087, None)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,206 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.127.243:34087 with 1028.8 MiB RAM, BlockManagerId(driver, 10.0.127.243, 34087, None)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,209 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.127.243, 34087, None)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,209 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.127.243, 34087, None)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,389 INFO ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,392 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@391df1d{/metrics/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,429 INFO history.SingleEventLogFileWriter: Logging events to file:/tmp/spark-events/application_1675343413375_0001.inprogress\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:37,856 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,182 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,193 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/lib/spark/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,194 INFO internal.SharedState: Warehouse path is 'file:/usr/lib/spark/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,215 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,218 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4fefbd46{/SQL,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,219 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,220 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@12c87a85{/SQL/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,221 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,222 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@36c9484b{/SQL/execution,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,223 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,224 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b031dd3{/SQL/execution/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,225 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,227 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16633ea2{/static/sql,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,693 INFO allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1675343413375_0001_000001 container=null queue=default clusterResource=<memory:31784, vCores:8> type=OFF_SWITCH requestedPartition=\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,694 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000002 Container Transitioned from NEW to ALLOCATED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,694 INFO fica.FiCaSchedulerNode: Assigned container container_1675343413375_0001_01_000002 of capacity <memory:13638, vCores:1> on host algo-2:43589, which has 1 containers, <memory:13638, vCores:1> used and <memory:2254, vCores:3> available after allocation\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,694 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Allocated Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000002#011RESOURCE=<memory:13638, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,695 INFO capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4572741 absoluteUsedCapacity=0.4572741 used=<memory:14534, vCores:2> cluster=<memory:31784, vCores:8>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,695 INFO capacity.CapacityScheduler: Allocation proposal accepted\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,710 INFO security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : algo-2:43589 for container : container_1675343413375_0001_01_000002\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,713 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,727 INFO allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1675343413375_0001_000001 container=null queue=default clusterResource=<memory:31784, vCores:8> type=OFF_SWITCH requestedPartition=\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,727 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000003 Container Transitioned from NEW to ALLOCATED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,728 INFO fica.FiCaSchedulerNode: Assigned container container_1675343413375_0001_01_000003 of capacity <memory:13638, vCores:1> on host algo-1:42563, which has 2 containers, <memory:14534, vCores:2> used and <memory:1358, vCores:2> available after allocation\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,728 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Allocated Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000003#011RESOURCE=<memory:13638, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,729 INFO capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.8863579 absoluteUsedCapacity=0.8863579 used=<memory:28172, vCores:3> cluster=<memory:31784, vCores:8>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:38,729 INFO capacity.CapacityScheduler: Allocation proposal accepted\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:35,774 INFO util.SignalUtils: Registering signal handler for TERM\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:35,776 INFO util.SignalUtils: Registering signal handler for HUP\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:35,776 INFO util.SignalUtils: Registering signal handler for INT\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,181 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,181 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,182 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,182 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,183 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,282 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,427 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,655 INFO client.RMProxy: Connecting to ResourceManager at /10.0.127.243:8030\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,701 INFO yarn.YarnRMClient: Registering the ApplicationMaster\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:36,949 INFO client.TransportClientFactory: Successfully created connection to /10.0.127.243:42921 after 83 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:37,068 INFO yarn.ApplicationMaster: Preparing Local resources\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:37,970 INFO yarn.ApplicationMaster: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] ===============================================================================\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] Default YARN executor launch context:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]   env:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     AWS_REGION -> eu-west-1\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     CLASSPATH -> /usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar<CPS>{{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     SPARK_YARN_STAGING_DIR -> hdfs://10.0.127.243/user/root/.sparkStaging/application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     SPARK_USER -> root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     PYTHONPATH -> {{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]   command:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     LD_LIBRARY_PATH=\\\"/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:$LD_LIBRARY_PATH\\\" \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       {{JAVA_HOME}}/bin/java \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       -server \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       -Xmx12399m \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-verbose:gc' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-XX:OnOutOfMemoryError=kill -9 %p' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-XX:+PrintGCDetails' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-XX:+PrintGCDateStamps' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-XX:+UseParallelGC' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-XX:InitiatingHeapOccupancyPercent=70' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-XX:ConcGCThreads=1' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-XX:ParallelGCThreads=3' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       -Djava.io.tmpdir={{PWD}}/tmp \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-Dspark.driver.port=42921' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       '-Dspark.rpc.askTimeout=300s' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       -Dspark.yarn.app.container.log.dir=<LOG_DIR> \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       org.apache.spark.executor.YarnCoarseGrainedExecutorBackend \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       --driver-url \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       spark://CoarseGrainedScheduler@10.0.127.243:42921 \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       --executor-id \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       <executorId> \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       --hostname \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       <hostname> \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       --cores \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       4 \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       --app-id \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       application_1675343413375_0001 \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       --resourceProfileId \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       0 \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       --user-class-path \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       file:$PWD/__app__.jar \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       1><LOG_DIR>/stdout \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]       2><LOG_DIR>/stderr\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]   resources:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     pyspark.zip -> resource { scheme: \"hdfs\" host: \"10.0.127.243\" port: -1 file: \"/user/root/.sparkStaging/application_1675343413375_0001/pyspark.zip\" } size: 889814 timestamp: 1675343429711 type: FILE visibility: PRIVATE\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     __spark_libs__ -> resource { scheme: \"hdfs\" host: \"10.0.127.243\" port: -1 file: \"/user/root/.sparkStaging/application_1675343413375_0001/__spark_libs__7287418884805699915.zip\" } size: 448655305 timestamp: 1675343429559 type: ARCHIVE visibility: PRIVATE\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     py4j-0.10.9-src.zip -> resource { scheme: \"hdfs\" host: \"10.0.127.243\" port: -1 file: \"/user/root/.sparkStaging/application_1675343413375_0001/py4j-0.10.9-src.zip\" } size: 41587 timestamp: 1675343429751 type: FILE visibility: PRIVATE\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr]     __spark_conf__ -> resource { scheme: \"hdfs\" host: \"10.0.127.243\" port: -1 file: \"/user/root/.sparkStaging/application_1675343413375_0001/__spark_conf__.zip\" } size: 266144 timestamp: 1675343429900 type: ARCHIVE visibility: PRIVATE\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] ===============================================================================\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:38,054 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 1239, script: , vendor: , cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 12399, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/stderr] 2023-02-02 13:10:38,056 INFO yarn.YarnAllocator: Resource profile 0 doesn't exist, adding it\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000001/sINFO:__main__:Arguments: Namespace(copy_hdfs='1', bucket_name='sagemaker-eu-west-1-691148928602', processing_input_files_path='electricity-forecasting/data/input', processing_output_files_path='electricity-forecasting/data/output')\u001b[0m\n",
      "\u001b[34mINFO:__main__:Creating /tmp folder in HDFS\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:38,953 INFO ipc.Server: Auth successful for appattempt_1675343413375_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,032 INFO containermanager.ContainerManagerImpl: Start request for container_1675343413375_0001_01_000002 by user root\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,090 INFO containermanager.ContainerManagerImpl: Creating a new application reference for app application_1675343413375_0001\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,100 INFO application.ApplicationImpl: Application application_1675343413375_0001 transitioned from NEW to INITING\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,100 INFO application.ApplicationImpl: Adding container_1675343413375_0001_01_000002 to application application_1675343413375_0001\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,100 INFO nodemanager.NMAuditLogger: USER=root#011IP=10.0.127.243#011OPERATION=Start Container Request#011TARGET=ContainerManageImpl#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000002\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,105 INFO application.ApplicationImpl: Application application_1675343413375_0001 transitioned from INITING to RUNNING\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,109 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000002 transitioned from NEW to LOCALIZING\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,109 INFO containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1675343413375_0001\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,121 INFO localizer.ResourceLocalizationService: Created localizer for container_1675343413375_0001_01_000002\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,216 INFO localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-root/nm-local-dir/nmPrivate/container_1675343413375_0001_01_000002.tokens\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,229 INFO nodemanager.DefaultContainerExecutor: Initializing user root\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,233 INFO nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-root/nm-local-dir/nmPrivate/container_1675343413375_0001_01_000002.tokens to /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002.tokens\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:39,234 INFO nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001 = file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,175 INFO security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : algo-1:42563 for container : container_1675343413375_0001_01_000003\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,176 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,193 INFO ipc.Server: Auth successful for appattempt_1675343413375_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,200 INFO containermanager.ContainerManagerImpl: Start request for container_1675343413375_0001_01_000003 by user root\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,202 INFO application.ApplicationImpl: Adding container_1675343413375_0001_01_000003 to application application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,203 INFO nodemanager.NMAuditLogger: USER=root#011IP=10.0.127.243#011OPERATION=Start Container Request#011TARGET=ContainerManageImpl#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000003\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,206 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000003 transitioned from NEW to LOCALIZING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,206 INFO containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,207 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000003 transitioned from LOCALIZING to SCHEDULED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,207 INFO scheduler.ContainerScheduler: Starting container [container_1675343413375_0001_01_000003]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,228 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000003 transitioned from SCHEDULED to RUNNING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,229 INFO monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1675343413375_0001_01_000003\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,233 INFO nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000003/default_container_executor.sh]\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/prelaunch.out\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/prelaunch.err\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/launch_container.sh\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,708 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:39,728 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:40,106 INFO monitor.ContainersMonitorImpl: container_1675343413375_0001_01_000003's ip = 10.0.127.243, and hostname = algo-1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:40,115 INFO monitor.ContainersMonitorImpl: Skipping monitoring container container_1675343413375_0001_01_000003 since CPU usage is not yet available.\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917712  132 -r-x------   1 root     root       134044 Feb  2 13:10 ./__spark_libs__/aircompressor-0.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917713  480 -r-x------   1 root     root       489884 Feb  2 13:10 ./__spark_libs__/log4j-1.2.17.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917714 1864 -r-x------   1 root     root      1908681 Feb  2 13:10 ./__spark_libs__/datanucleus-rdbms-4.1.19.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917715  100 -r-x------   1 root     root       100636 Feb  2 13:10 ./__spark_libs__/jsp-api-2.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917716  308 -r-x------   1 root     root       313702 Feb  2 13:10 ./__spark_libs__/libfb303-0.9.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917717  504 -r-x------   1 root     root       512742 Feb  2 13:10 ./__spark_libs__/woodstox-core-5.0.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917718   80 -r-x------   1 root     root        81406 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-server-web-proxy-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917719   20 -r-x------   1 root     root        18140 Feb  2 13:10 ./__spark_libs__/jakarta.inject-2.6.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917720  336 -r-x------   1 root     root       342143 Feb  2 13:10 ./__spark_libs__/jackson-module-scala_2.12-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917721   44 -r-x------   1 root     root        41123 Feb  2 13:10 ./__spark_libs__/commons-cli-1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917722  104 -r-x------   1 root     root       105365 Feb  2 13:10 ./__spark_libs__/metrics-core-4.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917723   44 -r-x------   1 root     root        43743 Feb  2 13:10 ./__spark_libs__/jackson-module-paranamer-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917724 1076 -r-x------   1 root     root      1098935 Feb  2 13:10 ./__spark_libs__/parquet-column-1.10.1-spark-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917725  116 -r-x------   1 root     root       115371 Feb  2 13:10 ./__spark_libs__/spark-mllib-local_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917726    8 -r-x------   1 root     root         4592 Feb  2 13:10 ./__spark_libs__/jul-to-slf4j-1.7.30.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917727 5008 -r-x------   1 root     root      5127896 Feb  2 13:10 ./__spark_libs__/hadoop-hdfs-client-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917728 8084 -r-x------   1 root     root      8274798 Feb  2 13:10 ./__spark_libs__/hive-metastore-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917729 4120 -r-x------   1 root     root      4216895 Feb  2 13:10 ./__spark_libs__/netty-all-4.1.51.Final.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917730   28 -r-x------   1 root     root        25058 Feb  2 13:10 ./__spark_libs__/jakarta.annotation-api-1.3.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917731  124 -r-x------   1 root     root       123052 Feb  2 13:10 ./__spark_libs__/py4j-0.10.9.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917732  276 -r-x------   1 root     root       281356 Feb  2 13:10 ./__spark_libs__/xbean-asm7-shaded-4.15.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917733   72 -r-x------   1 root     root        72668 Feb  2 13:10 ./__spark_libs__/arrow-format-2.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917734  604 -r-x------   1 root     root       616888 Feb  2 13:10 ./__spark_libs__/commons-configuration2-2.1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917735  380 -r-x------   1 root     root       386529 Feb  2 13:10 ./__spark_libs__/RoaringBitmap-0.9.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917736  628 -r-x------   1 root     root       643043 Feb  2 13:10 ./__spark_libs__/joda-time-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917737   44 -r-x------   1 root     root        44168 Feb  2 13:10 ./__spark_libs__/hadoop-client-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917738   20 -r-x------   1 root     root        20046 Feb  2 13:10 ./__spark_libs__/kerb-identity-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917739  224 -r-x------   1 root     root       226000 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-registry-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917740 1644 -r-x------   1 root     root      1679364 Feb  2 13:10 ./__spark_libs__/hive-service-rpc-3.1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917741  208 -r-x------   1 root     root       211523 Feb  2 13:10 ./__spark_libs__/chill_2.12-0.9.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917742  220 -r-x------   1 root     root       222980 Feb  2 13:10 ./__spark_libs__/scala-parser-combinators_2.12-1.1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917743   76 -r-x------   1 root     root        76928 Feb  2 13:10 ./__spark_libs__/spark-launcher_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917744  232 -r-x------   1 root     root       233745 Feb  2 13:10 ./__spark_libs__/threeten-extra-1.5.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917745  100 -r-x------   1 root     root       102174 Feb  2 13:10 ./__spark_libs__/kerby-asn1-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917746  132 -r-x------   1 root     root       134696 Feb  2 13:10 ./__spark_libs__/breeze-macros_2.12-1.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917747   60 -r-x------   1 root     root        60263 Feb  2 13:10 ./__spark_libs__/hadoop-annotations-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917748   36 -r-x------   1 root     root        33031 Feb  2 13:10 ./__spark_libs__/jsr305-3.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917749  160 -r-x------   1 root     root       160519 Feb  2 13:10 ./__spark_libs__/commons-dbcp-1.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917750  448 -r-x------   1 root     root       458605 Feb  2 13:10 ./__spark_libs__/netlib-native_system-linux-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917751 3216 -r-x------   1 root     root      3290504 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-api-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917752  764 -r-x------   1 root     root       780265 Feb  2 13:10 ./__spark_libs__/javassist-3.25.0-GA.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917753   20 -r-x------   1 root     root        19479 Feb  2 13:10 ./__spark_libs__/osgi-resource-locator-1.0.3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917754   52 -r-x------   1 root     root        51568 Feb  2 13:10 ./__spark_libs__/spark-unsafe_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917755  200 -r-x------   1 root     root       201124 Feb  2 13:10 ./__spark_libs__/jdo-api-3.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917756  440 -r-x------   1 root     root       447005 Feb  2 13:10 ./__spark_libs__/univocity-parsers-2.9.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917757   64 -r-x------   1 root     root        65261 Feb  2 13:10 ./__spark_libs__/oro-2.0.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917758  264 -r-x------   1 root     root       268780 Feb  2 13:10 ./__spark_libs__/jline-2.14.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917759  320 -r-x------   1 root     root       327605 Feb  2 13:10 ./__spark_libs__/hive-llap-common-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917760   84 -r-x------   1 root     root        82756 Feb  2 13:10 ./__spark_libs__/kerb-server-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917761   84 -r-x------   1 root     root        85756 Feb  2 13:10 ./__spark_libs__/okio-1.14.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917762  688 -r-x------   1 root     root       703130 Feb  2 13:10 ./__spark_libs__/spark-hive_2.12-3.1.1-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917763  116 -r-x------   1 root     root       116120 Feb  2 13:10 ./__spark_libs__/kerb-crypto-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917764  188 -r-x------   1 root     root       190432 Feb  2 13:10 ./__spark_libs__/gson-2.2.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917765    8 -r-x------   1 root     root         4722 Feb  2 13:10 ./__spark_libs__/jcip-annotations-1.0-1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917766  244 -r-x------   1 root     root       246918 Feb  2 13:10 ./__spark_libs__/commons-beanutils-1.9.4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917767  524 -r-x------   1 root     root       533455 Feb  2 13:10 ./__spark_libs__/protobuf-java-2.5.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917768 1024 -r-x------   1 root     root      1045744 Feb  2 13:10 ./__spark_libs__/leveldbjni-all-1.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917769   40 -r-x------   1 root     root        38365 Feb  2 13:10 ./__spark_libs__/hive-vector-code-gen-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917770  184 -r-x------   1 root     root       187052 Feb  2 13:10 ./__spark_libs__/avro-mapred-1.8.2-hadoop2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917771  100 -r-x------   1 root     root       100990 Feb  2 13:10 ./__spark_libs__/arrow-memory-core-2.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917772  620 -r-x------   1 root     root       632424 Feb  2 13:10 ./__spark_libs__/commons-compress-1.20.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917773  280 -r-x------   1 root     root       283653 Feb  2 13:10 ./__spark_libs__/curator-recipes-2.13.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917774  900 -r-x------   1 root     root       919285 Feb  2 13:10 ./__spark_libs__/hive-serde-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917775 1364 -r-x------   1 root     root      1393617 Feb  2 13:10 ./__spark_libs__/hadoop-yarn-server-common-3.2.1-amzn-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917776  544 -r-x------   1 root     root       553993 Feb  2 13:10 ./__spark_libs__/netlib-native_system-osx-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917777  656 -r-x------   1 root     root       668235 Feb  2 13:10 ./__spark_libs__/guice-4.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917778  636 -r-x------   1 root     root       649950 Feb  2 13:10 ./__spark_libs__/lz4-java-1.7.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917779  112 -r-x------   1 root     root       113017 Feb  2 13:10 ./__spark_libs__/kerb-client-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917780   68 -r-x------   1 root     root        68080 Feb  2 13:10 ./__spark_libs__/jackson-annotations-2.10.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917781   36 -r-x------   1 root     root        34601 Feb  2 13:10 ./__spark_libs__/spire-util_2.12-0.17.0-M1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917782   60 -r-x------   1 root     root        58684 Feb  2 13:10 ./__spark_libs__/chill-java-0.9.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917783   24 -r-x------   1 root     root        24239 Feb  2 13:10 ./__spark_libs__/commons-daemon-1.0.13.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917784  512 -r-x------   1 root     root       523372 Feb  2 13:10 ./__spark_libs__/commons-lang3-3.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917785   32 -r-x------   1 root     root        29134 Feb  2 13:10 ./__spark_libs__/kerby-xdr-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917786  384 -r-x------   1 root     root       392124 Feb  2 13:10 ./__spark_libs__/velocity-1.5.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917787   48 -r-x------   1 root     root        46219 Feb  2 13:10 ./__spark_libs__/hive-cli-2.3.7-amzn-4.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917788 2252 -r-x------   1 root     root      2305169 Feb  2 13:10 ./__spark_libs__/netlib-native_ref-win-x86_64-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917789   12 -r-x------   1 root     root         8685 Feb  2 13:10 ./__spark_libs__/jniloader-1.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917790  200 -r-x------   1 root     root       204650 Feb  2 13:10 ./__spark_libs__/kerby-pkix-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917791  296 -r-x------   1 root     root       299508 Feb  2 13:10 ./__spark_libs__/nimbus-jose-jwt-4.41.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917511  872 -r-x------   1 root     root       889814 Feb  2 13:10 ./pyspark.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917870    8 -rwx------   1 root     root         5138 Feb  2 13:10 ./launch_container.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917800    4 drwx------   3 root     root         4096 Feb  2 13:10 ./__spark_conf__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917826    4 -r-x------   1 root     root         2766 Feb  2 13:10 ./__spark_conf__/__spark_conf__.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917825  128 -r-x------   1 root     root       130051 Feb  2 13:10 ./__spark_conf__/__spark_hadoop_conf__.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917802    4 drwx------   2 root     root         4096 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917811   12 -r-x------   1 root     root         8260 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/capacity-scheduler.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917819   16 -r-x------   1 root     root        14890 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/log4j.properties.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917806    4 -r-x------   1 root     root         3321 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917814    8 -r-x------   1 root     root         6090 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/yarn-env.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917821    4 -r-x------   1 root     root         3593 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/container-log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917808   12 -r-x------   1 root     root         8260 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/capacity-scheduler.xml.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917817    4 -r-x------   1 root     root         1764 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/mapred-env.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917805   16 -r-x------   1 root     root        16380 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/hadoop-env.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917815    4 -r-x------   1 root     root         2979 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/hdfs-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917818    4 -r-x------   1 root     root         2316 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/ssl-client.xml.example\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917824    4 -r-x------   1 root     root         1764 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/mapred-env.sh.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917812    4 -r-x------   1 root     root         3593 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/container-log4j.properties.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917810    4 -r-x------   1 root     root           10 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/workers\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917816    4 -r-x------   1 root     root         1940 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/container-executor.cfg\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917820   12 -r-x------   1 root     root        11392 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/hadoop-policy.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917804   16 -r-x------   1 root     root        14890 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917813    4 -r-x------   1 root     root         1335 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/configuration.xsl\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917807    4 -r-x------   1 root     root         1912 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/yarn-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917823    8 -r-x------   1 root     root         4113 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/mapred-queues.xml.template\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917803    4 -r-x------   1 root     root          758 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/mapred-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917822    4 -r-x------   1 root     root         2697 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/ssl-server.xml.example\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917809    4 -r-x------   1 root     root          986 Feb  2 13:10 ./__spark_conf__/__hadoop_conf__/core-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917801   16 -r-x------   1 root     root        14890 Feb  2 13:10 ./__spark_conf__/log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917827    4 -r-x------   1 root     root          762 Feb  2 13:10 ./__spark_conf__/__spark_dist_cache__.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/directory.info] 917874    4 -rwx------   1 root INFO:__main__:EBS files: ['energy_dataset.csv', 'weather_features.csv', 'code']\u001b[0m\n",
      "\u001b[34mINFO:__main__:Copy /opt/ml/processing/input/energy_dataset.csv in HDFS hdfs://10.0.127.243/tmp/energy_dataset.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:42,186 INFO scheduler.AppSchedulingInfo: checking for deactivate of application :application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:42,808 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.127.243:53812) with ID 2,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:42,630 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000002 transitioned from LOCALIZING to SCHEDULED\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:42,631 INFO scheduler.ContainerScheduler: Starting container [container_1675343413375_0001_01_000002]\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:42,658 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000002 transitioned from SCHEDULED to RUNNING\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:42,659 INFO monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1675343413375_0001_01_000002\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:42,663 INFO nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002/default_container_executor.sh]\u001b[0m\n",
      "\u001b[35mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/prelaunch.out\u001b[0m\n",
      "\u001b[35mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/prelaunch.err\u001b[0m\n",
      "\u001b[35mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/launch_container.sh\u001b[0m\n",
      "\u001b[35mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/directory.info\u001b[0m\n",
      "\u001b[35mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout\u001b[0m\n",
      "\u001b[35mHandling create event for file: /var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:42,901 INFO monitor.ContainersMonitorImpl: container_1675343413375_0001_01_000002's ip = 10.0.73.224, and hostname = algo-2\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:42,906 INFO monitor.ContainersMonitorImpl: Skipping monitoring container container_1675343413375_0001_01_000002 since CPU usage is not yet available.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:43,195 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:35681 with 6.3 GiB RAM, BlockManagerId(2, algo-1, 35681, None)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:40,579 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 1247@algo-1\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:40,595 INFO util.SignalUtils: Registering signal handler for TERM\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:40,596 INFO util.SignalUtils: Registering signal handler for HUP\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:40,596 INFO util.SignalUtils: Registering signal handler for INT\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,113 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,114 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,115 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,115 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,116 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,691 INFO client.TransportClientFactory: Successfully created connection to /10.0.127.243:42921 after 128 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,973 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,974 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,974 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,975 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:41,975 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:42,075 INFO client.TransportClientFactory: Successfully created connection to /10.0.127.243:42921 after 7 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:42,218 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/blockmgr-73b515df-1a95-4b6f-b37a-bf6643a42800\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:42,272 INFO memory.MemoryStore: MemoryStore started with capacity 6.3 GiB\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:43,340 INFO hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /tmp/energy_dataset.csv._COPYING_\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:43,528 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741832_1008 src: /10.0.127.243:60108 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:43,576 INFO DataNode.clienttrace: src: /10.0.127.243:60108, dest: /10.0.127.243:9866, bytes: 6273009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_924278143_1, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741832_1008, duration(ns): 36501777\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:43,576 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:43,581 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_924278143_1\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_0INFO:__main__:Copy /opt/ml/processing/input/weather_features.csv in HDFS hdfs://10.0.127.243/tmp/weather_features.csv\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:43,531 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741832_1008 src: /10.0.127.243:34590 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:43,573 INFO DataNode.clienttrace: src: /10.0.127.243:34590, dest: /10.0.73.224:9866, bytes: 6273009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_924278143_1, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741832_1008, duration(ns): 40318439\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:43,573 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:45,109 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.73.224:45848) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:45,289 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-2:46853 with 6.3 GiB RAM, BlockManagerId(1, algo-2, 46853, None)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:45,677 INFO hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /tmp/weather_features.csv._COPYING_\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:45,778 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741833_1009 src: /10.0.127.243:60122 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:45,882 INFO DataNode.clienttrace: src: /10.0.127.243:60122, dest: /10.0.127.243:9866, bytes: 19918887, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-312329792_1, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741833_1009, duration(ns): 97081350\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:45,883 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:45,886 INFO hdfs.StateChange: DIR* completeFile: /tmp/weather_features.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-312329792_1\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:43,625 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 432@algo-2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:43,634 INFO util.SignalUtils: Registering signal handler for TERM\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:43,635 INFO util.SignalUtils: Registering signal handler for HUP\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:43,635 INFO util.SignalUtils: Registering signal handler for INT\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,109 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,110 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,111 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,112 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,112 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,464 INFO client.TransportClientFactory: Successfully created connection to /10.0.127.243:42921 after 65 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,549 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,550 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,550 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,550 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,550 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,599 INFO client.TransportClientFactory: Successfully created connection to /10.0.127.243:42921 after 1 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,657 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/blockmgr-cccb1f27-8a03-4224-8a89-26a86b700aca\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,695 INFO memory.MemoryStore: MemoryStore started with capacity 6.3 GiB\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:45,780 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741833_1009 src: /10.0.127.243:34606 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:45,881 INFO DataNode.clienttrace: src: /10.0.127.243:34606, dest: /10.0.73.224:9866, bytes: 19918887, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-312329792_1, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741833_1009, duration(ns): 89716554\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:45,881 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34mINFO:__main__:Copy /opt/ml/processing/input/code in HDFS hdfs://10.0.127.243/tmp/code\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:47,739 INFO hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /tmp/code/processing.py._COPYING_\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:47,823 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741834_1010 src: /10.0.127.243:60128 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:47,837 INFO DataNode.clienttrace: src: /10.0.127.243:60128, dest: /10.0.127.243:9866, bytes: 8621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_255755800_1, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741834_1010, duration(ns): 9196352\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:47,837 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:47,840 INFO hdfs.StateChange: DIR* completeFile: /tmp/code/processing.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_255755800_1\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:47,825 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741834_1010 src: /10.0.127.243:34616 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:47,836 INFO DataNode.clienttrace: src: /10.0.127.243:34616, dest: /10.0.73.224:9866, bytes: 8621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_255755800_1, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741834_1010, duration(ns): 9697668\u001b[0m\n",
      "\u001b[35m2023-02-02 13:10:47,836 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34mINFO:__main__:Loading energy_dataset.csv from path hdfs://10.0.127.243/tmp/energy_dataset.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:48,431 INFO datasources.InMemoryFileIndex: It took 41 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:48,490 INFO datasources.InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:50,433 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:50,434 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:50,437 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,001 INFO codegen.CodeGenerator: Code generated in 225.932696 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,062 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.6 KiB, free 1028.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,112 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1028.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,115 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,119 INFO spark.SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,163 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 2, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,169 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,2))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,271 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,305 INFO scheduler.DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,305 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,305 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,307 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,312 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,415 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.9 KiB, free 1028.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,424 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 1028.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,425 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.127.243:34087 (size: 5.4 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,426 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,441 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,442 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,491 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 2, partition 0, NODE_LOCAL, 5148 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:51,873 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:35681 (size: 5.4 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m1_000003/stderr] 2023-02-02 13:10:42,587 INFO executor.YarnCoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@10.0.127.243:42921\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:42,610 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:42,610 INFO resource.ResourceUtils: No custom resources configured for spark.executor.\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:42,611 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:42,839 INFO executor.YarnCoarseGrainedExecutorBackend: Successfully registered with driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:42,845 INFO executor.Executor: Starting executor ID 2 on host algo-1\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,162 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35681.\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,162 INFO netty.NettyBlockTransferService: Server created on algo-1:35681\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,165 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,168 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,177 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(2, algo-1, 35681, None)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,199 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(2, algo-1, 35681, None)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,200 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(2, algo-1, 35681, None)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,230 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:43,230 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:45,510 INFO executor.YarnCoarseGrainedExecutorBackend: eagerFSInit: Eagerly initialized FileSystem at s3://does/not/exist in 2822 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:51,523 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:51,567 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:51,734 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,039 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:35681 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,828 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2351 ms on algo-1 (executor 2) (1/1)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,830 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,836 INFO scheduler.DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 2.483 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,846 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,846 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,848 INFO scheduler.DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 2.577182 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,875 INFO codegen.CodeGenerator: Code generated in 12.582823 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,958 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,958 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,959 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,969 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 317.6 KiB, free 1028.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,983 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1028.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,984 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,985 INFO spark.SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,987 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 2, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:53,988 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,2))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:54,080 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.127.243:34087 in memory (size: 5.4 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:54,111 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:35681 in memory (size: 5.4 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m02-02 13:10 sagemaker-spark-event-logs-publisher INFO     Got spark event logs file: application_1675343413375_0001.inprogress\u001b[0m\n",
      "\u001b[34m02-02 13:10 root         INFO     copying /tmp/spark-events/application_1675343413375_0001.inprogress to /opt/ml/processing/spark-events/application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,261 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,404 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,404 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,404 INFO datasources.FileSourceStrategy: Output Data Schema: struct<generation biomass: string, generation fossil brown coal/lignite: string, generation fossil gas: string, generation fossil hard coal: string, generation fossil oil: string ... 15 more fields>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,822 INFO codegen.CodeGenerator: Code generated in 145.648346 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,828 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 317.5 KiB, free 1027.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,842 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,842 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,843 INFO spark.SparkContext: Created broadcast 3 from toPandas at /opt/ml/processing/input/code/processing.py:158\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,849 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 2, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,849 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,2))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,867 INFO scheduler.DAGScheduler: Registering RDD 13 (toPandas at /opt/ml/processing/input/code/processing.py:158) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,871 INFO scheduler.DAGScheduler: Got map stage job 1 (toPandas at /opt/ml/processing/input/code/processing.py:158) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,872 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 1 (toPandas at /opt/ml/processing/input/code/processing.py:158)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,873 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,873 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,877 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at toPandas at /opt/ml/processing/input/code/processing.py:158), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,904 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 56.5 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,906 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,907 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.127.243:34087 (size: 19.4 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,908 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,910 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at toPandas at /opt/ml/processing/input/code/processing.py:158) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,910 INFO cluster.YarnScheduler: Adding task set 1.0 with 2 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,913 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 2, partition 0, NODE_LOCAL, 4880 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,914 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (algo-2, executor 1, partition 1, NODE_LOCAL, 4880 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:55,933 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:35681 (size: 19.4 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:56,167 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-2:46853 (size: 19.4 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:56,258 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:35681 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:51,814 INFO client.TransportClientFactory: Successfully created connection to /10.0.127.243:34087 after 3 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:51,868 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:51,879 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 145 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:51,964 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:52,934 INFO codegen.CodeGenerator: Code generated in 204.127856 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:52,958 INFO datasources.FileScanRDD: TID: 0 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset.csv, range: 0-4194304, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:53,028 INFO codegen.CodeGenerator: Code generated in 13.436588 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:53,030 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:53,037 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:53,041 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 11 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:53,112 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:53,815 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 1935 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:55,917 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 1\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:55,917 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:55,924 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:55,931 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:55,934 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 10 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:55,937 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 56.5 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:56,932 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1020 ms on algo-1 (executor 2) (1/2)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,967 INFO executor.YarnCoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@10.0.127.243:42921\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,981 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,981 INFO resource.ResourceUtils: No custom resources configured for spark.executor.\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:44,982 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,120 INFO executor.YarnCoarseGrainedExecutorBackend: Successfully registered with driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,125 INFO executor.Executor: Starting executor ID 1 on host algo-2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,270 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46853.\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,270 INFO netty.NettyBlockTransferService: Server created on algo-2:46853\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,272 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,283 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, algo-2, 46853, None)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,290 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,293 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, algo-2, 46853, None)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,293 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(1, algo-2, 46853, None)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,318 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:45,318 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:47,281 INFO executor.YarnCoarseGrainedExecutorBackend: eagerFSInit: Eagerly initialized FileSystem at s3://does/not/exist in 2236 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:55,925 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:55,936 INFO executor.Executor: Running task 1.0 in stage 1.0 (TID 2)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:56,056 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:57,450 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-2:46853 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,639 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 2726 ms on algo-2 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,640 INFO scheduler.DAGScheduler: ShuffleMapStage 1 (toPandas at /opt/ml/processing/input/code/processing.py:158) finished in 2.758 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,641 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,641 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,642 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,642 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,642 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,729 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.127.243:34087 in memory (size: 19.4 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,732 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:35681 in memory (size: 19.4 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,734 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-2:46853 in memory (size: 19.4 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,763 INFO codegen.CodeGenerator: Code generated in 32.676427 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,789 INFO spark.SparkContext: Starting job: toPandas at /opt/ml/processing/input/code/processing.py:158\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,790 INFO scheduler.DAGScheduler: Got job 2 (toPandas at /opt/ml/processing/input/code/processing.py:158) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,790 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (toPandas at /opt/ml/processing/input/code/processing.py:158)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,790 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,790 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,794 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at toPandas at /opt/ml/processing/input/code/processing.py:158), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,803 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.7 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,805 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,807 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.127.243:34087 (size: 7.2 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,808 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,809 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at toPandas at /opt/ml/processing/input/code/processing.py:158) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,809 INFO cluster.YarnScheduler: Adding task set 3.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,811 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (algo-2, executor 1, partition 0, NODE_LOCAL, 4721 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,830 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-2:46853 (size: 7.2 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:58,975 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.73.224:45848\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,110 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 300 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,111 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,112 INFO scheduler.DAGScheduler: ResultStage 3 (toPandas at /opt/ml/processing/input/code/processing.py:158) finished in 0.311 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,114 INFO scheduler.DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,114 INFO cluster.YarnScheduler: Killing all running tasks in stage 3: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,115 INFO scheduler.DAGScheduler: Job 2 finished: toPandas at /opt/ml/processing/input/code/processing.py:158, took 0.325499 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,212 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,212 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,212 INFO datasources.FileSourceStrategy: Output Data Schema: struct<time: string, generation biomass: string, generation fossil brown coal/lignite: string, generation fossil gas: string, generation fossil hard coal: string ... 16 more fields>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,286 INFO codegen.CodeGenerator: Code generated in 54.405679 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,292 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 317.5 KiB, free 1027.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,305 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1027.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,306 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,306 INFO spark.SparkContext: Created broadcast 6 from toPandas at /opt/ml/processing/input/code/processing.py:162\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,308 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 2, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,309 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,2))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,324 INFO spark.SparkContext: Starting job: toPandas at /opt/ml/processing/input/code/processing.py:162\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,325 INFO scheduler.DAGScheduler: Got job 3 (toPandas at /opt/ml/processing/input/code/processing.py:162) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,325 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (toPandas at /opt/ml/processing/input/code/processing.py:162)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,325 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,325 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,326 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at toPandas at /opt/ml/processing/input/code/processing.py:162), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,331 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.8 KiB, free 1027.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,340 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 1027.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,345 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.127.243:34087 (size: 11.0 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,345 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,346 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at toPandas at /opt/ml/processing/input/code/processing.py:162) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,346 INFO cluster.YarnScheduler: Adding task set 4.0 with 2 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,348 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (algo-2, executor 1, partition 0, NODE_LOCAL, 5148 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,348 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.127.243:34087 in memory (size: 7.2 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,349 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5) (algo-1, executor 2, partition 1, NODE_LOCAL, 5148 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,351 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-2:46853 in memory (size: 7.2 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,370 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:35681 (size: 11.0 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,374 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-2:46853 (size: 11.0 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,484 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-2:46853 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,550 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:35681 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:10:59,855 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 507 ms on algo-1 (executor 2) (1/2)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,062 INFO storage.BlockManagerInfo: Added taskresult_4 in memory on algo-2:46853 (size: 1559.0 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,090 INFO client.TransportClientFactory: Successfully created connection to algo-2/10.0.73.224:46853 after 7 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:56,102 INFO client.TransportClientFactory: Successfully created connection to algo-1/10.0.127.243:35681 after 2 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:56,162 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:56,172 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 116 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:56,246 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 56.5 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:57,251 INFO codegen.CodeGenerator: Code generated in 342.273806 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:57,291 INFO datasources.FileScanRDD: TID: 2 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset.csv, range: 4194304-6273009, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:57,424 INFO codegen.CodeGenerator: Code generated in 35.557377 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:57,426 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:57,439 INFO client.TransportClientFactory: Successfully created connection to /10.0.127.243:34087 after 6 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:57,448 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:57,452 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 25 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:57,513 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,635 INFO executor.Executor: Finished task 1.0 in stage 1.0 (TID 2). 1956 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,815 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 3\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,815 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 3)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,821 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,823 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,829 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,831 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 8 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,833 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.7 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,967 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:58,969 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.127.243:42921)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,015 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,047 INFO storage.ShuffleBlockFetcherIterator: Getting 2 (169.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 1 (97.0 B) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,054 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 22 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,091 INFO codegen.CodeGenerator: Code generated in 30.77866 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,105 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 3). 2680 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,352 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 4\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,352 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 4)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,355 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,361 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,375 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 19 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,376 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,434 INFO codegen.CodeGenerator: Code generated in 53.238454 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,436 INFO datasources.FileScanRDD: TID: 4 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset.csv, range: 0-4194304, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,472 INFO codegen.CodeGenerator: Code generated in 17.703395 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,474 INFO broadcast.TorrentBroadcast: Started reading broadcast variable[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:43.605+0000: [GC (Allocation Failure) [PSYoungGen: 57856K->7089K(67072K)] 57856K->7097K(220160K), 0.0066530 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:44.146+0000: [GC (Allocation Failure) [PSYoungGen: 64945K->7978K(67072K)] 64953K->7994K(220160K), 0.0080744 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:44.314+0000: [GC (Metadata GC Threshold) [PSYoungGen: 37074K->6908K(67072K)] 37090K->6932K(220160K), 0.0053038 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:44.320+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 6908K->0K(67072K)] [ParOldGen: 24K->6764K(92160K)] 6932K->6764K(159232K), [Metaspace: 20444K->20444K(1067008K)], 0.0256055 secs] [Times: user=0.05 sys=0.00, real=0.03 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:44.725+0000: [GC (Allocation Failure) [PSYoungGen: 57856K->4790K(93184K)] 64620K->11562K(185344K), 0.0057105 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:45.031+0000: [GC (Allocation Failure) [PSYoungGen: 92854K->6934K(120832K)] 99626K->13707K(212992K), 0.0068172 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:45.191+0000: [GC (Metadata GC Threshold) [PSYoungGen: 44437K->4817K(144384K)] 51209K->11597K(236544K), 0.0058399 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:45.197+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 4817K->0K(144384K)] [ParOldGen: 6780K->9665K(138752K)] 11597K->9665K(283136K), [Metaspace: 33890K->33890K(1079296K)], 0.0282798 secs] [Times: user=0.06 sys=0.00, real=0.03 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:56.325+0000: [GC (Allocation Failure) [PSYoungGen: 135680K->8703K(144384K)] 145345K->29090K(283136K), 0.0207242 secs] [Times: user=0.05 sys=0.01, real=0.02 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:56.531+0000: [GC (Metadata GC Threshold) [PSYoungGen: 45106K->10415K(208384K)] 65492K->30809K(347136K), 0.0115202 secs] [Times: user=0.03 sys=0.01, real=0.01 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:56.542+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 10415K->0K(208384K)] [ParOldGen: 20394K->17898K(184320K)] 30809K->17898K(392704K), [Metaspace: 55955K->55955K(1101824K)], 0.0944813 secs] [Times: user=0.21 sys=0.01, real=0.10 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:57.788+0000: [GC (Allocation Failure) [PSYoungGen: 193024K->12824K(208384K)] 210922K->30730K(392704K), 0.0136499 secs] [Times: user=0.02 sys=0.01, real=0.01 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:58.501+0000: [GC (Allocation Failure) [PSYoungGen: 205848K->9868K(269312K)] 223754K->27783K(453632K), 0.0131184 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,118 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 771 ms on algo-2 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,118 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,119 INFO scheduler.DAGScheduler: ResultStage 4 (toPandas at /opt/ml/processing/input/code/processing.py:162) finished in 0.791 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,119 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,119 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,119 INFO scheduler.DAGScheduler: Job 3 finished: toPandas at /opt/ml/processing/input/code/processing.py:162, took 0.795268 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,125 INFO storage.BlockManagerInfo: Removed taskresult_4 on algo-2:46853 in memory (size: 1559.0 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:40.715+0000: [GC (Allocation Failure) [PSYoungGen: 57856K->8230K(67072K)] 57856K->8238K(220160K), 0.0109718 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:41.265+0000: [GC (Allocation Failure) [PSYoungGen: 66086K->7884K(67072K)] 66094K->7900K(220160K), 0.0135836 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:41.416+0000: [GC (Metadata GC Threshold) [PSYoungGen: 36784K->6302K(67072K)] 36800K->6326K(220160K), 0.0165337 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:41.432+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 6302K->0K(67072K)] [ParOldGen: 24K->6136K(82944K)] 6326K->6136K(150016K), [Metaspace: 20441K->20441K(1067008K)], 0.0463275 secs] [Times: user=0.08 sys=0.00, real=0.04 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:42.232+0000: [GC (Allocation Failure) [PSYoungGen: 57856K->4282K(99328K)] 63992K->10427K(182272K), 0.0049240 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:42.809+0000: [GC (Allocation Failure) [PSYoungGen: 99002K->8464K(120320K)] 105147K->14617K(203264K), 0.0241624 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:42.970+0000: [GC (GCLocker Initiated GC) [PSYoungGen: 24036K->3738K(164864K)] 30189K->9898K(247808K), 0.0051729 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:43.004+0000: [GC (GCLocker Initiated GC) [PSYoungGen: 11053K->3333K(165376K)] 17214K->9502K(248320K), 0.0077875 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:43.040+0000: [GC (Metadata GC Threshold) [PSYoungGen: 8110K->2116K(286720K)] 14279K->9577K(369664K), 0.0096933 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:43.050+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 2116K->0K(286720K)] [ParOldGen: 7461K->8288K(97280K)] 9577K->8288K(384000K), [Metaspace: 34484K->34484K(1081344K)], 0.0355593 secs] [Times: user=0.08 sys=0.00, real=0.03 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:52.391+0000: [GC (Metadata GC Threshold) [PSYoungGen: 213036K->11263K(287232K)] 221325K->30726K(384512K), 0.0226614 secs] [Times: user=0.04 sys=0.02, real=0.02 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:52.414+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 11263K->0K(287232K)] [ParOldGen: 19462K->29578K(131584K)] 30726K->29578K(418816K), [Metaspace: 56367K->56367K(1101824K)], 0.1000127 secs] [Times: user=0.23 sys=0.01, real=0.10 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:53.769+0000: [GC (Allocation Failure) [PSYoungGen: 275968K->16041K(425984K)] 305546K->45628K(557568K), 0.0187220 secs] [Times: user=0.04 sys=0.01, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stdout] 2023-02-02T13:10:59.738+0000: [GC (Allocation Failure) [PSYoungGen: 424617K->5415K(428032K)] 454204K->39099K(559616-02-02 13:10:56,176 INFO codegen.CodeGenerator: Code generated in 174.424541 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:56,196 INFO datasources.FileScanRDD: TID: 1 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset.csv, range: 0-4194304, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:56,246 INFO codegen.CodeGenerator: Code generated in 21.8892 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:56,248 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:56,256 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:56,259 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 11 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:56,274 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:56,925 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 1913 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,354 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 5\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,354 INFO executor.Executor: Running task 1.0 in stage 4.0 (TID 5)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,357 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,358 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,368 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,371 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 12 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,373 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,457 INFO codegen.CodeGenerator: Code generated in 69.562214 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,460 INFO datasources.FileScanRDD: TID: 5 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset.csv, range: 4194304-6273009, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,497 INFO codegen.CodeGenerator: Code generated in 19.627527 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,415 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:35681 in memory (size: 11.0 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,420 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.127.243:34087 in memory (size: 11.0 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:00,432 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-2:46853 in memory (size: 11.0 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,139 INFO codegen.CodeGenerator: Code generated in 24.553489 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,151 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,153 INFO scheduler.DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,153 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,153 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,154 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,154 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,175 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 18.8 KiB, free 1027.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,177 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 1027.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,178 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.127.243:34087 (size: 7.6 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,179 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,180 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,180 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,183 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (algo-2, executor 1, partition 0, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,203 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-2:46853 (size: 7.6 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,831 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 650 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,831 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,834 INFO python.PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 52703\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,836 INFO scheduler.DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 0.678 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,836 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,836 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,836 INFO scheduler.DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.684558 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,872 INFO codegen.CodeGenerator: Code generated in 24.706952 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,499 INFO broadcast.TorrentBroadcast: Started reading br+--------------------+------------------+------------------------------------+---------------------+---------------------------+---------------------+-------------------------------------------+------------------------------------------+--------------------------------+------------------+----------------+--------------------------+----------------+----------------+-----------------------+-----------------+---------------+------------+\u001b[0m\n",
      "\u001b[34m|                time|generation biomass|generation fossil brown coal/lignite|generation fossil gas|generation fossil hard coal|generation fossil oil|generation hydro pumped storage consumption|generation hydro run-of-river and poundage|generation hydro water reservoir|generation nuclear|generation other|generation other renewable|generation solar|generation waste|generation wind onshore|total load actual|price day ahead|price actual|\u001b[0m\n",
      "\u001b[34m+--------------------+------------------+------------------------------------+---------------------+---------------------------+---------------------+-------------------------------------------+------------------------------------------+--------------------------------+------------------+----------------+--------------------------+----------------+----------------+-----------------------+-----------------+---------------+------------+\u001b[0m\n",
      "\u001b[34m|2015-01-01 00:00:...|             447.0|                               329.0|               4844.0|                     4821.0|                162.0|                                      863.0|                                    1051.0|                          1899.0|            7096.0|            43.0|                      73.0|            49.0|           196.0|                 6378.0|          25385.0|           50.1|       65.41|\u001b[0m\n",
      "\u001b[34m+--------------------+------------------+------------------------------------+---------------------+---------------------------+---------------------+-------------------------------------------+------------------------------------------+--------------------------------+------------------+----------------+--------------------------+----------------+----------------+-----------------------+-----------------+---------------+------------+\u001b[0m\n",
      "\u001b[34monly showing top 1 row\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving energy_dataset_df in path hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,942 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-2:46853 in memory (size: 7.6 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:04,952 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.127.243:34087 in memory (size: 7.6 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,020 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,020 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,020 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,021 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,045 INFO codegen.CodeGenerator: Code generated in 16.221472 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,086 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,087 INFO scheduler.DAGScheduler: Got job 5 (csv at NativeMethodAccessorImpl.java:0) with 16 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,088 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,088 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,089 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,093 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:10:59.838+0000: [GC (Allocation Failure) [PSYoungGen: 265868K->5734K(271872K)] 283783K->28950K(45619 6 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,482 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,486 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 12 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:10:59,500 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:00,059 INFO memory.MemoryStore: Block taskresult_4 stored as bytes in memory (estimated size 1559.0 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:00,064 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 4). 1596382 bytes result sent via BlockManager)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:04,188 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 6\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:04,188 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 6)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:04,194 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 8 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:04,200 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:04,204 INFO broadcast.TorrentBroadcast: Reading broadcast variable 8 took 9 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:04,205 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 18.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:04,818 INFO codegen.CodeGenerator: Code generated in 22.682403 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:04,827 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 6). 2036 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,154 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 8\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,155 INFO executor.Executor: Running task 1.0 in stage 6.0 (TID 8)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,155 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 10\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,157 INFO executor.Executor: Running task 3.0 in stage 6.0 (TID 10)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,158 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,130 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 193.1 KiB, free 1027.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,133 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 69.9 KiB, free 1027.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,134 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.127.243:34087 (size: 69.9 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,134 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,135 INFO scheduler.DAGScheduler: Submitting 16 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,136 INFO cluster.YarnScheduler: Adding task set 6.0 with 16 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,137 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7) (algo-1, executor 2, partition 0, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,138 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 8) (algo-2, executor 1, partition 1, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,138 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 9) (algo-1, executor 2, partition 2, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,139 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 10) (algo-2, executor 1, partition 3, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,140 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 11) (algo-1, executor 2, partition 4, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,141 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 6.0 (TID 12) (algo-2, executor 1, partition 5, PROCESS_LOCAL, 569999 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,142 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 13) (algo-1, executor 2, partition 6, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,143 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 14) (algo-2, executor 1, partition 7, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,178 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-2:46853 (size: 69.9 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,188 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:35681 (size: 69.9 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,369 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.127.243:34087 in memory (size: 30.3 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,451 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-1:35681 in memory (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,468 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.127.243:34087 in memory (size: 30.3 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,510 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-2:46853 in memory (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,518 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:35681 in memory (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,523 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.127.243:34087 in memory (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,574 INFO hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311054367288171515370383_0006_m_000005_12/part-00005-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,585 INFO hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311054586333333113309_0006_m_000001_8/part-00001-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,586 INFO hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311056379071415974805391_0006_m_000007_14/part-00007-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,596 INFO hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_20230202131105972454875105768592_0006_m_000003_10/part-00003-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,681 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741838_1014 src: /10.0.73.224:53098 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,682 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741836_1012 src: /10.0.73.224:53088 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,682 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741835_1011 src: /10.0.73.224:53114 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,683 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741837_1013 src: /10.0.73.224:53104 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,742 INFO DataNode.clienttrace: src: /10.0.73.224:53098, dest: /10.0.127.243:9866, bytes: 269523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741838_1014, duration(ns): 52198073\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,743 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,744 INFO DataNode.clienttrace: src: /10.0.73.224:53104, dest: /10.0.127.243:9866, bytes: 269735, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741837_1013, duration(ns): 49011721\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,745 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,745 INFO DataNode.clienttrace: src: /10.0.73.224:53114, dest: /10.0.127.243:9866, bytes: 404242, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741835_1011, duration(ns): 49681690\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,746 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,747 INFO DataNode.clienttrace: src: /10.0.73.224:53088, dest: /10.0.127.243:9866, bytes: 270227, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741836_1012, duration(ns): 55931154\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,747 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,749 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_20230202131105972454875105768592_0006_m_000003_10/part-00003-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,751 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311056379071415974805391_0006_m_000007_14/part-00007-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,752 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311054367288171515370383_0006_m_000005_12/part-00005-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,755 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311054586333333113309_0006_m_000001_8/part-00001-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,817 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 15) (algo-2, executor 1, partition 8, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,825 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 6.0 (TID 16) (algo-2, executor 1, partition 9, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,831 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 6.0 (TID 12) in 691 ms on algo-2 (executor 1) (1/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,838 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 6.0 (TID 14) in 696 ms on algo-2 (executor 1) (2/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,863 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 6.0 (TID 17) (algo-2, executor 1, partition 10, PROCESS_LOCAL, 569999 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,868 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 6.0 (TID 10) in 729 ms on algo-2 (executor 1) (3/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,872 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 8) in 735 ms on algo-2 (executor 1) (4/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,876 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 6.0 (TID 18) (algo-2, executor 1, partition 11, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,876 INFO hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311057139211128392236498_0006_m_000008_15/part-00008-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,897 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741839_1015 src: /10.0.73.224:53128 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,940 INFO DataNode.clienttrace: src: /10.0.73.224:53128, dest: /10.0.127.243:9866, bytes: 271178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741839_1015, duration(ns): 41401832\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,940 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,948 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311057139211128392236498_0006_m_000008_15/part-00008-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,962 INFO hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311054645816974350615948_0006_m_000009_16/part-00009-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,968 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741840_1016 src: /10.0.73.224:53142 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:05,990 INFO hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_20230202131105495024308333514172_0006_m_000011_18/part-00011-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,000 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 6.0 (TID 19) (algo-2, executor 1, partition 12, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,001 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 6.0 (TID 15) in 185 ms on algo-2 (executor 1) (5/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,008 INFO hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311055752704514646030417_0006_m_000010_17/part-00010-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,013 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741841_1017 src: /10.0.73.224:53148 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,019 INFO DataNode.clienttrace: src: /10.0.73.224:53142, dest: /10.0.127.243:9866, bytes: 271640, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741840_1016, duration(ns): 49536709\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,019 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,024 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311054645816974350615948_0006_m_000009_16/part-00009-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,052 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741842_1018 src: /10.0.73.224:53150 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,070 INFO DataNode.clienttrace: src: /10.0.73.224:53148, dest: /10.0.127.243:9866, bytes: 270466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741841_1017, duration(ns): 55305058\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,070 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,073 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_20230202131105495024308333514172_0006_m_000011_18/part-00011-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,082 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 6.0 (TID 20) (algo-2, executor 1, partition 13, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,082 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 6.0 (TID 16) in 261 ms on algo-2 (executor 1) (6/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,109 INFO DataNode.clienttrace: src: /10.0.73.224:53150, dest: /10.0.127.243:9866, bytes: 405128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741842_1018, duration(ns): 54693837\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,109 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,111 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 6.0 (TID 21) (algo-2, executor 1, partition 14, PROCESS_LOCAL, 381537 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,113 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 6.0 (TID 18) in 240 ms on algo-2 (executor 1) (7/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,115 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311055752704514646030417_0006_m_000010_17/part-00010-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,117 INFO hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311056185064410812317356_0006_m_000012_19/part-00012-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,658 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741836_1012 src: /10.0.73.224:60698 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,659 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741838_1014 src: /10.0.73.224:60714 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,659 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741837_1013 src: /10.0.73.224:60696 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,668 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741835_1011 src: /10.0.73.224:60690 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,744 INFO DataNode.clienttrace: src: /10.0.73.224:60714, dest: /10.0.73.224:9866, bytes: 269523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741838_1014, duration(ns): 49489701\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,744 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,746 INFO DataNode.clienttrace: src: /10.0.73.224:60696, dest: /10.0.73.224:9866, bytes: 269735, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741837_1013, duration(ns): 51124228\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,746 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,747 INFO DataNode.clienttrace: src: /10.0.73.224:60690, dest: /10.0.73.224:9866, bytes: 404242, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741835_1011, duration(ns): 51839098\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,747 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,749 INFO DataNode.clienttrace: src: /10.0.73.224:60698, dest: /10.0.73.224:9866, bytes: 270227, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741836_1012, duration(ns): 57626703\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,749 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,895 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741839_1015 src: /10.0.73.224:60720 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,943 INFO DataNode.clienttrace: src: /10.0.73.224:60720, dest: /10.0.73.224:9866, bytes: 271178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741839_1015, duration(ns): 27054098\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,944 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:05,965 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741840_1016 src: /10.0.73.224:60736 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,011 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741841_1017 src: /10.0.73.224:60738 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,021 INFO DataNode.clienttrace: src: /10.0.73.224:60736, dest: /10.0.73.224:9866, bytes: 271640, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741840_1016, duration(ns): 44602783\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,022 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,049 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741842_1018 src: /10.0.73.224:60742 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,072 INFO DataNode.clienttrace: src: /10.0.73.224:60738, dest: /10.0.73.224:9866, bytes: 270466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741841_1017, duration(ns): 53239327\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,072 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,111 INFO DataNode.clienttrace: src: /10.0.73.224:60742, dest: /10.0.73.224:9866, bytes: 405128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741842_1018, duration(ns): 55263961\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,114 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,131 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741843_1019 src: /10.0.73.224:60750 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,197 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741844_1020 src: /10.0.73.224:60754 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,205 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741845_1021 src: /10.0.73.224:60768 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,215 INFO DataNode.clienttrace: src: /10.0.73.224:60750, dest: /10.0.73.224:9866, bytes: 271527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741843_1019, duration(ns): 40287606\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,216 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,245 INFO DataNode.clienttrace: src: /10.0.73.224:60768, dest: /10.0.73.224:9866, bytes: 270604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741845_1021, duration(ns): 28716459\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,246 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,251 INFO DataNode.clienttrace: src: /10.0.73.224:60754, dest: /10.0.73.224:9866, bytes: 271399, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741844_1020, duration(ns): 41784079\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,252 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,252 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741846_1022 src: /10.0.73.224:60784 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,271 INFO DataNode.clienttrace: src: /10.0.73.224:60784, dest: /10.0.73.224:9866, bytes: 303306, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741846_1022, duration(ns): 6890631\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,271 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.127.243:9866] terminating\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,160 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 12\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,165 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 14\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,166 INFO executor.Executor: Running task 5.0 in stage 6.0 (TID 12)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,170 INFO executor.Executor: Running task 7.0 in stage 6.0 (TID 14)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,176 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 69.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,179 INFO broadcast.TorrentBroadcast: Reading broadcast variable 9 took 20 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,181 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 193.1 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,311 INFO codegen.CodeGenerator: Code generated in 30.124973 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,339 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,339 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,340 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,340 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,339 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,346 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,341 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,347 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,346 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,347 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,349 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,349 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,346 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,348 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,347 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,353 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,683 INFO python.PythonRunner: Times: total = 52, boot = 32, init = 12, finish = 8\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,687 INFO python.PythonRunner: Times: total = 26, boot = 15, init = 4, finish = 7\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,691 INFO python.PythonRunner: Times: total = 27, boot = 13, init = 8, finish = 6\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,698 INFO python.PythonRunner: Times: total = 61, boot = 37, init = 13, finish = 11\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,804 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311054367288171515370383_0006_m_000005_12' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,804 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311056379071415974805391_0006_m_000007_14' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,804 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311054586333333113309_0006_m_000001_8' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,804 INFO output.FileOutputCommitter: Saved output of task 'attempt_20230202131105972454875105768592_0006_m_000003_10' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,805 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311054586333333113309_0006_m_000001_8: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,805 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311056379071415974805391_0006_m_000007_14: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,805 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311054367288171515370383_0006_m_000005_12: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,805 INFO mapred.SparkHadoopMapRedUtil: attempt_20230202131105972454875105768592_0006_m_000003_10: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,812 INFO executor.Executor: Finished task 5.0 in stage 6.0 (TID 12). 2879 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,812 INFO executor.Executor: Finished task 7.0 in stage 6.0 (TID 14). 2879 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,812 INFO executor.Executor: Finished task 3.0 in stage 6.0 (TID 10). 2879 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,812 INFO executor.Executor: Finished task 1.0 in stage 6.0 (TID 8). 2879 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,826 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 15\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,826 INFO executor.Executor: Running task 8.0 in stage 6.0 (TID 15)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,840 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,840 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,840 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,841 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,842 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 16\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,842 INFO executor.Executor: Running task 9.0 in stage 6.0 (TID 16)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,880 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,880 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,880 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 17\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,881 INFO executor.Executor: Running task 10.0 in stage 6.0 (TID 17)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,882 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 18\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,882 INFO executor.Executor: Running task 11.0 in stage 6.0 (TID 18)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,903 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,903 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,912 INFO python.PythonRunner: Times: total = 12, boot = -500, init = 504, finish = 8\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,941 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,941 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,941 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,941 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,960 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,961 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,961 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,961 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,973 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311057139211128392236498_0006_m_000008_15' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,973 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311057139211128392236498_0006_m_000008_15: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:05,997 INFO executor.Executor: Finished task 8.0 in stage 6.0 (TID 15). 2793 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,003 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 19\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,007 INFO python.PythonRunner: Times: total = 41, boot = -543, init = 578, finish = 6\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,008 INFO executor.Executor: Running task 12.0 in stage 6.0 (TID 19)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,031 INFO python.PythonRunner: Times: total = 21, boot = -619, init = 633, finish = 7\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,051 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311054645816974350615948_0006_m_000009_16' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,051 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311054645816974350615948_0006_m_000009_16: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,065 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,065 INFO executor.Executor: Finished task 9.0 in stage 6.0 (TID 16). 2793 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,065 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,066 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,066 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,070 INFO python.PythonRunner: Times: total = 16, boot = -593, init = 599, finish = 10\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,085 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 20\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,086 INFO executor.Executor: Running task 13.0 in stage 6.0 (TID 20)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,103 INFO output.FileOutputCommitter: Saved output of task 'attempt_20230202131105495024308333514172_0006_m_000011_18' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,103 INFO mapred.SparkHadoopMapRedUtil: attempt_20230202131105495024308333514172_0006_m_000011_18: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,108 INFO executor.Executor: Finished task 11.0 in stage 6.0 (TID 18). 2793 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,116 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 21\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,116 INFO executor.Executor: Running task 14.0 in stage 6.0 (TID 21)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,120 INFO python.PythonRunner: Times: total = 39, boot = -172, init = 202, finish = 9\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,140 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311055752704514646030417_0006_m_000010_17' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,140 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311055752704514646030417_0006_m_000010_17: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,144 INFO executor.Executor: Finished task 10.0 in stage 6.0 (TID 17). 2793 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,144 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,144 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,145 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,145 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,149 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,149 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,149 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,149 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,152 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 22\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,152 INFO executor.Executor: Running task 15.0 in stage 6.0 (TID 22)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,194 INFO python.PythonRunner: Times: total = 26, boot = -216, init = 235, finish = 7\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,208 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,208 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,210 INFO python.PythonRunner: Times: total = 30, boot = -174, init = 190, finish = 14\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,219 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,219 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,241 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311056185064410812317356_0006_m_000012_19' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,241 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311056185064410812317356_0006_m_000012_19: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,242 INFO executor.Executor: Finished task 12.0 in stage 6.0 (TID 19). 2793 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,454 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741848_1024 src: /10.0.127.243:39512 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,456 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741847_1023 src: /10.0.127.243:39542 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,456 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741849_1025 src: /10.0.127.243:39528 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,457 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741850_1026 src: /10.0.127.243:39548 dest: /10.0.73.224:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,148 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 6.0 (TID 22) (algo-2, executor 1, partition 15, PROCESS_LOCAL, 427195 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,149 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 6.0 (TID 17) in 306 ms on algo-2 (executor 1) (8/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,156 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741843_1019 src: /10.0.73.224:53162 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,189 INFO hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311057079678570213022661_0006_m_000013_20/part-00013-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,197 INFO hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311055691258562867191719_0006_m_000014_21/part-00014-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,206 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741844_1020 src: /10.0.73.224:53170 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,210 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741845_1021 src: /10.0.73.224:53186 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,214 INFO DataNode.clienttrace: src: /10.0.73.224:53162, dest: /10.0.127.243:9866, bytes: 271527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741843_1019, duration(ns): 52501534\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,214 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,219 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311056185064410812317356_0006_m_000012_19/part-00012-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,241 INFO hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=10.0.73.224:9866, 10.0.127.243:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311055314030176246788783_0006_m_000015_22/part-00015-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,242 INFO DataNode.clienttrace: src: /10.0.73.224:53186, dest: /10.0.127.243:9866, bytes: 270604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741845_1021, duration(ns): 26305819\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,246 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 6.0 (TID 19) in 247 ms on algo-2 (executor 1) (9/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,247 INFO namenode.FSNamesystem: BLOCK* blk_1073741845_1021 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311055691258562867191719_0006_m_000014_21/part-00014-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,242 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,248 INFO DataNode.clienttrace: src: /10.0.73.224:53170, dest: /10.0.127.243:9866, bytes: 271399, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741844_1020, duration(ns): 27408671\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,249 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,253 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311057079678570213022661_0006_m_000013_20/part-00013-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,262 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741846_1022 src: /10.0.73.224:53196 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,270 INFO DataNode.clienttrace: src: /10.0.73.224:53196, dest: /10.0.127.243:9866, bytes: 303306, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1385293070_40, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741846_1022, duration(ns): 4122369\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,270 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,272 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311055314030176246788783_0006_m_000015_22/part-00015-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,277 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 6.0 (TID 20) in 196 ms on algo-2 (executor 1) (10/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,289 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 6.0 (TID 22) in 141 ms on algo-2 (executor 1) (11/16)\u001b[0m\n",
      "\u001b[34moadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,517 INFO client.TransportClientFactory: Successfully created connection to algo-2/10.0.73.224:46853 after 12 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,548 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,550 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 50 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,565 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:10:59,844 INFO executor.Executor: Finished task 1.0 in stage 4.0 (TID 5). 787107 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,154 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 7\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,154 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 7)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,160 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,160 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 9\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,174 INFO executor.Executor: Running task 2.0 in stage 6.0 (TID 9)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,175 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 11\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,179 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 13\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,182 INFO executor.Executor: Running task 4.0 in stage 6.0 (TID 11)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,185 INFO executor.Executor: Running task 6.0 in stage 6.0 (TID 13)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,186 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 69.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,193 INFO broadcast.TorrentBroadcast: Reading broadcast variable 9 took 33 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:05,195 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 193.1 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,173 INFO codegen.CodeGenerator: Code generated in 75.035609 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,186 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,409 INFO hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311056316528886930452756_0006_m_000000_7/part-00000-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,410 INFO hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311057366870939151071556_0006_m_000002_9/part-00002-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,416 INFO hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311053927914158515645181_0006_m_000004_11/part-00004-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,417 INFO hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=10.0.127.243:9866, 10.0.73.224:9866 for /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311058244982978824502783_0006_m_000006_13/part-00006-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,450 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741848_1024 src: /10.0.127.243:45748 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,454 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741849_1025 src: /10.0.127.243:45758 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,454 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741847_1023 src: /10.0.127.243:45732 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,455 INFO datanode.DataNode: Receiving BP-679434436-10.0.127.243-1675343406013:blk_1073741850_1026 src: /10.0.127.243:45774 dest: /10.0.127.243:9866\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,523 INFO DataNode.clienttrace: src: /10.0.127.243:45732, dest: /10.0.127.243:9866, bytes: 271649, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1289281822_38, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741847_1023, duration(ns): 54965060\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,523 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,528 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311056316528886930452756_0006_m_000000_7/part-00000-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1289281822_38\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,528 INFO DataNode.clienttrace: src: /10.0.127.243:45748, dest: /10.0.127.243:9866, bytes: 270210, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1289281822_38, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741848_1024, duration(ns): 71491864\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,529 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,537 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311057366870939151071556_0006_m_000002_9/part-00002-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1289281822_38\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,551 INFO DataNode.clienttrace: src: /10.0.127.243:45758, dest: /10.0.127.243:9866, bytes: 269360, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1289281822_38, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741849_1025, duration(ns): 79920905\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,551 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,554 INFO DataNode.clienttrace: src: /10.0.127.243:45774, dest: /10.0.127.243:9866, bytes: 269040, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1289281822_38, offset: 0, srvID: 4b81e253-b887-4691-a79a-c4f0d69060f0, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741850_1026, duration(ns): 84398705\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,555 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.0.73.224:9866] terminating\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,555 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311053927914158515645181_0006_m_000004_11/part-00004-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1289281822_38\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,562 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311058244982978824502783_0006_m_000006_13/part-00006-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1289281822_38\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,625 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 6.0 (TID 9) in 1487 ms on algo-1 (executor 2) (12/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,627 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 6.0 (TID 13) in 1485 ms on algo-1 (executor 2) (13/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,628 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 6.0 (TID 11) in 1487 ms on algo-1 (executor 2) (14/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,635 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 1498 ms on algo-1 (executor 2) (15/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,649 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_temporary/0/_temporary/attempt_202302021311055691258562867191719_0006_m_000014_21/part-00014-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv is closed by DFSClient_NONMAPREDUCE_-1385293070_40\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,668 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 6.0 (TID 21) in 557 ms on algo-2 (executor 1) (16/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,668 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,669 INFO scheduler.DAGScheduler: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0) finished in 1.573 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,671 INFO scheduler.DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,671 INFO cluster.YarnScheduler: Killing all running tasks in stage 6: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,671 INFO scheduler.DAGScheduler: Job 5 finished: csv at NativeMethodAccessorImpl.java:0, took 1.584648 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,693 INFO hdfs.StateChange: DIR* completeFile: /tmp/energy_dataset_df/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1716286353_18\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,701 INFO datasources.FileFormatWriter: Write Job 8a15f8c6-e53e-40b6-96b5-dc144e04e65f committed.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,705 INFO datasources.FileFormatWriter: Finished processing stats for write job 8a15f8c6-e53e-40b6-96b5-dc144e04e65f.\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/applINFO:__main__:Loading weather_features.csv from path hdfs://10.0.127.243/tmp/weather_features.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,739 INFO datasources.InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,749 INFO datasources.InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,793 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,793 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#1002, None)) > 0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,794 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,808 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 317.6 KiB, free 1027.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,820 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1027.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,821 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,822 INFO spark.SparkContext: Created broadcast 10 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,823 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 5, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,824 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,5))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,834 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,835 INFO scheduler.DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,835 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,835 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,836 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,838 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[34] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,845 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.9 KiB, free 1027.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,847 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1027.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,847 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.127.243:34087 (size: 5.5 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,848 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,849 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[34] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,849 INFO cluster.YarnScheduler: Adding task set 7.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,851 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 23) (algo-2, executor 1, partition 0, NODE_LOCAL, 5150 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,863 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-2:46853 (size: 5.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,901 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-2:46853 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,920 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 23) in 70 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,920 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,921 INFO scheduler.DAGScheduler: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0) finished in 0.082 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,921 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,921 INFO cluster.YarnScheduler: Killing all running tasks in stage 7: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,921 INFO scheduler.DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.087026 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,934 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,934 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,934 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,940 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 317.6 KiB, free 1027.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,952 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1027.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,953 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,954 INFO spark.SparkContext: Created broadcast 12 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,955 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 5, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:06,955 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,5))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,074 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-2:46853 in memory (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,080 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.127.243:34087 in memory (size: 30.3 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,104 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.127.243:34087 in memory (size: 30.3 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,522 INFO DataNode.clienttrace: src: /10.0.127.243:39542, dest: /10.0.73.224:9866, bytes: 271649, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1289281822_38, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741847_1023, duration(ns): 63186491\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,522 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,527 INFO DataNode.clienttrace: src: /10.0.127.243:39512, dest: /10.0.73.224:9866, bytes: 270210, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1289281822_38, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741848_1024, duration(ns): 72350391\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,527 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,550 INFO DataNode.clienttrace: src: /10.0.127.243:39528, dest: /10.0.73.224:9866, bytes: 269360, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1289281822_38, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741849_1025, duration(ns): 92436339\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,550 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,551 INFO DataNode.clienttrace: src: /10.0.127.243:39548, dest: /10.0.73.224:9866, bytes: 269040, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1289281822_38, offset: 0, srvID: f7374d5e-7d40-4091-8c9c-2ed23a592adf, blockid: BP-679434436-10.0.127.243-1675343406013:blk_1073741850_1026, duration(ns): 91958761\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:06,551 INFO datanode.DataNode: PacketResponder: BP-679434436-10.0.127.243-1675343406013:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,254 INFO python.PythonRunner: Times: total = 31, boot = -214, init = 237, finish = 8\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,273 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311057079678570213022661_0006_m_000013_20' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,273 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311057079678570213022661_0006_m_000013_20: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,275 INFO executor.Executor: Finished task 13.0 in stage 6.0 (TID 20). 2793 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,285 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311055314030176246788783_0006_m_000015_22' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,285 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311055314030176246788783_0006_m_000015_22: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,286 INFO executor.Executor: Finished task 15.0 in stage 6.0 (TID 22). 2793 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,663 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311055691258562867191719_0006_m_000014_21' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,663 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311055691258562867191719_0006_m_000014_21: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,664 INFO executor.Executor: Finished task 14.0 in stage 6.0 (TID 21). 2793 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,853 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 23\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,853 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 23)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,856 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,861 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,863 INFO broadcast.TorrentBroadcast: Reading broadcast variable 11 took 7 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,865 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,882 INFO codegen.CodeGenerator: Code generated in 9.477142 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,138 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-2:46853 in memory (size: 5.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,148 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.127.243:34087 in memory (size: 5.5 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,170 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-2:46853 in memory (size: 69.9 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,171 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.127.243:34087 in memory (size: 69.9 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,179 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:35681 in memory (size: 69.9 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34mication_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,186 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,187 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,187 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,197 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,198 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,196 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,198 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,199 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,190 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,202 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,203 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,203 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,199 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,207 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,207 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,498 INFO python.PythonRunner: Times: total = 724, boot = 641, init = 73, finish = 10\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,516 INFO python.PythonRunner: Times: total = 673, boot = 636, init = 23, finish = 14\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,544 INFO python.PythonRunner: Times: total = 711, boot = 664, init = 39, finish = 8\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,320 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,320 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,321 INFO datasources.FileSourceStrategy: Output Data Schema: struct<dt_iso: string, city_name: string, temp: string, temp_min: string, temp_max: string ... 15 more fields>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,416 INFO codegen.CodeGenerator: Code generated in 26.581458 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,422 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 317.5 KiB, free 1028.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,435 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1028.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,436 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,437 INFO spark.SparkContext: Created broadcast 13 from showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,439 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 5, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,439 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,5))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,467 INFO codegen.CodeGenerator: Code generated in 11.6536 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,508 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,515 INFO scheduler.DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 5 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,515 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,515 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,515 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,516 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[46] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,520 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 30.3 KiB, free 1028.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,522 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 1028.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,522 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.127.243:34087 (size: 10.8 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,523 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,524 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 8 (MapPartitionsRDD[46] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,524 INFO cluster.YarnScheduler: Adding task set 8.0 with 5 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,526 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 24) (algo-1, executor 2, partition 0, NODE_LOCAL, 5150 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,526 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 25) (algo-2, executor 1, partition 1, NODE_LOCAL, 5150 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,526 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 8.0 (TID 26) (algo-1, executor 2, partition 2, NODE_LOCAL, 5150 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,527 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 8.0 (TID 27) (algo-2, executor 1, partition 3, NODE_LOCAL, 5150 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,527 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 8.0 (TID 28) (algo-1, executor 2, partition 4, NODE_LOCAL, 5150 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,693 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-2:46853 (size: 10.8 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,782 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:35681 (size: 10.8 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:07,785 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-2:46853 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:08,017 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:35681 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,884 INFO datasources.FileScanRDD: TID: 23 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 0-4194304, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,893 INFO codegen.CodeGenerator: Code generated in 6.90941 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,895 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,900 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,902 INFO broadcast.TorrentBroadcast: Reading broadcast variable 10 took 6 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,909 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:06,918 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 23). 1664 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,644 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 25\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,644 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 27\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,644 INFO executor.Executor: Running task 1.0 in stage 8.0 (TID 25)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,644 INFO executor.Executor: Running task 3.0 in stage 8.0 (TID 27)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,646 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 14 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,691 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,694 INFO broadcast.TorrentBroadcast: Reading broadcast variable 14 took 48 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,695 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,742 INFO codegen.CodeGenerator: Code generated in 22.734093 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,759 INFO codegen.CodeGenerator: Code generated in 6.907509 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,762 INFO datasources.FileScanRDD: TID: 25 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 4194304-8388608, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,544 INFO python.PythonRunner: Times: total = 711, boot = 657, init = 46, finish = 8\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,609 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311053927914158515645181_0006_m_000004_11' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,609 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311056316528886930452756_0006_m_000000_7' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,610 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311053927914158515645181_0006_m_000004_11: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,610 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311056316528886930452756_0006_m_000000_7: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,611 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311058244982978824502783_0006_m_000006_13' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,611 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311058244982978824502783_0006_m_000006_13: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,613 INFO output.FileOutputCommitter: Saved output of task 'attempt_202302021311057366870939151071556_0006_m_000002_9' to hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,613 INFO mapred.SparkHadoopMapRedUtil: attempt_202302021311057366870939151071556_0006_m_000002_9: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,617 INFO executor.Executor: Finished task 4.0 in stage 6.0 (TID 11). 2836 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,618 INFO executor.Executor: Finished task 2.0 in stage 6.0 (TID 9). 2836 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,617 INFO executor.Executor: Finished task 6.0 in stage 6.0 (TID 13). 2836 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:06,626 INFO executor.Executor: Finished task 0.0 in stage 6.0 (TID 7). 2836 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,530 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 24\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,531 INFO executor.Executor: Running task 0.0 in stage 8.0 (TID 24)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,533 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 14 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,550 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 26\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:09,173 INFO storage.BlockManagerInfo: Added taskresult_27 in memory on algo-2:46853 (size: 1193.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:09,177 INFO storage.BlockManagerInfo: Added taskresult_25 in memory on algo-2:46853 (size: 1227.7 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:09,289 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 25) in 1763 ms on algo-2 (executor 1) (1/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:09,293 INFO storage.BlockManagerInfo: Removed taskresult_25 on algo-2:46853 in memory (size: 1227.7 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:09,330 INFO storage.BlockManagerInfo: Removed taskresult_27 on algo-2:46853 in memory (size: 1193.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:09,333 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 8.0 (TID 27) in 1805 ms on algo-2 (executor 1) (2/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:09,823 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 8.0 (TID 28) in 2296 ms on algo-1 (executor 2) (3/5)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,762 INFO datasources.FileScanRDD: TID: 27 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 12582912-16777216, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,773 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 13 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,784 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,786 INFO broadcast.TorrentBroadcast: Reading broadcast variable 13 took 12 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:07,797 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:09,171 INFO memory.MemoryStore: Block taskresult_27 stored as bytes in memory (estimated size 1193.5 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:09,174 INFO memory.MemoryStore: Block taskresult_25 stored as bytes in memory (estimated size 1227.7 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:09,175 INFO executor.Executor: Finished task 3.0 in stage 8.0 (TID 27). 1222095 bytes result sent via BlockManager)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:09,181 INFO executor.Executor: Finished task 1.0 in stage 8.0 (TID 25). 1257212 bytes result sent via BlockManager)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,390 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 29\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,390 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 31\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,390 INFO executor.Executor: Running task 0.0 in stage 9.0 (TID 29)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,390 INFO executor.Executor: Running task 2.0 in stage 9.0 (TID 31)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,391 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 33\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,391 INFO executor.Executor: Running task 4.0 in stage 9.0 (TID 33)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,392 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 15 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,400 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.5 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,402 INFO broadcast.TorrentBroadcast: Reading broadcast variable 15 took 10 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,403 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 64.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,443 INFO codegen.CodeGenerator: Code generated in 9.723711 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,470 INFO datasources.FileScanRDD: TID: 29 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 0-4194304, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,471 INFO datasources.FileScanRDD: TID: 33 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 16777216-19918887, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:10,470 INFO datasources.FileScanRDD: TID: 31 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 8388608-12582912, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:11,936 INFO executor.Executor: Finished task 0.0 in stage 9.0 (TID 29). 3868 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:11,948 INFO executor.Executor: Finished task 4.0 in stage 9.0 (TID 33). 3868 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,152 INFO executor.Executor: Finished task 2.0 in stage 9.0 (TID 31). 3868 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,498 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 34\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,498 INFO executor.Executor: Running task 0.0 in stage 11.0 (TID 34)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,502 INFO spark.MapOutputTrackerWorker: Updating epoch to 2 and clearing cache\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,504 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 16 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,510 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 40.6 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,512 INFO broadcast.TorrentBroadcast: Reading broadcast variable 16 took 8 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,513 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 118.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,705 INFO codegen.CodeGenerator: Code generated in 99.984201 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,730 INFO codegen.CodeGenerator: Code generated in 11.603132 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,742 INFO codegen.CodeGenerator: Code generated in 7.075666 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,777 INFO codegen.CodeGenerator: Code generated in 15.693491 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,818 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,818 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.127.243:42921)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,822 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,826 INFO storage.ShuffleBlockFetcherIterator: Getting 4 (252.1 KiB) non-empty blocks including 2 (150.0 KiB) local and 0 (0.0 B) host-local and 2 (102.1 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,827 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 3 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,840 INFO codegen.CodeGenerator: Code generated in 12.84156 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,857 INFO codegen.CodeGenerator: Code generated in 6.417591 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:12,902 INFO codegen.CodeGenerator: Code generated in 6.030841 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,001 INFO storage.ShuffleBlockFetcherIterator: Getting 4 (284.8 KiB) non-empty blocks including 2 (147.4 KiB) local and 0 (0.0 B) host-local and 2 (137.4 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,001 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 2 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,057 INFO storage.ShuffleBlockFetcherIterator: Getting 4 (241.5 KiB) non-empty blocks including 2 (108.0 KiB) local and 0 (0.0 B) host-local and 2 (133.4 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,058 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 2 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,096 INFO storage.ShuffleBlockFetcherIterator: Getting 4 (276.1 KiB) non-empty blocks including 2 (160.4 KiB) local and 0 (0.0 B) host-local and 2 (115.8 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,097 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,128 INFO storage.ShuffleBlockFetcherIterator: Getting 4 (284.5 KiB) non-empty blocks including 2 (124.3 KiB) local and 0 (0.0 B) host-local and 2 (160.2 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,128 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,157 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (283.1 KiB) non-empty blocks including 3 (173.3 KiB) local and 0 (0.0 B) host-local and 2 (109.8 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,158 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,183 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (299.0 KiB) non-empty blocks including 3 (182.6 KiB) local and 0 (0.0 B) host-local and 2 (116.3 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,184 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,204 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (307.7 KiB) non-empty blocks including 3 (189.7 KiB) local and 0 (0.0 B) host-local and 2 (118.0 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,204 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,227 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (299.1 KiB) non-empty blocks including 3 (179.9 KiB) local and 0 (0.0 B) host-local and 2 (119.2 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,227 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,248 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (263.4 KiB) non-empty blocks including 3 (154.7 KiB) local and 0 (0.0 B) host-local and 2 (108.7 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,248 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,262 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (278.2 KiB) non-empty blocks including 3 (164.3 KiB) local and 0 (0.0 B) host-local and 2 (113.9 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,263 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,281 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (222.3 KiB) non-empty blocks including 3 (132.7 KiB) local and 0 (0.0 B) host-local and 2 (89.6 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,282 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,302 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (251.5 KiB) non-empty blocks including 3 (149.4 KiB) local and 0 (0.0 B) host-local and 2 (102.1 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,302 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,319 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (253.7 KiB) non-empty blocks including 3 (151.3 KiB) local and 0 (0.0 B) host-local and 2 (102.4 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,319 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,336 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (265.2 KiB) non-empty blocks including 3 (157.6 KiB) local and 0 (0.0 B) host-local and 2 (107.6 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,336 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,349 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (266.6 KiB) non-empty blocks including 3 (156.7 KiB) local and 0 (0.0 B) host-local and 2 (109.9 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,350 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,365 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (256.9 KiB) non-empty blocks including 3 (151.9 KiB) local and 0 (0.0 B) host-local and 2 (105.0 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,365 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,375 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (262.2 KiB) non-empty blocks including 3 (156.6 KiB) local and 0 (0.0 B) host-local and 2 (105.6 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,376 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,385 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (264.2 KiB) non-empty blocks including 3 (156.7 KiB) local and 0 (0.0 B) host-local and 2 (107.5 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,386 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,397 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (258.1 KiB) non-empty blocks including 3 (152.8 KiB) local and 0 (0.0 B) host-local and 2 (105.3 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,397 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,407 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (267.0 KiB) non-empty blocks including 3 (157.9 KiB) local and 0 (0.0 B) host-local and 2 (109.1 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,408 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,417 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (265.5 KiB) non-empty blocks including 3 (155.3 KiB) local and 0 (0.0 B) host-local and 2 (110.2 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,417 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,429 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (260.6 KiB) non-empty blocks including 3 (152.8 KiB) local and 0 (0.0 B) host-local and 2 (107.9 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,430 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,440 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (266.3 KiB) non-empty blocks including 3 (157.3 KiB) local and 0 (0.0 B) host-local and 2 (109.0 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,440 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,455 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (256.0 KiB) non-empty blocks including 3 (151.5 KiB) local and 0 (0.0 B) host-local and 2 (104.5 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,456 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,467 INFO storage.ShuffleBlockFetcherIterator: Getting 5 (77.7 KiB) non-empty blocks including 3 (47.3 KiB) local and 0 (0.0 B) host-local and 2 (30.4 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,468 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:13,572 INFO executor.Executor: Finished task 0.0 in stage 11.0 (TID 34). 3977 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,060 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 35\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,060 INFO executor.Executor: Running task 0.0 in stage 12.0 (TID 35)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,062 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 18 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,066 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,068 INFO broadcast.TorrentBroadcast: Reading broadcast variable 18 took 6 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,069 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,071 INFO datasources.FileScanRDD: TID: 35 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00010-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-405128, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,072 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 17 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,134 INFO storage.BlockManagerInfo: Added taskresult_24 in memory on algo-1:35681 (size: 1211.8 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,140 INFO storage.BlockManagerInfo: Added taskresult_26 in memory on algo-1:35681 (size: 1227.2 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,146 INFO client.TransportClientFactory: Successfully created connection to algo-1/10.0.127.243:35681 after 3 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,178 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 8.0 (TID 26) in 2652 ms on algo-1 (executor 2) (4/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,183 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 24) in 2658 ms on algo-1 (executor 2) (5/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,184 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,185 INFO scheduler.DAGScheduler: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0) finished in 2.666 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,185 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,185 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,186 INFO scheduler.DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 2.677233 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,195 INFO storage.BlockManagerInfo: Removed taskresult_26 on algo-1:35681 in memory (size: 1227.2 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,196 INFO storage.BlockManagerInfo: Removed taskresult_24 on algo-1:35681 in memory (size: 1211.8 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,551 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 28\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,551 INFO executor.Executor: Running task 2.0 in stage 8.0 (TID 26)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,555 INFO executor.Executor: Running task 4.0 in stage 8.0 (TID 28)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,779 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,783 INFO broadcast.TorrentBroadcast: Reading broadcast variable 14 took 250 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,787 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,939 INFO codegen.CodeGenerator: Code generated in 71.0759 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,978 INFO codegen.CodeGenerator: Code generated in 25.551047 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,981 INFO datasources.FileScanRDD: TID: 28 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 16777216-19918887, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,982 INFO datasources.FileScanRDD: TID: 24 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 0-4194304, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:07,986 INFO datasources.FileScanRDD: TID: 26 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 8388608-12582912, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:08,003 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 13 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:08,015 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:08,018 INFO broadcast.TorrentBroadcast: Reading broadcast variable 13 took 14 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:08,029 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:09,795 INFO executor.Executor: Finished task 4.0 in stage 8.0 (TID 28). 947553 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,132 INFO memory.MemoryStore: Block taskresult_24 stored as bytes in memory (estimated size 1211.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,326 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-2:46853 in memory (size: 10.8 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,329 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:35681 in memory (size: 10.8 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,336 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.127.243:34087 in memory (size: 10.8 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,366 INFO scheduler.DAGScheduler: Registering RDD 47 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,367 INFO scheduler.DAGScheduler: Got map stage job 8 (showString at NativeMethodAccessorImpl.java:0) with 5 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,367 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,367 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,367 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,368 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,380 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 64.8 KiB, free 1028.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,382 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.5 KiB, free 1028.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,382 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.127.243:34087 (size: 20.5 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,383 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,384 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,384 INFO cluster.YarnScheduler: Adding task set 9.0 with 5 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,385 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 29) (algo-2, executor 1, partition 0, NODE_LOCAL, 4882 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,386 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 9.0 (TID 30) (algo-1, executor 2, partition 1, NODE_LOCAL, 4882 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,386 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 9.0 (TID 31) (algo-2, executor 1, partition 2, NODE_LOCAL, 4882 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,387 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 9.0 (TID 32) (algo-1, executor 2, partition 3, NODE_LOCAL, 4882 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,387 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 9.0 (TID 33) (algo-2, executor 1, partition 4, NODE_LOCAL, 4882 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,401 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-2:46853 (size: 20.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:10,404 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:35681 (size: 20.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:11,562 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 9.0 (TID 30) in 1176 ms on algo-1 (executor 2) (1/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:11,568 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 9.0 (TID 32) in 1182 ms on algo-1 (executor 2) (2/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:11,939 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 29) in 1554 ms on algo-2 (executor 1) (3/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:11,962 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 9.0 (TID 33) in 1575 ms on algo-2 (executor 1) (4/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,154 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 9.0 (TID 31) in 1768 ms on algo-2 (executor 1) (5/5)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,155 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,155 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 1.785 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,155 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,155 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,155 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,155 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,173 INFO adaptive.ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1122832.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,360 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-2:46853 in memory (size: 20.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,377 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:35681 in memory (size: 20.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,378 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.127.243:34087 in memory (size: 20.5 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,387 INFO codegen.CodeGenerator: Code generated in 128.559415 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,404 INFO codegen.CodeGenerator: Code generated in 13.159563 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,476 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,478 INFO scheduler.DAGScheduler: Got job 9 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,478 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,478 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,478 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,479 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[53] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,487 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 118.8 KiB, free 1028.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,489 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 40.6 KiB, free 1028.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,490 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.127.243:34087 (size: 40.6 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,490 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,491 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[53] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,491 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,495 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 34) (algo-2, executor 1, partition 0, PROCESS_LOCAL, 5581 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,511 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-2:46853 (size: 40.6 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:12,819 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.73.224:45848\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,574 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 34) in 1082 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,574 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,574 INFO scheduler.DAGScheduler: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0) finished in 1.093 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,575 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,575 INFO cluster.YarnScheduler: Killing all running tasks in stage 11: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,576 INFO scheduler.DAGScheduler: Job 9 finished: showString at NativeMethodAccessorImpl.java:0, took 1.099812 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,595 INFO codegen.CodeGenerator: Code generated in 13.199909 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,138 INFO executor.Executor: Finished task 0.0 in stage 8.0 (TID 24). 1240929 bytes result sent+---------+-------+--------+--------+--------+--------+----------+--------+-------+-------+-------+----------+----------+------------+-------------------+------------+-------------------+\u001b[0m\n",
      "\u001b[34m|city_name|   temp|temp_min|temp_max|pressure|humidity|wind_speed|wind_deg|rain_1h|rain_3h|snow_3h|clouds_all|weather_id|weather_main|weather_description|weather_icon|               time|\u001b[0m\n",
      "\u001b[34m+---------+-------+--------+--------+--------+--------+----------+--------+-------+-------+-------+----------+----------+------------+-------------------+------------+-------------------+\u001b[0m\n",
      "\u001b[34m|     null|270.475| 270.475| 270.475|  1001.0|    77.0|       1.0|    62.0|    0.0|    0.0|    0.0|       0.0|     800.0|        null|               null|        null|2014-12-31 23:00:00|\u001b[0m\n",
      "\u001b[34m+---------+-------+--------+--------+--------+--------+----------+--------+-------+-------+-------+----------+----------+------------+-------------------+------------+-------------------+\u001b[0m\n",
      "\u001b[34monly showing top 1 row\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,724 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.127.243:34087 in memory (size: 40.6 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,725 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-2:46853 in memory (size: 40.6 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Loading energy_dataset_df from path hdfs://10.0.127.243/tmp/energy_dataset_df\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,932 INFO datasources.InMemoryFileIndex: It took 11 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:13,965 INFO datasources.InMemoryFileIndex: It took 25 ms to list leaf files for 16 paths.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,004 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,004 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#1802, None)) > 0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,004 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,013 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 317.6 KiB, free 1027.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,034 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,034 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,035 INFO spark.SparkContext: Created broadcast 17 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,038 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4483631 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 16, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,038 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,16))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,047 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,048 INFO scheduler.DAGScheduler: Got job 10 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,048 INFO scheduler.DAGScheduler: Final stage: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,048 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,048 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,049 INFO scheduler.DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[57] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,052 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.9 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,054 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,054 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.127.243:34087 (size: 5.5 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,055 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,056 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[57] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,056 INFO cluster.YarnScheduler: Adding task set 12.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,057 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 35) (algo-2, executor 1, partition 0, NODE_LOCAL, 5204 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,068 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-2:46853 (size: 5.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,076 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-2:46853 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,093 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 35) in 36 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,093 INFO cluster.YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,094 INFO scheduler.DAGScheduler: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0) finished in 0.044 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,095 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,095 INFO cluster.YarnScheduler: Killing all running tasks in stage 12: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,096 INFO scheduler.DAGScheduler: Job 10 finished: csv at NativeMethodAccessorImpl.java:0, took 0.048989 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,108 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,108 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,109 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,112 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 317.6 KiB, free 1027.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,120 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1027.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,121 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,121 INFO spark.SparkContext: Created broadcast 19 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,124 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4483631 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 16, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,125 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,16))\u001b[0m\n",
      "\u001b[34m02-02 13:11 sagemaker-spark-event-logs-publisher INFO     Got spark event logs file: application_1675343413375_0001.inprogress\u001b[0m\n",
      "\u001b[34m02-02 13:11 root         INFO     copying /tmp/spark-events/application_1675343413375_0001.inprogress to /opt/ml/processing/spark-events/application_1675343413375_0001\u001b[0m\n",
      "\u001b[34mINFO:__main__:Writing output file energy_full.csv to s3://sagemaker-eu-west-1-691148928602/electricity-forecasting/data/output\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,372 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.127.243:34087 in memory (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,393 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-2:46853 in memory (size: 5.5 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,397 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.127.243:34087 in memory (size: 5.5 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,423 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-2:46853 in memory (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,423 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.127.243:34087 in memory (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,525 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,542 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:14,542 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:15,788 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:15,788 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:15,788 INFO datasources.FileSourceStrategy: Output Data Schema: struct<time: string, generation biomass: string, generation fossil brown coal/lignite: string, generation fossil gas: string, generation fossil hard coal: string ... 16 more fields>\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,188 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,188 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,189 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,189 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,547 INFO codegen.CodeGenerator: Code generated in 24.913289 ms\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,550 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 317.5 KiB, free 1027.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,560 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,560 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.127.243:34087 (size: 30.3 KiB, free: 1028.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,561 INFO spark.SparkContext: Created broadcast 20 from save at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,566 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4483631 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 16, prefetch: false\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,566 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,16))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,572 INFO scheduler.DAGScheduler: Registering RDD 67 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,572 INFO scheduler.DAGScheduler: Got map stage job 11 (save at NativeMethodAccessorImpl.java:0) with 16 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,572 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 13 (save at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,573 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,573 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,573 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[67] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,580 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 37.7 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,582 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 1027.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,582 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.127.243:34087 (size: 11.7 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,583 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,583 INFO scheduler.DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[67] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,583 INFO cluster.YarnScheduler: Adding task set 13.0 with 16 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,585 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 36) (algo-2, executor 1, partition 0, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,586 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 13.0 (TID 37) (algo-1, executor 2, partition 1, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,586 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 13.0 (TID 38) (algo-2, executor 1, partition 2, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,587 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 13.0 (TID 39) (algo-1, executor 2, partition 3, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,587 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 13.0 (TID 40) (algo-2, executor 1, partition 4, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,588 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 13.0 (TID 41) (algo-1, executor 2, partition 5, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,588 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 13.0 (TID 42) (algo-2, executor 1, partition 6, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,589 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 13.0 (TID 43) (algo-1, executor 2, partition 7, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,602 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:35681 (size: 11.7 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,634 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-2:46853 (size: 11.7 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,685 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-2:46853 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,689 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:35681 (size: 30.3 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,786 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 13.0 (TID 44) (algo-1, executor 2, partition 8, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,788 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 13.0 (TID 37) in 203 ms on algo-1 (executor 2) (1/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,798 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 13.0 (TID 45) (algo-2, executor 1, partition 9, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,804 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 13.0 (TID 40) in 217 ms on algo-2 (executor 1) (2/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,813 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 13.0 (TID 46) (algo-2, executor 1, partition 10, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,814 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 13.0 (TID 42) in 226 ms on algo-2 (executor 1) (3/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,816 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 36) in 231 ms on algo-2 (executor 1) (4/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,817 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 13.0 (TID 47) (algo-2, executor 1, partition 11, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,819 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 13.0 (TID 38) in 233 ms on algo-2 (executor 1) (5/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,821 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 13.0 (TID 48) (algo-2, executor 1, partition 12, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,844 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 13.0 (TID 49) (algo-1, executor 2, partition 13, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,846 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 13.0 (TID 39) in 259 ms on algo-1 (executor 2) (6/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,851 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 13.0 (TID 50) (algo-1, executor 2, partition 14, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,853 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 13.0 (TID 43) in 264 ms on algo-1 (executor 2) (7/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,871 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 13.0 (TID 51) (algo-2, executor 1, partition 15, NODE_LOCAL, 4936 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,872 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 13.0 (TID 45) in 73 ms on algo-2 (executor 1) (8/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,896 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 13.0 (TID 41) in 308 ms on algo-1 (executor 2) (9/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,902 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 13.0 (TID 47) in 85 ms on algo-2 (executor 1) (10/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,910 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 13.0 (TID 48) in 89 ms on algo-2 (executor 1) (11/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,926 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 13.0 (TID 46) in 113 ms on algo-2 (executor 1) (12/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,932 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 13.0 (TID 51) in 61 ms on algo-2 (executor 1) (13/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,934 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 13.0 (TID 44) in 149 ms on algo-1 (executor 2) (14/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,967 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 13.0 (TID 50) in 116 ms on algo-1 (executor 2) (15/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,976 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 13.0 (TID 49) in 132 ms on algo-1 (executor 2) (16/16)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,977 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (save at NativeMethodAccessorImpl.java:0) finished in 0.402 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,978 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,979 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,978 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,979 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:16,979 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,096 INFO spark.SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,097 INFO scheduler.DAGScheduler: Got job 12 (save at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,097 INFO scheduler.DAGScheduler: Final stage: ResultStage 15 (save at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,097 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,097 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,098 INFO scheduler.DAGScheduler: Submitting ResultStage 15 (ShuffledRowRDD[68] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,127 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 188.6 KiB, free 1027.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,131 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 67.9 KiB, free 1027.5 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,075 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,077 INFO broadcast.TorrentBroadcast: Reading broadcast variable 17 took 5 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,084 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:14,091 INFO executor.Executor: Finished task 0.0 in stage 12.0 (TID 35). 1777 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,591 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 36\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,592 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 38\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,592 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 40\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,592 INFO executor.Executor: Running task 2.0 in stage 13.0 (TID 38)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,592 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 42\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,592 INFO executor.Executor: Running task 0.0 in stage 13.0 (TID 36)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,592 INFO executor.Executor: Running task 6.0 in stage 13.0 (TID 42)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,594 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 21 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,594 INFO executor.Executor: Running task 4.0 in stage 13.0 (TID 40)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,633 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,635 INFO broadcast.TorrentBroadcast: Reading broadcast variable 21 took 40 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,636 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 37.7 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,667 INFO codegen.CodeGenerator: Code generated in 27.210928 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,671 INFO datasources.FileScanRDD: TID: 42 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00013-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-271399, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,671 INFO datasources.FileScanRDD: TID: 36 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00010-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-405128, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,671 INFO datasources.FileScanRDD: TID: 40 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00009-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-271640, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,672 INFO datasources.FileScanRDD: TID: 38 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00015-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-303306, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,676 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 20 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,683 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,685 INFO broadcast.TorrentBroadcast: Reading broadcast variable 20 took 9 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,693 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,796 INFO executor.Executor: Finished task 4.0 in stage 13.0 (TID 40). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,798 INFO executor.Executor: Finished task 0.0 in stage 13.0 (TID 36). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,799 INFO executor.Executor: Finished task 2.0 in stage 13.0 (TID 38). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,799 INFO executor.Executor: Finished task 6.0 in stage 13.0 (TID 42). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,809 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 45\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,810 INFO executor.Executor: Running task 9.0 in stage 13.0 (TID 45)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,814 INFO datasources.FileScanRDD: TID: 45 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00011-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-270466, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,815 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 46\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,816 INFO executor.Executor: Running task 10.0 in stage 13.0 (TID 46)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,818 INFO datasources.FileScanRDD: TID: 46 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00001-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-270227, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,819 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 47\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,819 INFO executor.Executor: Running task 11.0 in stage 13.0 (TID 47)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,822 INFO datasources.FileScanRDD: TID: 47 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00002-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-270210, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,823 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 48\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,823 INFO executor.Executor: Running task 12.0 in stage 13.0 (TID 48)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,826 INFO datasources.FileScanRDD: TID: 48 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00007-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-269735, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,868 INFO executor.Executor: Finished task 9.0 in stage 13.0 (TID 45). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,873 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 51\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,873 INFO executor.Executor: Running task 15.0 in stage 13.0 (TID 51)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,886 INFO datasources.FileScanRDD: TID: 51 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00006-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-269040, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,899 INFO executor.Executor: Finished task 11.0 in stage 13.0 (TID 47). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,907 INFO executor.Executor: Finished task 12.0 in stage 13.0 (TID 48). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,924 INFO executor.Executor: Finished task 10.0 in stage 13.0 (TID 46). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:16,929 INFO executor.Executor: Finished task 15.0 in stage 13.0 (TID 51). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,149 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 52\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,149 INFO executor.Executor: Running task 0.0 in stage 15.0 (TID 52)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,150 INFO spark.MapOutputTrackerWorker: Updating epoch to 3 and clearing cache\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,141 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.127.243:34087 (size: 67.9 KiB, free: 1028.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,142 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1479\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,145 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (ShuffledRowRDD[68] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,145 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,147 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 52) (algo-2, executor 1, partition 0, NODE_LOCAL, 4721 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,156 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-2:46853 (size: 67.9 KiB, free: 6.3 GiB)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:17,167 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.73.224:45848\n",
      " via BlockManager)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,138 INFO memory.MemoryStore: Block taskresult_26 stored as bytes in memory (estimated size 1227.2 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,141 INFO executor.Executor: Finished task 2.0 in stage 8.0 (TID 26). 1256681 bytes result sent via BlockManager)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,390 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 30\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,391 INFO executor.Executor: Running task 1.0 in stage 9.0 (TID 30)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,391 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 32\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,391 INFO executor.Executor: Running task 3.0 in stage 9.0 (TID 32)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,393 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 15 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,403 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.5 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,405 INFO broadcast.TorrentBroadcast: Reading broadcast variable 15 took 10 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,407 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 64.8 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,466 INFO codegen.CodeGenerator: Code generated in 18.174219 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,499 INFO datasources.FileScanRDD: TID: 30 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 4194304-8388608, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:10,502 INFO datasources.FileScanRDD: TID: 32 - Reading current file: path: hdfs://10.0.127.243/tmp/weather_features.csv, range: 12582912-16777216, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:11,559 INFO executor.Executor: Finished task 1.0 in stage 9.0 (TID 30). 3868 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:11,566 INFO executor.Executor: Finished task 3.0 in stage 9.0 (TID 32). 3868 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,592 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 37\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,592 INFO executor.Executor: Running task 1.0 in stage 13.0 (TID 37)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,593 INFO spark.MapOutputTrackerWorker: Updating epoch to 2 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,594 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 21 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,600 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,602 INFO broadcast.TorrentBroadcast: Reading broadcast variable 21 took 8 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,603 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 37.7 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,613 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 39\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,613 INFO executor.Executor: Running task 3.0 in stage 13.0 (TID 39)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,631 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 41\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,631 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 43\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,631 INFO executor.Executor: Running task 5.0 in stage 13.0 (TID 41)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,635 INFO executor.Executor: Running task 7.0 in stage 13.0 (TID 43)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,659 INFO codegen.CodeGenerator: Code generated in 49.601502 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,662 INFO datasources.FileScanRDD: TID: 37 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00005-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-404242, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,662 INFO datasources.FileScanRDD: TID: 41 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00012-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-271527, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,663 INFO datasources.FileScanRDD: TID: 39 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00000-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-271649, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,663 INFO datasources.FileScanRDD: TID: 43 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00008-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-271178, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,681 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 20 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,688 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,696 INFO broadcast.TorrentBroadcast: Reading broadcast variable 20 took 14 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,703 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 445.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,783 INFO executor.Executor: Finished task 1.0 in stage 13.0 (TID 37). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,791 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 44\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,791 INFO executor.Executor: Running task 8.0 in stage 13.0 (TID 44)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,804 INFO datasources.FileScanRDD: TID: 44 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00014-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-270604, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,841 INFO executor.Executor: Finished task 3.0 in stage 13.0 (TID 39). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,848 INFO executor.Executor: Finished task 7.0 in stage 13.0 (TID 43). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,849 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 49\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,851 INFO executor.Executor: Running task 13.0 in stage 13.0 (TID 49)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,854 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 50\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,854 INFO executor.Executor: Running task 14.0 in stage 13.0 (TID 50)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,859 INFO datasources.FileScanRDD: TID: 50 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00004-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-269360, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,868 INFO datasources.FileScanRDD: TID: 49 - Reading current file: path: hdfs://10.0.127.243/tmp/energy_dataset_df/part-00003-cb7fee08-c3ce-486a-b941-c6b7c62006a5-c000.csv, range: 0-269523, partition values: [empty row], isDataPresent: false, eTag: null\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,876 INFO executor.Executor: Finished task 5.0 in stage 13.0 (TID 41). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,921 INFO executor.Executor: Finished task 8.0 in stage 13.0 (TID 44). 1766 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:19,387 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 52) in 2240 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:19,387 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:19,388 INFO scheduler.DAGScheduler: ResultStage 15 (save at NativeMethodAccessorImpl.java:0) finished in 2.289 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:19,388 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:19,388 INFO cluster.YarnScheduler: Killing all running tasks in stage 15: Stage finished\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:19,388 INFO scheduler.DAGScheduler: Job 12 finished: save at NativeMethodAccessorImpl.java:0, took 2.292348 s\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:19,907 INFO datasources.FileFormatWriter: Write Job 665cc8cc-fe26-4518-94ef-1bffd4a9f8ba committed.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:19,907 INFO datasources.FileFormatWriter: Finished processing stats for write job 665cc8cc-fe26-4518-94ef-1bffd4a9f8ba.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,012 INFO spark.SparkContext: Invoking stop() from shutdown hook\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,020 INFO server.AbstractConnector: Stopped Spark@3cd5f0c0{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,021 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.127.243:4040\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,024 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,040 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,040 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,045 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,062 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,085 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,085 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,098 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,111 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,137 INFO attempt.RMAppAttemptImpl: Updating application attempt appattempt_1675343413375_0001_000001 with final state: FINISHING, and exit status: -1000\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,138 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from RUNNING to FINAL_SAVING on event = UNREGISTERED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,138 INFO rmapp.RMAppImpl: Updating application application_1675343413375_0001 with final state: FINISHING\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,139 INFO recovery.RMStateStore: Updating info for app: application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,140 INFO rmapp.RMAppImpl: application_1675343413375_0001 State change from RUNNING to FINAL_SAVING on event = ATTEMPT_UNREGISTERED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,140 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,140 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from FINAL_SAVING to FINISHING on event = ATTEMPT_UPDATE_SAVED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,140 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,140 INFO rmapp.RMAppImpl: application_1675343413375_0001 State change from FINAL_SAVING to FINISHING on event = APP_UPDATE_SAVED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,141 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-7d4d7994-85f1-4b17-b2a6-ee01002eb82a\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,152K), 0.0117961 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:05.603+0000: [GC (Allocation Failure) [PSYoungGen: 261734K->14503K(339456K)] 284952K->39880K(523776K), 0.0208556 secs] [Times: user=0.05 sys=0.01, real=0.02 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:08.153+0000: [GC (Allocation Failure) [PSYoungGen: 339111K->8472K(346624K)] 364488K->33857K(530944K), 0.0217628 secs] [Times: user=0.06 sys=0.01, real=0.03 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:08.677+0000: [GC (Allocation Failure) [PSYoungGen: 337688K->6878K(423424K)] 363073K->32263K(607744K), 0.0085282 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:09.041+0000: [GC (Allocation Failure) [PSYoungGen: 413406K->9374K(422912K)] 438791K->34759K(607232K), 0.0102224 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:10.696+0000: [GC (Allocation Failure) [PSYoungGen: 415902K->6775K(541184K)] 441287K->230370K(791552K), 0.0761180 secs] [Times: user=0.11 sys=0.12, real=0.07 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:10.772+0000: [Full GC (Ergonomics) [PSYoungGen: 6775K->0K(541184K)] [ParOldGen: 223595K->227831K(507904K)] 230370K->227831K(1049088K), [Metaspace: 82003K->81594K(1128448K)], 0.2185282 secs] [Times: user=0.53 sys=0.01, real=0.22 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:11.386+0000: [GC (Allocation Failure) [PSYoungGen: 525312K->2144K(540672K)] 753143K->229983K(1048576K), 0.0034361 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:11.876+0000: [GC (GCLocker Initiated GC) [PSYoungGen: 527456K->5984K(636928K)] 755359K->233895K(1144832K), 0.0051718 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] 2023-02-02T13:11:18.120+0000: [GC (Allocation Failure) [PSYoungGen: 634720K->7808K(644096K)] 862649K->235809K(1152000K), 0.0121512 secs] [Times: user=0.02 sys=0.01, real=0.01 secs] \u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout] Heap\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout]  PSYoungGen      total 644096K, used 130323K [0x00000006bdb00000, 0x00000006ec780000, 0x00000007c0000000)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout]   eden space 628736K, 19% used [0x00000006bdb00000,0x00000006c52a4e08,0x00000006e4100000)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout]   from space 15360K, 50% used [0x00000006e4100000,0x00000006e48a0058,0x00000006e5000000)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout]   to   space 14848K, 0% used [0x00000006eb900000,0x00000006eb900000,0x00000006ec780000)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout]  ParOldGen       total 507904K, used 228001K [0x00000004b9000000, 0x00000004d8000000, 0x00000006bdb00000)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout]   object space 507904K, 44% used [0x00000004b9000000,0x00000004c6ea85f8,0x00000004d8000000)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stdout]  Metaspace       1 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 22 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,155 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 67.9 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,157 INFO broadcast.TorrentBroadcast: Reading broadcast variable 22 took 6 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,158 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 188.6 KiB, free 6.3 GiB)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,164 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 2, fetching them\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,165 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.127.243:42921)\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,169 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,170 INFO storage.ShuffleBlockFetcherIterator: Getting 16 (3.5 MiB) non-empty blocks including 9 (2041.7 KiB) local and 0 (0.0 B) host-local and 7 (1593.4 KiB) remote blocks\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,171 INFO storage.ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,239 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,239 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,240 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:17,240 INFO datasources.SQLConfCommitterProvider: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:19,384 INFO output.FileOutputCommitter: Saved output of task 'attempt_20230202131117429118723851236830_0015_m_000000_52' to s3://sagemaker-eu-west-1-691148928602/electricity-forecasting/data/output/energy_full.csv\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:19,384 INFO mapred.SparkHadoopMapRedUtil: attempt_20230202131117429118723851236830_0015_m_000000_52: Committed\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:19,385 INFO executor.Executor: Finished task 0.0 in stage 15.0 (TID 52). 3413 bytes result sent to driver\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:20,045 INFO executor.YarnCoarseGrainedExecutorBackend: Driver commanded a shutdown\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000002/stderr] 2023-02-02 13:11:20,068 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,144 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-ed2ca6b2-1a51-4a82-b916-65a54de8b19a\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,146 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-ed2ca6b2-1a51-4a82-b916-65a54de8b19a/pyspark-f13c1a6d-c4bb-491d-b826-970ff01a4a6f\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,150 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,150 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,150 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,241 INFO resourcemanager.ApplicationMasterService: application_1675343413375_0001 unregistered successfully. \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,247 INFO namenode.FSEditLog: Number of transactions: 183 Total time for transactions(ms): 28 Number of transactions batched in Syncs: 56 Number of syncs: 127 SyncTimes(ms): 4710 \u001b[0m\n",
      "\u001b[34m02-02 13:11 smspark-submit INFO     spark submit was successful. primary node exiting.\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,566 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000002 Container Transitioned from RUNNING to COMPLETED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,567 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Released Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000002#011RESOURCE=<memory:13638, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,587 INFO launcher.ContainerLaunch: Container container_1675343413375_0001_01_000003 succeeded \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,596 INFO launcher.ContainerLaunch: Container container_1675343413375_0001_01_000001 succeeded \u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,598 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000003 transitioned from RUNNING to EXITED_WITH_SUCCESS\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,598 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,599 INFO launcher.ContainerCleanup: Cleaning up container container_1675343413375_0001_01_000003\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,601 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000003\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,602 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,602 INFO launcher.ContainerCleanup: Cleaning up container container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,610 INFO nodemanager.NMAuditLogger: USER=root#011OPERATION=Container Finished - Succeeded#011TARGET=ContainerImpl#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000003\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,615 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000003 transitioned from EXITED_WITH_SUCCESS to DONE\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,615 INFO nodemanager.NMAuditLogger: USER=root#011OPERATION=Container Finished - Succeeded#011TARGET=ContainerImpl#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,615 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,616 INFO application.ApplicationImpl: Removing container_1675343413375_0001_01_000003 from application application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,616 INFO monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1675343413375_0001_01_000003\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,616 INFO containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,616 INFO application.ApplicationImpl: Removing container_1675343413375_0001_01_000001 from application application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,616 INFO monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,616 INFO containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,626 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000001 Container Transitioned from RUNNING to COMPLETED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,626 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Released Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000001#011RESOURCE=<memory:896, max memory:15892, vCores:1, max vCores:4>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,627 INFO resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,627 INFO rmcontainer.RMContainerImpl: container_1675343413375_0001_01_000003 Container Transitioned from RUNNING to COMPLETED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,627 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Released Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000003#011RESOURCE=<memory:13638, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,629 INFO security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000003/launch_container.sh\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001/launch_container.sh\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000003/launch_container.sh]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001/launch_container.sh]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000003/container_tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001/container_tokens\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000003/container_tokens]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001/container_tokens]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000003/sysfs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001/sysfs\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000003/sysfs]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,630 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000001/sysfs]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,633 INFO attempt.RMAppAttemptImpl: appattempt_1675343413375_0001_000001 State change from FINISHING to FINISHED on event = CONTAINER_FINISHED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,637 INFO rmapp.RMAppImpl: application_1675343413375_0001 State change from FINISHING to FINISHED on event = ATTEMPT_FINISHED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,637 INFO capacity.CapacityScheduler: Application Attempt appattempt_1675343413375_0001_000001 is done. finalState=FINISHED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,637 INFO scheduler.AppSchedulingInfo: Application application_1675343413375_0001 requests cleared\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,638 INFO capacity.LeafQueue: Application removed - appId: application_1675343413375_0001 user: root queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,638 INFO capacity.ParentQueue: Application removed - appId: application_1675343413375_0001 user: root leaf-queue of parent: root #applications: 0\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,638 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=Application Finished - Succeeded#011TARGET=RMAppManager#011RESULT=SUCCESS#011APPID=application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,637 INFO amlauncher.AMLauncher: Cleaning master appattempt_1675343413375_0001_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,643 INFO resourcemanager.RMAppManager$ApplicationSummary: appId=application_1675343413375_0001,name=processing.py,user=root,queue=default,state=FINISHED,trackingUrl=http://algo-1:8088/proxy/application_1675343413375_0001/,appMasterHost=10.0.127.243,submitTime=1675343429982,startTime=1675343430041,launchTime=1675343431262,finishTime=1675343480138,finalStatus=SUCCEEDED,memorySeconds=1187239,vcoreSeconds=131,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\\, vCores:0>,applicationType=SPARK,resourceSeconds=1187239 MB-seconds\\, 131 vcore-seconds,preemptedResourceSeconds=0 MB-seconds\\, 0 vcore-seconds,applicationTags=\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,648 INFO ipc.Server: Auth successful for appattempt_1675343413375_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,652 INFO containermanager.ContainerManagerImpl: Stopping container with container Id: container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:20,652 INFO nodemanager.NMAuditLogger: USER=root#011IP=10.0.127.243#011OPERATION=Stop Container Request#011TARGET=ContainerManageImpl#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000001\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,546 INFO launcher.ContainerLaunch: Container container_1675343413375_0001_01_000002 succeeded \u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,555 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000002 transitioned from RUNNING to EXITED_WITH_SUCCESS\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,556 INFO launcher.ContainerCleanup: Cleaning up container container_1675343413375_0001_01_000002\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,559 INFO nodemanager.NMAuditLogger: USER=root#011OPERATION=Container Finished - Succeeded#011TARGET=ContainerImpl#011RESULT=SUCCESS#011APPID=application_1675343413375_0001#011CONTAINERID=container_1675343413375_0001_01_000002\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,560 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,563 INFO container.ContainerImpl: Container container_1675343413375_0001_01_000002 transitioned from EXITED_WITH_SUCCESS to DONE\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,564 INFO application.ApplicationImpl: Removing container_1675343413375_0001_01_000002 from application application_1675343413375_0001\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,564 INFO monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1675343413375_0001_01_000002\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,564 INFO containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1675343413375_0001\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,576 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002/launch_container.sh\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,576 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002/launch_container.sh]\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,576 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002/container_tokens\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,576 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002/container_tokens]\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,576 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002/sysfs\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:20,576 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001/container_1675343413375_0001_01_000002/sysfs]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:21,628 INFO nodemanager.NodeStatusUpdaterImpl: Removed completed containers from NM context: [container_1675343413375_0001_01_000001]\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:21,630 INFO application.ApplicationImpl: Application application_1675343413375_0001 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:21,630 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:21,630 INFO containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:21,631 INFO application.ApplicationImpl: Application application_1675343413375_0001 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:21,631 INFO loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1675343413375_0001, with delay of 10800 seconds\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:21,570 INFO application.ApplicationImpl: Application application_1675343413375_0001 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:21,571 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1675343413375_0001\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:21,571 INFO containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1675343413375_0001\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:21,572 INFO application.ApplicationImpl: Application application_1675343413375_0001 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:21,572 INFO loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1675343413375_0001, with delay of 10800 seconds\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,249 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED\n",
      "  getNumBytes()     = 134217728\n",
      "  getBytesOnDisk()  = 134217728\n",
      "  getVisibleLength()= 134217728\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741825 for deletion\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,250 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 replica FinalizedReplica, blk_1073741826_1002, FINALIZED\n",
      "  getNumBytes()     = 134217728\n",
      "  getBytesOnDisk()  = 134217728\n",
      "  getVisibleLength()= 134217728\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741826 for deletion\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,251 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 replica FinalizedReplica, blk_1073741827_1003, FINALIZED\n",
      "  getNumBytes()     = 134217728\n",
      "  getBytesOnDisk()  = 134217728\n",
      "  getVisibleLength()= 134217728\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741827 for deletion\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,251 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 replica FinalizedReplica, blk_1073741828_1004, FINALIZED\n",
      "  getNumBytes()     = 46002121\n",
      "  getBytesOnDisk()  = 46002121\n",
      "  getVisibleLength()= 46002121\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741828 for deletion\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,251 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 replica FinalizedReplica, blk_1073741829_1005, FINALIZED\n",
      "  getNumBytes()     = 889814\n",
      "  getBytesOnDisk()  = 889814\n",
      "  getVisibleLength()= 889814\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741829 for deletion\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,251 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 replica FinalizedReplica, blk_1073741830_1006, FINALIZED\n",
      "  getNumBytes()     = 41587\n",
      "  getBytesOnDisk()  = 41587\n",
      "  getVisibleLength()= 41587\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741830 for deletion\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,251 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 replica FinalizedReplica, blk_1073741831_1007, FINALIZED\n",
      "  getNumBytes()     = 266144\n",
      "  getBytesOnDisk()  = 266144\n",
      "  getVisibleLength()= 266144\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741831 for deletion\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,265 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741825_1001 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741825\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,280 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741826_1002 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741826\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,295 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741827_1003 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741827\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,300 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741828_1004 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741828\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,301 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741829_1005 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741829\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,301 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741830_1006 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741830\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:22,301 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741831_1007 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741831\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,803 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED\n",
      "  getNumBytes()     = 134217728\n",
      "  getBytesOnDisk()  = 134217728\n",
      "  getVisibleLength()= 134217728\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741825 for deletion\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,804 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 replica FinalizedReplica, blk_1073741826_1002, FINALIZED\n",
      "  getNumBytes()     = 134217728\n",
      "  getBytesOnDisk()  = 134217728\n",
      "  getVisibleLength()= 134217728\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741826 for deletion\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,804 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 replica FinalizedReplica, blk_1073741827_1003, FINALIZED\n",
      "  getNumBytes()     = 134217728\n",
      "  getBytesOnDisk()  = 134217728\n",
      "  getVisibleLength()= 134217728\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741827 for deletion\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,804 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 replica FinalizedReplica, blk_1073741828_1004, FINALIZED\n",
      "  getNumBytes()     = 46002121\n",
      "  getBytesOnDisk()  = 46002121\n",
      "  getVisibleLength()= 46002121\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741828 for deletion\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,805 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 replica FinalizedReplica, blk_1073741829_1005, FINALIZED\n",
      "  getNumBytes()     = 889814\n",
      "  getBytesOnDisk()  = 889814\n",
      "  getVisibleLength()= 889814\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741829 for deletion\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,805 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 replica FinalizedReplica, blk_1073741830_1006, FINALIZED\n",
      "  getNumBytes()     = 41587\n",
      "  getBytesOnDisk()  = 41587\n",
      "  getVisibleLength()= 41587\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741830 for deletion\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,805 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 replica FinalizedReplica, blk_1073741831_1007, FINALIZED\n",
      "  getNumBytes()     = 266144\n",
      "  getBytesOnDisk()  = 266144\n",
      "  getVisibleLength()= 266144\n",
      "  getVolume()       = /opt/amazon/hadoop/hdfs/datanode\n",
      "  getBlockURI()     = file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741831 for deletion\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,820 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741825_1001 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741825\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,835 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741826_1002 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741826\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,851 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741827_1003 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741827\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,857 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741828_1004 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741828\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,857 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741829_1005 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741829\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,858 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741830_1006 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741830\u001b[0m\n",
      "\u001b[34m2023-02-02 13:11:25,858 INFO impl.FsDatasetAsyncDiskService: Deleted BP-679434436-10.0.127.243-1675343406013 blk_1073741831_1007 URI file:/opt/amazon/hadoop/hdfs/datanode/current/BP-679434436-10.0.127.243-1675343406013/current/finalized/subdir0/subdir0/blk_1073741831\u001b[0m\n",
      "\u001b[34m02-02 13:11 sagemaker-spark-event-logs-publisher INFO     Got spark event logs file: application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m02-02 13:11 root         INFO     copying /tmp/spark-events/application_1675343413375_0001 to /opt/ml/processing/spark-events/application_1675343413375_0001\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1675343413375_0001/container_1675343413375_0001_01_000003/stderr] 2023-02-02 13:11:16,964 INFO executo\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:34,592 INFO retry.RetryInvocationHandler: java.io.EOFException: End of File Exception between local host is: \"algo-2/10.0.73.224\"; destination host is: \"algo-1\":8031; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking ResourceTrackerPBClientImpl.nodeHeartbeat over null. Retrying after sleeping for 30000ms.\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:37,242 WARN datanode.DataNode: IOException in offerService\u001b[0m\n",
      "\u001b[35mjava.io.EOFException: End of File Exception between local host is: \"algo-2/10.0.73.224\"; destination host is: \"algo-1\":8020; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException\u001b[0m\n",
      "\u001b[35m#011at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\u001b[0m\n",
      "\u001b[35m#011at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\u001b[0m\n",
      "\u001b[35m#011at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\u001b[0m\n",
      "\u001b[35m#011at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client.call(Client.java:1491)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client.call(Client.java:1388)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)\u001b[0m\n",
      "\u001b[35m#011at com.sun.proxy.$Proxy16.sendHeartbeat(Unknown Source)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)\u001b[0m\n",
      "\u001b[35m#011at java.lang.Thread.run(Thread.java:748)\u001b[0m\n",
      "\u001b[35mCaused by: java.io.EOFException\u001b[0m\n",
      "\u001b[35m#011at java.io.DataInputStream.readInt(DataInputStream.java:392)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)\u001b[0m\n",
      "\u001b[35m02-02 13:11 urllib3.connectionpool WARNING  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f34e43c1b80>: Failed to establish a new connection: [Errno 111] Connection refused')': /\u001b[0m\n",
      "\u001b[35m02-02 13:11 urllib3.connectionpool WARNING  Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f34e43c1b50>: Failed to establish a new connection: [Errno 111] Connection refused')': /\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:41,242 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m02-02 13:11 urllib3.connectionpool WARNING  Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f34e43fb0d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:42,242 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:43,243 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:44,244 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:45,244 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m02-02 13:11 urllib3.connectionpool WARNING  Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f34e43fb2e0>: Failed to establish a new connection: [Errno 111] Connection refused')': /\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:46,245 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:47,246 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:48,247 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:49,247 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:50,248 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:50,249 WARN datanode.DataNode: IOException in offerService\u001b[0m\n",
      "\u001b[35mjava.net.ConnectException: Call From algo-2/10.0.73.224 to algo-1:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\u001b[0m\n",
      "\u001b[35m#011at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\u001b[0m\n",
      "\u001b[35m#011at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\u001b[0m\n",
      "\u001b[35m#011at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\u001b[0m\n",
      "\u001b[35m#011at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client.call(Client.java:1491)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client.call(Client.java:1388)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)\u001b[0m\n",
      "\u001b[35m#011at com.sun.proxy.$Proxy16.sendHeartbeat(Unknown Source)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)\u001b[0m\n",
      "\u001b[35m#011at java.lang.Thread.run(Thread.java:748)\u001b[0m\n",
      "\u001b[35mCaused by: java.net.ConnectException: Connection refused\u001b[0m\n",
      "\u001b[35m#011at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\u001b[0m\n",
      "\u001b[35m#011at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:700)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:804)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:421)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client.getConnection(Client.java:1606)\u001b[0m\n",
      "\u001b[35m#011at org.apache.hadoop.ipc.Client.call(Client.java:1435)\u001b[0m\n",
      "\u001b[35m#011... 9 more\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:52,250 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m2023-02-02 13:11:53,251 INFO ipc.Client: Retrying connect to server: algo-1/10.0.127.243:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[35m02-02 13:11 urllib3.connectionpool WARNING  Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f34e43fb4f0>: Failed to establish a new connection: [Errno 111] Connection refused')': /\u001b[0m\n",
      "\u001b[35m02-02 13:11 smspark-submit INFO     primary is down, worker now exiting\u001b[0m\n",
      "\u001b[35m[/var/log/yarn/userlogs/application_1675343413375_000\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processor.run(\n",
    "    submit_app=run_args.code,\n",
    "    arguments=[\n",
    "        \"--copy_hdfs\",\n",
    "        \"1\",\n",
    "        \"--bucket_name\",\n",
    "        bucket_name,\n",
    "        \"--processing_input_files_path\",\n",
    "        processing_input_files_path,\n",
    "        \"--processing_output_files_path\",\n",
    "        processing_output_files_path\n",
    "    ],\n",
    "    inputs=run_args.inputs,\n",
    "    outputs=run_args.outputs,\n",
    "    spark_event_logs_s3_uri=\"s3://{}/electricity-forecasting/logs\".format(bucket_name),\n",
    "    wait=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "7830b2e0dcc405ab83456d8c26dd7c2db32ddf1a7b2e64ef505b215ebac66515"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
